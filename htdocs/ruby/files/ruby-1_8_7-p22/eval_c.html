  <div id="fileHeader">
    <h1>eval.c</h1>
    <table class="header-table">
    <tr class="top-aligned-row">
      <td><strong>Path:</strong></td>
      <td>ruby-1.8.7-p22/eval.c
      </td>
    </tr>
    <tr class="top-aligned-row">
      <td><strong>Last Update:</strong></td>
      <td>Sat May 31 06:44:49 -0500 2008</td>
    </tr>
    </table>
  </div>
 <!-- banner header -->

  <div id="bodyContent" >
    <h2>Source Code</h2>
    <pre>/**********************************************************************

  eval.c -

  $Author: knu $
  $Date: 2008-05-31 20:44:49 +0900 (Sat, 31 May 2008) $
  created at: Thu Jun 10 14:22:17 JST 1993

  Copyright (C) 1993-2003 Yukihiro Matsumoto
  Copyright (C) 2000  Network Applied Communication Laboratory, Inc.
  Copyright (C) 2000  Information-technology Promotion Agency, Japan

**********************************************************************/

#include &quot;ruby.h&quot;
#include &quot;node.h&quot;
#include &quot;env.h&quot;
#include &quot;util.h&quot;
#include &quot;rubysig.h&quot;

#ifdef HAVE_STDLIB_H
#include &lt;stdlib.h&gt;
#endif
#ifndef EXIT_SUCCESS
#define EXIT_SUCCESS 0
#endif
#ifndef EXIT_FAILURE
#define EXIT_FAILURE 1
#endif

#include &lt;stdio.h&gt;

#include &quot;st.h&quot;
#include &quot;dln.h&quot;

#ifdef __APPLE__
#include &lt;crt_externs.h&gt;
#endif

/* Make alloca work the best possible way.  */
#ifdef __GNUC__
# ifndef atarist
#  ifndef alloca
#   define alloca __builtin_alloca
#  endif
# endif /* atarist */
#else
# ifdef HAVE_ALLOCA_H
#  include &lt;alloca.h&gt;
# else
#  ifndef _AIX
#   ifndef alloca /* predefined by HP cc +Olibcalls */
void *alloca ();
#   endif
#  endif /* AIX */
# endif /* HAVE_ALLOCA_H */
#endif /* __GNUC__ */

#ifdef HAVE_STDARG_PROTOTYPES
#include &lt;stdarg.h&gt;
#define va_init_list(a,b) va_start(a,b)
#else
#include &lt;varargs.h&gt;
#define va_init_list(a,b) va_start(a)
#endif

#ifndef HAVE_STRING_H
char *strrchr _((const char*,const char));
#endif

#ifdef HAVE_UNISTD_H
#include &lt;unistd.h&gt;
#endif

#ifdef __BEOS__
#include &lt;net/socket.h&gt;
#endif

#ifdef __MACOS__
#include &quot;macruby_private.h&quot;
#endif

#ifdef __VMS
#include &quot;vmsruby_private.h&quot;
#endif

#ifdef USE_CONTEXT

NORETURN(static void rb_jump_context(rb_jmpbuf_t, int));
static inline void
rb_jump_context(env, val)
    rb_jmpbuf_t env;
    int val;
{
    env-&gt;status = val;
    setcontext(&amp;env-&gt;context);
    abort();			/* ensure noreturn */
}
/*
 * PRE_GETCONTEXT and POST_GETCONTEXT is a magic for getcontext, gcc,
 * IA64 register stack and SPARC register window combination problem.
 *
 * Assume following code sequence.
 * 
 * 1. set a register in the register stack/window such as r32/l0.
 * 2. call getcontext.
 * 3. use the register.
 * 4. update the register for other use.
 * 5. call setcontext indirectly (or directly).
 *
 * This code should be run as 1-&gt;2-&gt;3-&gt;4-&gt;5-&gt;3-&gt;4.
 * But after second getcontext return (second 3),
 * the register is broken (updated).
 * It's because getcontext/setcontext doesn't preserve the content of the
 * register stack/window.
 *
 * setjmp also doesn't preserve the content of the register stack/window.
 * But it has not the problem because gcc knows setjmp may return twice.
 * gcc detects setjmp and generates setjmp safe code.
 *
 * So setjmp calls before and after the getcontext call makes the code
 * somewhat safe.
 * It fix the problem on IA64.
 * It is not required that setjmp is called at run time, since the problem is
 * register usage.
 *
 * Since the magic setjmp is not enough for SPARC,
 * inline asm is used to prohibit registers in register windows.
 *
 * Since the problem is fixed at gcc 4.0.3, the magic is applied only for
 * prior versions of gcc.
 * http://gcc.gnu.org/bugzilla/show_bug.cgi?id=21957
 * http://gcc.gnu.org/bugzilla/show_bug.cgi?id=22127
 */
#  define GCC_VERSION_BEFORE(major, minor, patchlevel) \
    (defined(__GNUC__) &amp;&amp; !defined(__INTEL_COMPILER) &amp;&amp; \
     ((__GNUC__ &lt; (major)) ||  \
      (__GNUC__ == (major) &amp;&amp; __GNUC_MINOR__ &lt; (minor)) || \
      (__GNUC__ == (major) &amp;&amp; __GNUC_MINOR__ == (minor) &amp;&amp; __GNUC_PATCHLEVEL__ &lt; (patchlevel))))
#  if GCC_VERSION_BEFORE(4,0,3) &amp;&amp; (defined(sparc) || defined(__sparc__))
#    ifdef __pic__
/*
 * %l7 is excluded for PIC because it is PIC register.
 * http://lists.freebsd.org/pipermail/freebsd-sparc64/2006-January/003739.html
 */
#      define PRE_GETCONTEXT \
	 ({ __asm__ volatile (&quot;&quot; : : :  \
	    &quot;%o0&quot;, &quot;%o1&quot;, &quot;%o2&quot;, &quot;%o3&quot;, &quot;%o4&quot;, &quot;%o5&quot;, &quot;%o7&quot;, \
	    &quot;%l0&quot;, &quot;%l1&quot;, &quot;%l2&quot;, &quot;%l3&quot;, &quot;%l4&quot;, &quot;%l5&quot;, &quot;%l6&quot;, \
	    &quot;%i0&quot;, &quot;%i1&quot;, &quot;%i2&quot;, &quot;%i3&quot;, &quot;%i4&quot;, &quot;%i5&quot;, &quot;%i7&quot;); })
#    else
#      define PRE_GETCONTEXT \
	 ({ __asm__ volatile (&quot;&quot; : : :  \
	    &quot;%o0&quot;, &quot;%o1&quot;, &quot;%o2&quot;, &quot;%o3&quot;, &quot;%o4&quot;, &quot;%o5&quot;, &quot;%o7&quot;, \
	    &quot;%l0&quot;, &quot;%l1&quot;, &quot;%l2&quot;, &quot;%l3&quot;, &quot;%l4&quot;, &quot;%l5&quot;, &quot;%l6&quot;, &quot;%l7&quot;, \
	    &quot;%i0&quot;, &quot;%i1&quot;, &quot;%i2&quot;, &quot;%i3&quot;, &quot;%i4&quot;, &quot;%i5&quot;, &quot;%i7&quot;); })
#    endif
#    define POST_GETCONTEXT PRE_GETCONTEXT
#  elif GCC_VERSION_BEFORE(4,0,3) &amp;&amp; defined(__ia64)
static jmp_buf function_call_may_return_twice_jmp_buf;
int function_call_may_return_twice_false_1 = 0;
int function_call_may_return_twice_false_2 = 0;
#    define PRE_GETCONTEXT \
       (function_call_may_return_twice_false_1 ? \
        setjmp(function_call_may_return_twice_jmp_buf) : \
        0)
#    define POST_GETCONTEXT \
       (function_call_may_return_twice_false_2 ? \
        setjmp(function_call_may_return_twice_jmp_buf) : \
        0)
#  elif defined(__FreeBSD__) &amp;&amp; __FreeBSD__ &lt; 7
/*
 * workaround for FreeBSD/i386 getcontext/setcontext bug.
 * clear the carry flag by (0 ? ... : ...).
 * FreeBSD PR 92110 http://www.freebsd.org/cgi/query-pr.cgi?pr=92110
 * [ruby-dev:28263]
 */
static int volatile freebsd_clear_carry_flag = 0;
#    define PRE_GETCONTEXT \
       (freebsd_clear_carry_flag ? (freebsd_clear_carry_flag = 0) : 0)
#  endif
#  ifndef PRE_GETCONTEXT
#    define PRE_GETCONTEXT 0
#  endif
#  ifndef POST_GETCONTEXT
#    define POST_GETCONTEXT 0
#  endif
#  define ruby_longjmp(env, val) rb_jump_context(env, val)
#  define ruby_setjmp(just_before_setjmp, j) ((j)-&gt;status = 0, \
     (just_before_setjmp), \
     PRE_GETCONTEXT, \
     getcontext(&amp;(j)-&gt;context), \
     POST_GETCONTEXT, \
     (j)-&gt;status)
#else
#  define ruby_setjmp(just_before_setjmp, env) \
     ((just_before_setjmp), RUBY_SETJMP(env))
#  define ruby_longjmp(env,val) RUBY_LONGJMP(env,val)
#  ifdef __CYGWIN__
int _setjmp(), _longjmp();
#  endif
#endif

#include &lt;sys/types.h&gt;
#include &lt;signal.h&gt;
#include &lt;errno.h&gt;

#if defined(__VMS)
#pragma nostandard
#endif

#ifdef HAVE_SYS_SELECT_H
#include &lt;sys/select.h&gt;
#endif

#include &lt;sys/stat.h&gt;

VALUE rb_cProc;
VALUE rb_cBinding;
static VALUE proc_invoke _((VALUE,VALUE,VALUE,VALUE));
static VALUE rb_f_binding _((VALUE));
static void rb_f_END _((void));
static VALUE rb_f_block_given_p _((void));
static VALUE block_pass _((VALUE,NODE*));

VALUE rb_cMethod;
static VALUE method_call _((int, VALUE*, VALUE));
VALUE rb_cUnboundMethod;
static VALUE umethod_bind _((VALUE, VALUE));
static VALUE rb_mod_define_method _((int, VALUE*, VALUE));
NORETURN(static void rb_raise_jump _((VALUE)));
static VALUE rb_make_exception _((int argc, VALUE *argv));

static int scope_vmode;
#define SCOPE_PUBLIC    0
#define SCOPE_PRIVATE   1
#define SCOPE_PROTECTED 2
#define SCOPE_MODFUNC   5
#define SCOPE_MASK      7
#define SCOPE_SET(f)  (scope_vmode=(f))
#define SCOPE_TEST(f) (scope_vmode&amp;(f))

VALUE (*ruby_sandbox_save)_((rb_thread_t));
VALUE (*ruby_sandbox_restore)_((rb_thread_t));
NODE* ruby_current_node;
int ruby_safe_level = 0;
/* safe-level:
   0 - strings from streams/environment/ARGV are tainted (default)
   1 - no dangerous operation by tainted value
   2 - process/file operations prohibited
   3 - all generated objects are tainted
   4 - no global (non-tainted) variable modification/no direct output
*/

static VALUE safe_getter _((void));
static void safe_setter _((VALUE val));

void
rb_secure(level)
    int level;
{
    if (level &lt;= ruby_safe_level) {
	if (ruby_frame-&gt;last_func) {
	    rb_raise(rb_eSecurityError, &quot;Insecure operation `%s' at level %d&quot;,
		     rb_id2name(ruby_frame-&gt;last_func), ruby_safe_level);
	}
	else {
	    rb_raise(rb_eSecurityError, &quot;Insecure operation at level %d&quot;, ruby_safe_level);
	}
    }
}

void
rb_secure_update(obj)
    VALUE obj;
{
    if (!OBJ_TAINTED(obj)) rb_secure(4);
}

void
rb_check_safe_obj(x)
    VALUE x;
{
    if (ruby_safe_level &gt; 0 &amp;&amp; OBJ_TAINTED(x)){
	if (ruby_frame-&gt;last_func) {
	    rb_raise(rb_eSecurityError, &quot;Insecure operation - %s&quot;,
		     rb_id2name(ruby_frame-&gt;last_func));
	}
	else {
	    rb_raise(rb_eSecurityError, &quot;Insecure operation: -r&quot;);
	}
    }
    rb_secure(4);
}

void
rb_check_safe_str(x)
    VALUE x;
{
    rb_check_safe_obj(x);
    if (TYPE(x)!= T_STRING) {
	rb_raise(rb_eTypeError, &quot;wrong argument type %s (expected String)&quot;,
		 rb_obj_classname(x));
    }
}

NORETURN(static void print_undef _((VALUE, ID)));
static void
print_undef(klass, id)
    VALUE klass;
    ID id;
{
    rb_name_error(id, &quot;undefined method `%s' for %s `%s'&quot;,
		  rb_id2name(id),
		  (TYPE(klass) == T_MODULE) ? &quot;module&quot; : &quot;class&quot;,
		  rb_class2name(klass));
}

static ID removed, singleton_removed, undefined, singleton_undefined;

#define CACHE_SIZE 0x800
#define CACHE_MASK 0x7ff
#define EXPR1(c,m) ((((c)&gt;&gt;3)^(m))&amp;CACHE_MASK)

struct cache_entry {		/* method hash table. */
    ID mid;			/* method's id */
    ID mid0;			/* method's original id */
    VALUE klass;		/* receiver's class */
    VALUE origin;		/* where method defined  */
    NODE *method;
    int noex;
};

static struct cache_entry cache[CACHE_SIZE];
static int ruby_running = 0;

void
rb_clear_cache()
{
   struct cache_entry *ent, *end;

    if (!ruby_running) return;
    ent = cache; end = ent + CACHE_SIZE;
    while (ent &lt; end) {
	ent-&gt;mid = 0;
	ent++;
    }
}

static void
rb_clear_cache_for_undef(klass, id)
    VALUE klass;
    ID id;
{
    struct cache_entry *ent, *end;

    if (!ruby_running) return;
    ent = cache; end = ent + CACHE_SIZE;
    while (ent &lt; end) {
	if (ent-&gt;mid == id &amp;&amp;
	    RCLASS(ent-&gt;origin)-&gt;m_tbl == RCLASS(klass)-&gt;m_tbl) {
	    ent-&gt;mid = 0;
	}
	ent++;
    }
}

static void
rb_clear_cache_by_id(id)
    ID id;
{
    struct cache_entry *ent, *end;

    if (!ruby_running) return;
    ent = cache; end = ent + CACHE_SIZE;
    while (ent &lt; end) {
	if (ent-&gt;mid == id) {
	    ent-&gt;mid = 0;
	}
	ent++;
    }
}

void
rb_clear_cache_by_class(klass)
    VALUE klass;
{
    struct cache_entry *ent, *end;

    if (!ruby_running) return;
    ent = cache; end = ent + CACHE_SIZE;
    while (ent &lt; end) {
	if (ent-&gt;klass == klass || ent-&gt;origin == klass) {
	    ent-&gt;mid = 0;
	}
	ent++;
    }
}

static ID init, eqq, each, aref, aset, match, missing;
static ID added, singleton_added;
static ID __id__, __send__, respond_to;

#define NOEX_TAINTED 8
#define NOEX_SAFE(n) ((n) &gt;&gt; 4)
#define NOEX_WITH(n, v) ((n) | (v) &lt;&lt; 4)
#define NOEX_WITH_SAFE(n) NOEX_WITH(n, ruby_safe_level)

void
rb_add_method(klass, mid, node, noex)
    VALUE klass;
    ID mid;
    NODE *node;
    int noex;
{
    NODE *body;

    if (NIL_P(klass)) klass = rb_cObject;
    if (ruby_safe_level &gt;= 4 &amp;&amp; (klass == rb_cObject || !OBJ_TAINTED(klass))) {
	rb_raise(rb_eSecurityError, &quot;Insecure: can't define method&quot;);
    }
    if (!FL_TEST(klass, FL_SINGLETON) &amp;&amp;
	node &amp;&amp; nd_type(node) != NODE_ZSUPER &amp;&amp;
	(mid == rb_intern(&quot;initialize&quot; )|| mid == rb_intern(&quot;initialize_copy&quot;))) {
	noex = NOEX_PRIVATE | noex;
    }
    else if (FL_TEST(klass, FL_SINGLETON) &amp;&amp; node &amp;&amp; nd_type(node) == NODE_CFUNC &amp;&amp;
	     mid == rb_intern(&quot;allocate&quot;)) {
	rb_warn(&quot;defining %s.allocate is deprecated; use rb_define_alloc_func()&quot;,
		rb_class2name(rb_iv_get(klass, &quot;__attached__&quot;)));
	mid = ID_ALLOCATOR;
    }
    if (OBJ_FROZEN(klass)) rb_error_frozen(&quot;class/module&quot;);
    rb_clear_cache_by_id(mid);
    body = NEW_METHOD(node, NOEX_WITH_SAFE(noex));
    st_insert(RCLASS(klass)-&gt;m_tbl, mid, (st_data_t)body);
    if (node &amp;&amp; mid != ID_ALLOCATOR &amp;&amp; ruby_running) {
	if (FL_TEST(klass, FL_SINGLETON)) {
	    rb_funcall(rb_iv_get(klass, &quot;__attached__&quot;), singleton_added, 1, ID2SYM(mid));
	}
	else {
	    rb_funcall(klass, added, 1, ID2SYM(mid));
	}
    }
}

void
rb_define_alloc_func(klass, func)
    VALUE klass;
    VALUE (*func) _((VALUE));
{
    Check_Type(klass, T_CLASS);
    rb_add_method(rb_singleton_class(klass), ID_ALLOCATOR, NEW_CFUNC(func, 0),
		  NOEX_PRIVATE);
}

void
rb_undef_alloc_func(klass)
    VALUE klass;
{
    Check_Type(klass, T_CLASS);
    rb_add_method(rb_singleton_class(klass), ID_ALLOCATOR, 0, NOEX_UNDEF);
}

static NODE*
search_method(klass, id, origin)
    VALUE klass, *origin;
    ID id;
{
    st_data_t body;

    if (!klass) return 0;
    while (!st_lookup(RCLASS(klass)-&gt;m_tbl, id, &amp;body)) {
	klass = RCLASS(klass)-&gt;super;
	if (!klass) return 0;
    }

    if (origin) *origin = klass;
    return (NODE *)body;
}

static NODE*
rb_get_method_body(klassp, idp, noexp)
    VALUE *klassp;
    ID *idp;
    int *noexp;
{
    ID id = *idp;
    VALUE klass = *klassp;
    VALUE origin = 0;
    NODE * volatile body;
    struct cache_entry *ent;

    if ((body = search_method(klass, id, &amp;origin)) == 0 || !body-&gt;nd_body) {
	/* store empty info in cache */
	ent = cache + EXPR1(klass, id);
	ent-&gt;klass  = klass;
	ent-&gt;origin = klass;
	ent-&gt;mid = ent-&gt;mid0 = id;
	ent-&gt;noex   = 0;
	ent-&gt;method = 0;

	return 0;
    }

    if (ruby_running) {
	/* store in cache */
	ent = cache + EXPR1(klass, id);
	ent-&gt;klass  = klass;
	ent-&gt;noex   = body-&gt;nd_noex;
	if (noexp) *noexp = body-&gt;nd_noex;
	body = body-&gt;nd_body;
	if (nd_type(body) == NODE_FBODY) {
	    ent-&gt;mid = id;
	    *klassp = body-&gt;nd_orig;
	    ent-&gt;origin = body-&gt;nd_orig;
	    *idp = ent-&gt;mid0 = body-&gt;nd_mid;
	    body = ent-&gt;method = body-&gt;nd_head;
	}
	else {
	    *klassp = origin;
	    ent-&gt;origin = origin;
	    ent-&gt;mid = ent-&gt;mid0 = id;
	    ent-&gt;method = body;
	}
    }
    else {
	if (noexp) *noexp = body-&gt;nd_noex;
	body = body-&gt;nd_body;
	if (nd_type(body) == NODE_FBODY) {
	    *klassp = body-&gt;nd_orig;
	    *idp = body-&gt;nd_mid;
	    body = body-&gt;nd_head;
	}
	else {
	    *klassp = origin;
	}
    }

    return body;
}

NODE*
rb_method_node(klass, id)
    VALUE klass;
    ID id;
{
    int noex;

    return rb_get_method_body(&amp;klass, &amp;id, &amp;noex);
}

static void
remove_method(klass, mid)
    VALUE klass;
    ID mid;
{
    st_data_t data;
    NODE *body = 0;

    if (klass == rb_cObject) {
	rb_secure(4);
    }
    if (ruby_safe_level &gt;= 4 &amp;&amp; !OBJ_TAINTED(klass)) {
	rb_raise(rb_eSecurityError, &quot;Insecure: can't remove method&quot;);
    }
    if (OBJ_FROZEN(klass)) rb_error_frozen(&quot;class/module&quot;);
    if (mid == __id__ || mid == __send__ || mid == init) {
	rb_warn(&quot;removing `%s' may cause serious problem&quot;, rb_id2name(mid));
    }
    if (st_lookup(RCLASS(klass)-&gt;m_tbl, mid, &amp;data)) {
	body = (NODE *)data;
	if (!body || !body-&gt;nd_body) body = 0;
	else {
	    st_delete(RCLASS(klass)-&gt;m_tbl, &amp;mid, &amp;data);
	}
    }
    if (!body) {
	rb_name_error(mid, &quot;method `%s' not defined in %s&quot;,
		      rb_id2name(mid), rb_class2name(klass));
    }
    rb_clear_cache_for_undef(klass, mid);
    if (FL_TEST(klass, FL_SINGLETON)) {
	rb_funcall(rb_iv_get(klass, &quot;__attached__&quot;), singleton_removed, 1, ID2SYM(mid));
    }
    else {
	rb_funcall(klass, removed, 1, ID2SYM(mid));
    }
}

void
rb_remove_method(klass, name)
    VALUE klass;
    const char *name;
{
    remove_method(klass, rb_intern(name));
}

/*
 *  call-seq:
 *     remove_method(symbol)   =&gt; self
 *  
 *  Removes the method identified by _symbol_ from the current
 *  class. For an example, see &lt;code&gt;Module.undef_method&lt;/code&gt;.
 */

static VALUE
rb_mod_remove_method(argc, argv, mod)
    int argc;
    VALUE *argv;
    VALUE mod;
{
    int i;

    for (i=0; i&lt;argc; i++) {
	remove_method(mod, rb_to_id(argv[i]));
    }
    return mod;
}

#undef rb_disable_super
#undef rb_enable_super

void
rb_disable_super(klass, name)
    VALUE klass;
    const char *name;
{
    /* obsolete - no use */
}

void
rb_enable_super(klass, name)
    VALUE klass;
    const char *name;
{
    rb_warn(&quot;rb_enable_super() is obsolete&quot;);
}

static void
rb_export_method(klass, name, noex)
    VALUE klass;
    ID name;
    ID noex;
{
    NODE *body;
    VALUE origin;

    if (klass == rb_cObject) {
	rb_secure(4);
    }
    body = search_method(klass, name, &amp;origin);
    if (!body &amp;&amp; TYPE(klass) == T_MODULE) {
	body = search_method(rb_cObject, name, &amp;origin);
    }
    if (!body || !body-&gt;nd_body) {
	print_undef(klass, name);
    }
    if (body-&gt;nd_noex != noex) {
	if (klass == origin) {
	    body-&gt;nd_noex = noex;
	}
	else {
	    rb_add_method(klass, name, NEW_ZSUPER(), noex);
	}
    }
}

int
rb_method_boundp(klass, id, ex)
    VALUE klass;
    ID id;
    int ex;
{
    struct cache_entry *ent;
    int noex;

    /* is it in the method cache? */
    ent = cache + EXPR1(klass, id);
    if (ent-&gt;mid == id &amp;&amp; ent-&gt;klass == klass) {
	if (ex &amp;&amp; (ent-&gt;noex &amp; NOEX_PRIVATE))
	    return Qfalse;
	if (!ent-&gt;method) return Qfalse;
	return Qtrue;
    }
    if (rb_get_method_body(&amp;klass, &amp;id, &amp;noex)) {
	if (ex &amp;&amp; (noex &amp; NOEX_PRIVATE))
	    return Qfalse;
	return Qtrue;
    }
    return Qfalse;
}

void
rb_attr(klass, id, read, write, ex)
    VALUE klass;
    ID id;
    int read, write, ex;
{
    const char *name;
    char *buf;
    ID attriv;
    int noex;
    size_t len;

    if (!ex) noex = NOEX_PUBLIC;
    else {
	if (SCOPE_TEST(SCOPE_PRIVATE)) {
	    noex = NOEX_PRIVATE;
	    rb_warning((scope_vmode == SCOPE_MODFUNC) ?
		       &quot;attribute accessor as module_function&quot; :
		       &quot;private attribute?&quot;);
	}
	else if (SCOPE_TEST(SCOPE_PROTECTED)) {
	    noex = NOEX_PROTECTED;
	}
	else {
	    noex = NOEX_PUBLIC;
	}
    }

    if (!rb_is_local_id(id) &amp;&amp; !rb_is_const_id(id)) {
	rb_name_error(id, &quot;invalid attribute name `%s'&quot;, rb_id2name(id));
    }
    name = rb_id2name(id);
    if (!name) {
	rb_raise(rb_eArgError, &quot;argument needs to be symbol or string&quot;);
    }
    len = strlen(name)+2;
    buf = ALLOCA_N(char,len);
    snprintf(buf, len, &quot;@%s&quot;, name);
    attriv = rb_intern(buf);
    if (read) {
	rb_add_method(klass, id, NEW_IVAR(attriv), noex);
    }
    if (write) {
	rb_add_method(klass, rb_id_attrset(id), NEW_ATTRSET(attriv), noex);
    }
}

extern int ruby_in_compile;

VALUE ruby_errinfo = Qnil;
extern NODE *ruby_eval_tree_begin;
extern NODE *ruby_eval_tree;
extern int ruby_nerrs;

VALUE rb_eLocalJumpError;
VALUE rb_eSysStackError;

extern VALUE ruby_top_self;

struct FRAME *ruby_frame;
struct SCOPE *ruby_scope;
static struct FRAME *top_frame;
static struct SCOPE *top_scope;

static unsigned long frame_unique = 0;

#define PUSH_FRAME() do {		\
    struct FRAME _frame;		\
    _frame.prev = ruby_frame;		\
    _frame.tmp  = 0;			\
    _frame.node = ruby_current_node;	\
    _frame.iter = ruby_iter-&gt;iter;	\
    _frame.argc = 0;			\
    _frame.flags = 0;			\
    _frame.uniq = frame_unique++;	\
    ruby_frame = &amp;_frame

#define POP_FRAME()  			\
    ruby_current_node = _frame.node;	\
    ruby_frame = _frame.prev;		\
} while (0)

struct BLOCK {
    NODE *var;
    NODE *body;
    VALUE self;
    struct FRAME frame;
    struct SCOPE *scope;
    VALUE klass;
    NODE *cref;
    int iter;
    int vmode;
    int flags;
    int uniq;
    struct RVarmap *dyna_vars;
    VALUE orig_thread;
    VALUE wrapper;
    VALUE block_obj;
    struct BLOCK *outer;
    struct BLOCK *prev;
};

#define BLOCK_D_SCOPE 1
#define BLOCK_LAMBDA  2

static struct BLOCK *ruby_block;
static unsigned long block_unique = 1;

#define PUSH_BLOCK(v,b) do {		\
    struct BLOCK _block;		\
    _block.var = (v);			\
    _block.body = (b);			\
    _block.self = self;			\
    _block.frame = *ruby_frame;		\
    _block.klass = ruby_class;		\
    _block.cref = ruby_cref;		\
    _block.frame.node = ruby_current_node;\
    _block.scope = ruby_scope;		\
    _block.prev = ruby_block;		\
    _block.outer = ruby_block;		\
    _block.iter = ruby_iter-&gt;iter;	\
    _block.vmode = scope_vmode;		\
    _block.flags = BLOCK_D_SCOPE;	\
    _block.dyna_vars = ruby_dyna_vars;	\
    _block.wrapper = ruby_wrapper;	\
    _block.block_obj = 0;		\
    _block.uniq = (b)?block_unique++:0; \
    if (b) {				\
	prot_tag-&gt;blkid = _block.uniq;  \
    }                                   \
    ruby_block = &amp;_block

#define POP_BLOCK() \
   ruby_block = _block.prev; \
} while (0)

struct RVarmap *ruby_dyna_vars;
#define PUSH_VARS() do { \
    struct RVarmap * volatile _old; \
    _old = ruby_dyna_vars; \
    ruby_dyna_vars = 0

#define POP_VARS() \
    if (_old &amp;&amp; (ruby_scope-&gt;flags &amp; SCOPE_DONT_RECYCLE)) {\
	if (RBASIC(_old)-&gt;flags) /* unless it's already recycled */ \
	    FL_SET(_old, DVAR_DONT_RECYCLE); \
    }\
    ruby_dyna_vars = _old; \
} while (0)

#define DVAR_DONT_RECYCLE FL_USER2

#define DMETHOD_P() (ruby_frame-&gt;flags &amp; FRAME_DMETH)

static struct RVarmap*
new_dvar(id, value, prev)
    ID id;
    VALUE value;
    struct RVarmap *prev;
{
    NEWOBJ(vars, struct RVarmap);
    OBJSETUP(vars, 0, T_VARMAP);
    vars-&gt;id = id;
    vars-&gt;val = value;
    vars-&gt;next = prev;

    return vars;
}

VALUE
rb_dvar_defined(id)
    ID id;
{
    struct RVarmap *vars = ruby_dyna_vars;

    while (vars) {
	if (vars-&gt;id == id) return Qtrue;
	vars = vars-&gt;next;
    }
    return Qfalse;
}

VALUE
rb_dvar_curr(id)
    ID id;
{
    struct RVarmap *vars = ruby_dyna_vars;

    while (vars) {
	if (vars-&gt;id == 0) break;
	if (vars-&gt;id == id) return Qtrue;
	vars = vars-&gt;next;
    }
    return Qfalse;
}

VALUE
rb_dvar_ref(id)
    ID id;
{
    struct RVarmap *vars = ruby_dyna_vars;

    while (vars) {
	if (vars-&gt;id == id) {
	    return vars-&gt;val;
	}
	vars = vars-&gt;next;
    }
    return Qnil;
}

void
rb_dvar_push(id, value)
    ID id;
    VALUE value;
{
    ruby_dyna_vars = new_dvar(id, value, ruby_dyna_vars);
}

static void
dvar_asgn_internal(id, value, curr)
    ID id;
    VALUE value;
    int curr;
{
    int n = 0;
    struct RVarmap *vars = ruby_dyna_vars;

    while (vars) {
	if (curr &amp;&amp; vars-&gt;id == 0) {
	    /* first null is a dvar header */
	    n++;
	    if (n == 2) break;
	}
	if (vars-&gt;id == id) {
	    vars-&gt;val = value;
	    return;
	}
	vars = vars-&gt;next;
    }
    if (!ruby_dyna_vars) {
	ruby_dyna_vars = new_dvar(id, value, 0);
    }
    else {
	vars = new_dvar(id, value, ruby_dyna_vars-&gt;next);
	ruby_dyna_vars-&gt;next = vars;
    }
}

static inline void
dvar_asgn(id, value)
    ID id;
    VALUE value;
{
    dvar_asgn_internal(id, value, 0);
}

static inline void
dvar_asgn_curr(id, value)
    ID id;
    VALUE value;
{
    dvar_asgn_internal(id, value, 1);
}

VALUE *
rb_svar(cnt)
    int cnt;
{
    struct RVarmap *vars = ruby_dyna_vars;
    ID id;

    if (!ruby_scope-&gt;local_tbl) return NULL;
    if (cnt &gt;= ruby_scope-&gt;local_tbl[0]) return NULL;
    id = ruby_scope-&gt;local_tbl[cnt+1];
    while (vars) {
	if (vars-&gt;id == id) return &amp;vars-&gt;val;
	vars = vars-&gt;next;
    }
    if (ruby_scope-&gt;local_vars == 0) return NULL;
    return &amp;ruby_scope-&gt;local_vars[cnt];
}

struct iter {
    int iter;
    struct iter *prev;
};
static struct iter *ruby_iter;

#define ITER_NOT 0
#define ITER_PRE 1
#define ITER_CUR 2
#define ITER_PAS 3

#define PUSH_ITER(i) do {		\
    struct iter _iter;			\
    _iter.prev = ruby_iter;		\
    _iter.iter = (i);			\
    ruby_iter = &amp;_iter

#define POP_ITER()			\
    ruby_iter = _iter.prev;		\
} while (0)

struct tag {
    rb_jmpbuf_t buf;
    struct FRAME *frame;
    struct iter *iter;
    VALUE tag;
    VALUE retval;
    struct SCOPE *scope;
    VALUE dst;
    struct tag *prev;
    int blkid;
};
static struct tag *prot_tag;

#define PUSH_TAG(ptag) do {		\
    struct tag _tag;			\
    _tag.retval = Qnil;			\
    _tag.frame = ruby_frame;		\
    _tag.iter = ruby_iter;		\
    _tag.prev = prot_tag;		\
    _tag.scope = ruby_scope;		\
    _tag.tag = ptag;			\
    _tag.dst = 0;			\
    _tag.blkid = 0;			\
    prot_tag = &amp;_tag

#define PROT_NONE   Qfalse	/* 0 */
#define PROT_THREAD Qtrue	/* 2 */
#define PROT_FUNC   INT2FIX(0)	/* 1 */
#define PROT_LOOP   INT2FIX(1)	/* 3 */
#define PROT_LAMBDA INT2FIX(2)	/* 5 */
#define PROT_YIELD  INT2FIX(3)	/* 7 */

#define EXEC_TAG()    ruby_setjmp(((void)0), prot_tag-&gt;buf)

#define JUMP_TAG(st) do {		\
    ruby_frame = prot_tag-&gt;frame;	\
    ruby_iter = prot_tag-&gt;iter;		\
    ruby_longjmp(prot_tag-&gt;buf,(st));	\
} while (0)

#define POP_TAG()			\
    prot_tag = _tag.prev;		\
} while (0)

#define TAG_DST() (_tag.dst == (VALUE)ruby_frame-&gt;uniq)

#define TAG_RETURN	0x1
#define TAG_BREAK	0x2
#define TAG_NEXT	0x3
#define TAG_RETRY	0x4
#define TAG_REDO	0x5
#define TAG_RAISE	0x6
#define TAG_THROW	0x7
#define TAG_FATAL	0x8
#define TAG_MASK	0xf

VALUE ruby_class;
static VALUE ruby_wrapper;	/* security wrapper */

#define PUSH_CLASS(c) do {		\
    VALUE _class = ruby_class;		\
    ruby_class = (c)

#define POP_CLASS() ruby_class = _class; \
} while (0)

NODE *ruby_cref = 0;
NODE *ruby_top_cref;
#define PUSH_CREF(c) ruby_cref = NEW_NODE(NODE_CREF,(c),0,ruby_cref)
#define POP_CREF() ruby_cref = ruby_cref-&gt;nd_next

#define PUSH_SCOPE() do {		\
    volatile int _vmode = scope_vmode;	\
    struct SCOPE * volatile _old;	\
    NEWOBJ(_scope, struct SCOPE);	\
    OBJSETUP(_scope, 0, T_SCOPE);	\
    _scope-&gt;local_tbl = 0;		\
    _scope-&gt;local_vars = 0;		\
    _scope-&gt;flags = 0;			\
    _old = ruby_scope;			\
    ruby_scope = _scope;		\
    scope_vmode = SCOPE_PUBLIC

rb_thread_t rb_curr_thread;
rb_thread_t rb_main_thread;
#define main_thread rb_main_thread
#define curr_thread rb_curr_thread

static void scope_dup _((struct SCOPE *));

#define POP_SCOPE() 			\
    if (ruby_scope-&gt;flags &amp; SCOPE_DONT_RECYCLE) {\
	if (_old) scope_dup(_old);	\
    }					\
    if (!(ruby_scope-&gt;flags &amp; SCOPE_MALLOC)) {\
	ruby_scope-&gt;local_vars = 0;	\
	ruby_scope-&gt;local_tbl  = 0;	\
	if (!(ruby_scope-&gt;flags &amp; SCOPE_DONT_RECYCLE) &amp;&amp; \
	    ruby_scope != top_scope) {	\
	    rb_gc_force_recycle((VALUE)ruby_scope);\
	}				\
    }					\
    ruby_scope-&gt;flags |= SCOPE_NOSTACK;	\
    ruby_scope = _old;			\
    scope_vmode = _vmode;		\
} while (0)

static VALUE rb_eval _((VALUE,NODE*));
static VALUE eval _((VALUE,VALUE,VALUE,const char*,int));
static NODE *compile _((VALUE, const char*, int));

static VALUE rb_yield_0 _((VALUE, VALUE, VALUE, int, int));

#define YIELD_LAMBDA_CALL 1
#define YIELD_PROC_CALL   2
#define YIELD_PUBLIC_DEF  4
#define YIELD_FUNC_AVALUE 1
#define YIELD_FUNC_SVALUE 2
#define YIELD_FUNC_LAMBDA 3

static VALUE rb_call _((VALUE,VALUE,ID,int,const VALUE*,int,VALUE));
static VALUE module_setup _((VALUE,NODE*));

static VALUE massign _((VALUE,NODE*,VALUE,int));
static void assign _((VALUE,NODE*,VALUE,int));

typedef struct event_hook {
    rb_event_hook_func_t func;
    rb_event_t events;
    struct event_hook *next;
} rb_event_hook_t;

static rb_event_hook_t *event_hooks;

#define EXEC_EVENT_HOOK(event, node, self, id, klass) \
    do { \
	rb_event_hook_t *hook = event_hooks; \
        rb_event_hook_func_t hook_func; \
        rb_event_t events; \
	\
	while (hook) { \
            hook_func = hook-&gt;func; \
            events = hook-&gt;events; \
            hook = hook-&gt;next; \
	    if (events &amp; event) \
		(*hook_func)(event, node, self, id, klass); \
	} \
    } while (0)

static VALUE trace_func = 0;
static int tracing = 0;
static void call_trace_func _((rb_event_t,NODE*,VALUE,ID,VALUE));

#if 0
#define SET_CURRENT_SOURCE() (ruby_sourcefile = ruby_current_node-&gt;nd_file, \
			      ruby_sourceline = nd_line(ruby_current_node))
#else
#define SET_CURRENT_SOURCE() ((void)0)
#endif

void
ruby_set_current_source()
{
    if (ruby_current_node) {
	ruby_sourcefile = ruby_current_node-&gt;nd_file;
	ruby_sourceline = nd_line(ruby_current_node);
    }
}

static void
#ifdef HAVE_STDARG_PROTOTYPES
warn_printf(const char *fmt, ...)
#else
warn_printf(fmt, va_alist)
    const char *fmt;
    va_dcl
#endif
{
    char buf[BUFSIZ];
    va_list args;

    va_init_list(args, fmt);
    vsnprintf(buf, BUFSIZ, fmt, args);
    va_end(args);
    rb_write_error(buf);
}

#define warn_print(x) rb_write_error(x)
#define warn_print2(x,l) rb_write_error2(x,l)

static void
error_pos()
{
    ruby_set_current_source();
    if (ruby_sourcefile) {
	if (ruby_frame-&gt;last_func) {
	    warn_printf(&quot;%s:%d:in `%s'&quot;, ruby_sourcefile, ruby_sourceline,
			rb_id2name(ruby_frame-&gt;orig_func));
	}
	else if (ruby_sourceline == 0) {
	    warn_printf(&quot;%s&quot;, ruby_sourcefile);
	}
	else {
	    warn_printf(&quot;%s:%d&quot;, ruby_sourcefile, ruby_sourceline);
	}
    }
}

VALUE rb_check_backtrace(VALUE);

static VALUE
get_backtrace(info)
    VALUE info;
{
    if (NIL_P(info)) return Qnil;
    info = rb_funcall(info, rb_intern(&quot;backtrace&quot;), 0);
    if (NIL_P(info)) return Qnil;
    return rb_check_backtrace(info);
}

static void
set_backtrace(info, bt)
    VALUE info, bt;
{
    rb_funcall(info, rb_intern(&quot;set_backtrace&quot;), 1, bt);
}

static void
error_print()
{
    VALUE errat = Qnil;		/* OK */
    volatile VALUE eclass, e;
    const char *einfo;
    long elen;

    if (NIL_P(ruby_errinfo)) return;

    PUSH_TAG(PROT_NONE);
    if (EXEC_TAG() == 0) {
	errat = get_backtrace(ruby_errinfo);
    }
    else {
	errat = Qnil;
    }
    if (EXEC_TAG()) goto error;
    if (NIL_P(errat)){
	ruby_set_current_source();
	if (ruby_sourcefile)
	    warn_printf(&quot;%s:%d&quot;, ruby_sourcefile, ruby_sourceline);
	else
	    warn_printf(&quot;%d&quot;, ruby_sourceline);
    }
    else if (RARRAY(errat)-&gt;len == 0) {
	error_pos();
    }
    else {
	VALUE mesg = RARRAY(errat)-&gt;ptr[0];

	if (NIL_P(mesg)) error_pos();
	else {
	    warn_print2(RSTRING(mesg)-&gt;ptr, RSTRING(mesg)-&gt;len);
	}
    }

    eclass = CLASS_OF(ruby_errinfo);
    if (EXEC_TAG() == 0) {
  	e = rb_funcall(ruby_errinfo, rb_intern(&quot;message&quot;), 0, 0);
 	StringValue(e);
	einfo = RSTRING(e)-&gt;ptr;
	elen = RSTRING(e)-&gt;len;
    }
    else {
	einfo = &quot;&quot;;
	elen = 0;
    }
    if (EXEC_TAG()) goto error;
    if (eclass == rb_eRuntimeError &amp;&amp; elen == 0) {
	warn_print(&quot;: unhandled exception\n&quot;);
    }
    else {
	VALUE epath;

	epath = rb_class_name(eclass);
	if (elen == 0) {
	    warn_print(&quot;: &quot;);
	    warn_print2(RSTRING(epath)-&gt;ptr, RSTRING(epath)-&gt;len);
	    warn_print(&quot;\n&quot;);
	}
	else {
	    char *tail  = 0;
	    long len = elen;

	    if (RSTRING(epath)-&gt;ptr[0] == '#') epath = 0;
	    if ((tail = memchr(einfo, '\n', elen)) != 0) {
		len = tail - einfo;
		tail++;		/* skip newline */
	    }
	    warn_print(&quot;: &quot;);
	    warn_print2(einfo, len);
	    if (epath) {
		warn_print(&quot; (&quot;);
		warn_print2(RSTRING(epath)-&gt;ptr, RSTRING(epath)-&gt;len);
		warn_print(&quot;)\n&quot;);
	    }
	    if (tail &amp;&amp; elen&gt;len+1) {
		warn_print2(tail, elen-len-1);
		if (einfo[elen-1] != '\n') warn_print2(&quot;\n&quot;, 1);
	    }
	}
    }

    if (!NIL_P(errat)) {
	long i;
	struct RArray *ep = RARRAY(errat);
        int truncate = eclass == rb_eSysStackError;

#define TRACE_MAX (TRACE_HEAD+TRACE_TAIL+5)
#define TRACE_HEAD 8
#define TRACE_TAIL 5

	ep = RARRAY(errat);
	for (i=1; i&lt;ep-&gt;len; i++) {
	    if (TYPE(ep-&gt;ptr[i]) == T_STRING) {
		warn_printf(&quot;\tfrom %s\n&quot;, RSTRING(ep-&gt;ptr[i])-&gt;ptr);
	    }
	    if (truncate &amp;&amp; i == TRACE_HEAD &amp;&amp; ep-&gt;len &gt; TRACE_MAX) {
		warn_printf(&quot;\t ... %ld levels...\n&quot;,
			ep-&gt;len - TRACE_HEAD - TRACE_TAIL);
		i = ep-&gt;len - TRACE_TAIL;
	    }
	}
    }
  error:
    POP_TAG();
}

#if defined(__APPLE__)
#define environ (*_NSGetEnviron())
#elif !defined(_WIN32) &amp;&amp; !defined(__MACOS__) || defined(_WIN32_WCE)
extern char **environ;
#endif
char **rb_origenviron;

void rb_call_inits _((void));
void Init_stack _((VALUE*));
void Init_heap _((void));
void Init_ext _((void));

#ifdef HAVE_NATIVETHREAD
static rb_nativethread_t ruby_thid;
int 
is_ruby_native_thread() {
    return NATIVETHREAD_EQUAL(ruby_thid, NATIVETHREAD_CURRENT());
}

# ifdef HAVE_NATIVETHREAD_KILL
void
ruby_native_thread_kill(sig)
    int sig;
{
    NATIVETHREAD_KILL(ruby_thid, sig);
}
# endif
#endif

void
ruby_init()
{
    static int initialized = 0;
    static struct FRAME frame;
    static struct iter iter;
    int state;

    if (initialized)
	return;
    initialized = 1;
#ifdef HAVE_NATIVETHREAD
    ruby_thid = NATIVETHREAD_CURRENT();
#endif

    ruby_frame = top_frame = &amp;frame;
    ruby_iter = &amp;iter;

#ifdef __MACOS__
    rb_origenviron = 0;
#else
    rb_origenviron = environ;
#endif

    Init_stack((void*)&amp;state);
    Init_heap();
    PUSH_SCOPE();
    ruby_scope-&gt;local_vars = 0;
    ruby_scope-&gt;local_tbl  = 0;
    top_scope = ruby_scope;
    /* default visibility is private at toplevel */
    SCOPE_SET(SCOPE_PRIVATE);

    PUSH_TAG(PROT_NONE);
    if ((state = EXEC_TAG()) == 0) {
	rb_call_inits();
	ruby_class = rb_cObject;
	ruby_frame-&gt;self = ruby_top_self;
	ruby_top_cref = rb_node_newnode(NODE_CREF,rb_cObject,0,0);
	ruby_cref = ruby_top_cref;
	rb_define_global_const(&quot;TOPLEVEL_BINDING&quot;, rb_f_binding(ruby_top_self));
#ifdef __MACOS__
	_macruby_init();
#elif defined(__VMS)
	_vmsruby_init();
#endif
	ruby_prog_init();
	ALLOW_INTS;
    }
    POP_TAG();
    if (state) {
	error_print();
	exit(EXIT_FAILURE);
    }
    POP_SCOPE();
    ruby_scope = top_scope;
    top_scope-&gt;flags &amp;= ~SCOPE_NOSTACK;
    ruby_running = 1;
}

static VALUE
eval_node(self, node)
    VALUE self;
    NODE *node;
{
    NODE *beg_tree = ruby_eval_tree_begin;

    ruby_eval_tree_begin = 0;
    if (beg_tree) {
	rb_eval(self, beg_tree);
    }

    if (!node) return Qnil;
    return rb_eval(self, node);
}

int ruby_in_eval;

static void rb_thread_cleanup _((void));
static void rb_thread_wait_other_threads _((void));

static int thread_set_raised();
static int thread_reset_raised();

static int thread_no_ensure _((void));

static VALUE exception_error;
static VALUE sysstack_error;

static int
sysexit_status(err)
    VALUE err;
{
    VALUE st = rb_iv_get(err, &quot;status&quot;);
    return NUM2INT(st);
}

static int
error_handle(ex)
    int ex;
{
    int status = EXIT_FAILURE;

    if (thread_set_raised()) return EXIT_FAILURE;
    switch (ex &amp; TAG_MASK) {
      case 0:
	status = EXIT_SUCCESS;
	break;

      case TAG_RETURN:
	error_pos();
	warn_print(&quot;: unexpected return\n&quot;);
	break;
      case TAG_NEXT:
	error_pos();
	warn_print(&quot;: unexpected next\n&quot;);
	break;
      case TAG_BREAK:
	error_pos();
	warn_print(&quot;: unexpected break\n&quot;);
	break;
      case TAG_REDO:
	error_pos();
	warn_print(&quot;: unexpected redo\n&quot;);
	break;
      case TAG_RETRY:
	error_pos();
	warn_print(&quot;: retry outside of rescue clause\n&quot;);
	break;
      case TAG_THROW:
	if (prot_tag &amp;&amp; prot_tag-&gt;frame &amp;&amp; prot_tag-&gt;frame-&gt;node) {
	    NODE *tag = prot_tag-&gt;frame-&gt;node;
	    warn_printf(&quot;%s:%d: uncaught throw\n&quot;,
		    tag-&gt;nd_file, nd_line(tag));
	}
	else {
	    error_pos();
	    warn_printf(&quot;: unexpected throw\n&quot;);
	}
	break;
      case TAG_RAISE:
      case TAG_FATAL:
	if (rb_obj_is_kind_of(ruby_errinfo, rb_eSystemExit)) {
	    status = sysexit_status(ruby_errinfo);
	}
	else if (rb_obj_is_instance_of(ruby_errinfo, rb_eSignal)) {
	    /* no message when exiting by signal */
	}
	else {
	    error_print();
	}
	break;
      default:
	rb_bug(&quot;Unknown longjmp status %d&quot;, ex);
	break;
    }
    thread_reset_raised();
    return status;
}

void
ruby_options(argc, argv)
    int argc;
    char **argv;
{
    int state;

    Init_stack((void*)&amp;state);
    PUSH_TAG(PROT_NONE);
    if ((state = EXEC_TAG()) == 0) {
	ruby_process_options(argc, argv);
    }
    else {
	trace_func = 0;
	tracing = 0;
	exit(error_handle(state));
    }
    POP_TAG();
}

void rb_exec_end_proc _((void));

static void
ruby_finalize_0()
{
    PUSH_TAG(PROT_NONE);
    if (EXEC_TAG() == 0) {
	rb_trap_exit();
    }
    POP_TAG();
    rb_exec_end_proc();
}

static void
ruby_finalize_1()
{
    signal(SIGINT, SIG_DFL);
    ruby_errinfo = 0;
    rb_gc_call_finalizer_at_exit();
    trace_func = 0;
    tracing = 0;
}

void
ruby_finalize()
{
    ruby_finalize_0();
    ruby_finalize_1();
}

int
ruby_cleanup(ex)
    int ex;
{
    int state;
    volatile VALUE errs[2];
    int nerr;

    errs[1] = ruby_errinfo;
    ruby_safe_level = 0;
    Init_stack((void *)&amp;state);
    ruby_finalize_0();
    errs[0] = ruby_errinfo;
    PUSH_TAG(PROT_NONE);
    PUSH_ITER(ITER_NOT);
    if ((state = EXEC_TAG()) == 0) {
	rb_thread_cleanup();
	rb_thread_wait_other_threads();
    }
    else if (ex == 0) {
	ex = state;
    }
    POP_ITER();
    ruby_errinfo = errs[1];
    ex = error_handle(ex);
    ruby_finalize_1();
    POP_TAG();

    for (nerr = 0; nerr &lt; sizeof(errs) / sizeof(errs[0]); ++nerr) {
	VALUE err = errs[nerr];

	if (!RTEST(err)) continue;

	if (rb_obj_is_kind_of(err, rb_eSystemExit)) {
	    return sysexit_status(err);
	}
	else if (rb_obj_is_kind_of(err, rb_eSignal)) {
	    VALUE sig = rb_iv_get(err, &quot;signo&quot;);
	    ruby_default_signal(NUM2INT(sig));
	}
	else if (ex == 0) {
	    ex = 1;
	}
    }

#if EXIT_SUCCESS != 0 || EXIT_FAILURE != 1
    switch (ex) {
#if EXIT_SUCCESS != 0
      case 0: return EXIT_SUCCESS;
#endif
#if EXIT_FAILURE != 1
      case 1: return EXIT_FAILURE;
#endif
    }
#endif

    return ex;
}

static int
ruby_exec_internal()
{
    int state;

    PUSH_TAG(PROT_NONE);
    PUSH_ITER(ITER_NOT);
    /* default visibility is private at toplevel */
    SCOPE_SET(SCOPE_PRIVATE);
    if ((state = EXEC_TAG()) == 0) {
	eval_node(ruby_top_self, ruby_eval_tree);
    }
    POP_ITER();
    POP_TAG();
    return state;
}

void
ruby_stop(ex)
    int ex;
{
    exit(ruby_cleanup(ex));
}

int
ruby_exec()
{
    volatile NODE *tmp;

    Init_stack((void*)&amp;tmp);
    return ruby_exec_internal();
}

void
ruby_run()
{
    int state;
    static int ex;

    if (ruby_nerrs &gt; 0) exit(EXIT_FAILURE);
    state = ruby_exec();
    if (state &amp;&amp; !ex) ex = state;
    ruby_stop(ex);
}

static void
compile_error(at)
    const char *at;
{
    VALUE str;

    ruby_nerrs = 0;
    str = rb_str_buf_new2(&quot;compile error&quot;);
    if (at) {
	rb_str_buf_cat2(str, &quot; in &quot;);
	rb_str_buf_cat2(str, at);
    }
    rb_str_buf_cat(str, &quot;\n&quot;, 1);
    if (!NIL_P(ruby_errinfo)) {
	rb_str_append(str, rb_obj_as_string(ruby_errinfo));
    }
    rb_exc_raise(rb_exc_new3(rb_eSyntaxError, str));
}

VALUE
rb_eval_string(str)
    const char *str;
{
    VALUE v;
    NODE *oldsrc = ruby_current_node;

    ruby_current_node = 0;
    ruby_sourcefile = rb_source_filename(&quot;(eval)&quot;);
    v = eval(ruby_top_self, rb_str_new2(str), Qnil, 0, 0);
    ruby_current_node = oldsrc;

    return v;
}

VALUE
rb_eval_string_protect(str, state)
    const char *str;
    int *state;
{
    return rb_protect((VALUE (*)_((VALUE)))rb_eval_string, (VALUE)str, state);
}

VALUE
rb_eval_string_wrap(str, state)
    const char *str;
    int *state;
{
    int status;
    VALUE self = ruby_top_self;
    VALUE wrapper = ruby_wrapper;
    VALUE val;

    PUSH_CLASS(ruby_wrapper = rb_module_new());
    ruby_top_self = rb_obj_clone(ruby_top_self);
    rb_extend_object(ruby_top_self, ruby_wrapper);
    PUSH_FRAME();
    ruby_frame-&gt;last_func = 0;
    ruby_frame-&gt;last_class = 0;
    ruby_frame-&gt;self = self;
    PUSH_CREF(ruby_wrapper);
    PUSH_SCOPE();

    val = rb_eval_string_protect(str, &amp;status);
    ruby_top_self = self;

    POP_SCOPE();
    POP_FRAME();
    POP_CLASS();
    ruby_wrapper = wrapper;
    if (state) {
	*state = status;
    }
    else if (status) {
	JUMP_TAG(status);
    }
    return val;
}

NORETURN(static void localjump_error(const char*, VALUE, int));
static void
localjump_error(mesg, value, reason)
    const char *mesg;
    VALUE value;
    int reason;
{
    VALUE exc = rb_exc_new2(rb_eLocalJumpError, mesg);
    ID id;

    rb_iv_set(exc, &quot;@exit_value&quot;, value);
    switch (reason) {
      case TAG_BREAK:
	id = rb_intern(&quot;break&quot;); break;
      case TAG_REDO:
	id = rb_intern(&quot;redo&quot;); break;
      case TAG_RETRY:
	id = rb_intern(&quot;retry&quot;); break;
      case TAG_NEXT:
	id = rb_intern(&quot;next&quot;); break;
      case TAG_RETURN:
	id = rb_intern(&quot;return&quot;); break;
      default:
	id = rb_intern(&quot;noreason&quot;); break;
    }
    rb_iv_set(exc, &quot;@reason&quot;, ID2SYM(id));
    rb_exc_raise(exc);
}

/*
 * call_seq:
 *   local_jump_error.exit_value  =&gt; obj
 *
 * Returns the exit value associated with this +LocalJumpError+.
 */
static VALUE
localjump_xvalue(exc)
    VALUE exc;
{
    return rb_iv_get(exc, &quot;@exit_value&quot;);
}

/*
 * call-seq:
 *    local_jump_error.reason   =&gt; symbol
 *
 * The reason this block was terminated:
 * :break, :redo, :retry, :next, :return, or :noreason.
 */

static VALUE
localjump_reason(exc)
    VALUE exc;
{
    return rb_iv_get(exc, &quot;@reason&quot;);
}

NORETURN(static void jump_tag_but_local_jump _((int,VALUE)));
static void
jump_tag_but_local_jump(state, val)
    int state;
    VALUE val;
{

    if (val == Qundef) val = prot_tag-&gt;retval;
    switch (state) {
      case 0:
	break;
      case TAG_RETURN:
	localjump_error(&quot;unexpected return&quot;, val, state);
	break;
      case TAG_BREAK:
	localjump_error(&quot;unexpected break&quot;, val, state);
	break;
      case TAG_NEXT:
	localjump_error(&quot;unexpected next&quot;, val, state);
	break;
      case TAG_REDO:
	localjump_error(&quot;unexpected redo&quot;, Qnil, state);
	break;
      case TAG_RETRY:
	localjump_error(&quot;retry outside of rescue clause&quot;, Qnil, state);
	break;
      default:
	break;
    }
    JUMP_TAG(state);
}

VALUE
rb_eval_cmd(cmd, arg, level)
    VALUE cmd, arg;
    int level;
{
    int state;
    VALUE val = Qnil;		/* OK */
    struct SCOPE *saved_scope;
    volatile int safe = ruby_safe_level;

    if (OBJ_TAINTED(cmd)) {
	level = 4;
    }
    if (TYPE(cmd) != T_STRING) {
	PUSH_ITER(ITER_NOT);
	PUSH_TAG(PROT_NONE);
	ruby_safe_level = level;
	if ((state = EXEC_TAG()) == 0) {
	    val = rb_funcall2(cmd, rb_intern(&quot;call&quot;), RARRAY(arg)-&gt;len, RARRAY(arg)-&gt;ptr);
	}
	ruby_safe_level = safe;
	POP_TAG();
	POP_ITER();
	if (state) JUMP_TAG(state);
	return val;
    }

    saved_scope = ruby_scope;
    ruby_scope = top_scope;
    PUSH_FRAME();
    ruby_frame-&gt;last_func = 0;
    ruby_frame-&gt;last_class = 0;
    ruby_frame-&gt;self = ruby_top_self;
    PUSH_CREF(ruby_wrapper ? ruby_wrapper : rb_cObject);

    ruby_safe_level = level;

    PUSH_TAG(PROT_NONE);
    if ((state = EXEC_TAG()) == 0) {
	val = eval(ruby_top_self, cmd, Qnil, 0, 0);
    }
    if (ruby_scope-&gt;flags &amp; SCOPE_DONT_RECYCLE)
	scope_dup(saved_scope);
    ruby_scope = saved_scope;
    ruby_safe_level = safe;
    POP_TAG();
    POP_FRAME();

    if (state) jump_tag_but_local_jump(state, val);
    return val;
}

#define ruby_cbase (ruby_cref-&gt;nd_clss)

static VALUE
ev_const_defined(cref, id, self)
    NODE *cref;
    ID id;
    VALUE self;
{
    NODE *cbase = cref;
    VALUE result;

    while (cbase &amp;&amp; cbase-&gt;nd_next) {
	struct RClass *klass = RCLASS(cbase-&gt;nd_clss);

	if (!NIL_P(klass)) {
	    if (klass-&gt;iv_tbl &amp;&amp; st_lookup(klass-&gt;iv_tbl, id, &amp;result)) {
		if (result == Qundef &amp;&amp; NIL_P(rb_autoload_p((VALUE)klass, id))) {
		    return Qfalse;
		}
		return Qtrue;
	    }
	}
	cbase = cbase-&gt;nd_next;
    }
    return rb_const_defined(cref-&gt;nd_clss, id);
}

static VALUE
ev_const_get(cref, id, self)
    NODE *cref;
    ID id;
    VALUE self;
{
    NODE *cbase = cref;
    VALUE result;

    while (cbase &amp;&amp; cbase-&gt;nd_next) {
	VALUE klass = cbase-&gt;nd_clss;

	if (!NIL_P(klass)) {
	    while (RCLASS(klass)-&gt;iv_tbl &amp;&amp;
		   st_lookup(RCLASS(klass)-&gt;iv_tbl, id, &amp;result)) {
		if (result == Qundef) {
		    if (!RTEST(rb_autoload_load(klass, id))) break;
		    continue;
		}
		return result;
	    }
	}
	cbase = cbase-&gt;nd_next;
    }
    return rb_const_get(NIL_P(cref-&gt;nd_clss) ? CLASS_OF(self): cref-&gt;nd_clss, id);
}

static VALUE
cvar_cbase()
{
    NODE *cref = ruby_cref;

    while (cref &amp;&amp; cref-&gt;nd_next &amp;&amp; (NIL_P(cref-&gt;nd_clss) || FL_TEST(cref-&gt;nd_clss, FL_SINGLETON))) {
	cref = cref-&gt;nd_next;
	if (!cref-&gt;nd_next) {
	    rb_warn(&quot;class variable access from toplevel singleton method&quot;);
	}
    }
    if (NIL_P(cref-&gt;nd_clss)) {
	rb_raise(rb_eTypeError, &quot;no class variables available&quot;);
    }
    return cref-&gt;nd_clss;
}

/*
 *  call-seq:
 *     Module.nesting    =&gt; array
 *  
 *  Returns the list of +Modules+ nested at the point of call.
 *     
 *     module M1
 *       module M2
 *         $a = Module.nesting
 *       end
 *     end
 *     $a           #=&gt; [M1::M2, M1]
 *     $a[0].name   #=&gt; &quot;M1::M2&quot;
 */

static VALUE
rb_mod_nesting()
{
    NODE *cbase = ruby_cref;
    VALUE ary = rb_ary_new();

    while (cbase &amp;&amp; cbase-&gt;nd_next) {
	if (!NIL_P(cbase-&gt;nd_clss)) rb_ary_push(ary, cbase-&gt;nd_clss);
	cbase = cbase-&gt;nd_next;
    }
    if (ruby_wrapper &amp;&amp; RARRAY(ary)-&gt;len == 0) {
	rb_ary_push(ary, ruby_wrapper);
    }
    return ary;
}

/*
 *  call-seq:
 *     Module.constants   =&gt; array
 *  
 *  Returns an array of the names of all constants defined in the
 *  system. This list includes the names of all modules and classes.
 *     
 *     p Module.constants.sort[1..5]
 *     
 *  &lt;em&gt;produces:&lt;/em&gt;
 *     
 *     [&quot;ARGV&quot;, &quot;ArgumentError&quot;, &quot;Array&quot;, &quot;Bignum&quot;, &quot;Binding&quot;]
 */

static VALUE
rb_mod_s_constants()
{
    NODE *cbase = ruby_cref;
    void *data = 0;

    while (cbase) {
	if (!NIL_P(cbase-&gt;nd_clss)) {
	    data = rb_mod_const_at(cbase-&gt;nd_clss, data);
	}
	cbase = cbase-&gt;nd_next;
    }

    if (!NIL_P(ruby_cbase)) {
	data = rb_mod_const_of(ruby_cbase, data);
    }
    return rb_const_list(data);
}

void
rb_frozen_class_p(klass)
    VALUE klass;
{
    const char *desc = &quot;something(?!)&quot;;

    if (OBJ_FROZEN(klass)) {
	if (FL_TEST(klass, FL_SINGLETON))
	    desc = &quot;object&quot;;
	else {
	    switch (TYPE(klass)) {
	      case T_MODULE:
	      case T_ICLASS:
		desc = &quot;module&quot;; break;
	      case T_CLASS:
		desc = &quot;class&quot;; break;
	    }
	}
	rb_error_frozen(desc);
    }
}

void
rb_undef(klass, id)
    VALUE klass;
    ID id;
{
    VALUE origin;
    NODE *body;

    if (ruby_cbase == rb_cObject &amp;&amp; klass == rb_cObject) {
	rb_secure(4);
    }
    if (ruby_safe_level &gt;= 4 &amp;&amp; !OBJ_TAINTED(klass)) {
	rb_raise(rb_eSecurityError, &quot;Insecure: can't undef `%s'&quot;, rb_id2name(id));
    }
    rb_frozen_class_p(klass);
    if (id == __id__ || id == __send__ || id == init) {
	rb_warn(&quot;undefining `%s' may cause serious problem&quot;, rb_id2name(id));
    }
    body = search_method(klass, id, &amp;origin);
    if (!body || !body-&gt;nd_body) {
	const char *s0 = &quot; class&quot;;
	VALUE c = klass;

	if (FL_TEST(c, FL_SINGLETON)) {
	    VALUE obj = rb_iv_get(klass, &quot;__attached__&quot;);

	    switch (TYPE(obj)) {
	      case T_MODULE:
	      case T_CLASS:
		c = obj;
		s0 = &quot;&quot;;
	    }
	}
	else if (TYPE(c) == T_MODULE) {
	    s0 = &quot; module&quot;;
	}
	rb_name_error(id, &quot;undefined method `%s' for%s `%s'&quot;,
		      rb_id2name(id),s0,rb_class2name(c));
    }
    rb_add_method(klass, id, 0, NOEX_PUBLIC);
    if (FL_TEST(klass, FL_SINGLETON)) {
	rb_funcall(rb_iv_get(klass, &quot;__attached__&quot;),
		   singleton_undefined, 1, ID2SYM(id));
    }
    else {
	rb_funcall(klass, undefined, 1, ID2SYM(id));
    }
}

/*
 *  call-seq:
 *     undef_method(symbol)    =&gt; self
 *  
 *  Prevents the current class from responding to calls to the named
 *  method. Contrast this with &lt;code&gt;remove_method&lt;/code&gt;, which deletes
 *  the method from the particular class; Ruby will still search
 *  superclasses and mixed-in modules for a possible receiver.
 *     
 *     class Parent
 *       def hello
 *         puts &quot;In parent&quot;
 *       end
 *     end
 *     class Child &lt; Parent
 *       def hello
 *         puts &quot;In child&quot;
 *       end
 *     end
 *     
 *     
 *     c = Child.new
 *     c.hello
 *     
 *     
 *     class Child
 *       remove_method :hello  # remove from child, still in parent
 *     end
 *     c.hello
 *     
 *     
 *     class Child
 *       undef_method :hello   # prevent any calls to 'hello'
 *     end
 *     c.hello
 *     
 *  &lt;em&gt;produces:&lt;/em&gt;
 *     
 *     In child
 *     In parent
 *     prog.rb:23: undefined method `hello' for #&lt;Child:0x401b3bb4&gt; (NoMethodError)
 */

static VALUE
rb_mod_undef_method(argc, argv, mod)
    int argc;
    VALUE *argv;
    VALUE mod;
{
    int i;

    for (i=0; i&lt;argc; i++) {
	rb_undef(mod, rb_to_id(argv[i]));
    }
    return mod;
}

void
rb_alias(klass, name, def)
    VALUE klass;
    ID name, def;
{
    VALUE origin = 0;
    NODE *orig, *body, *node;
    VALUE singleton = 0;
    st_data_t data;

    rb_frozen_class_p(klass);
    if (name == def) return;
    if (klass == rb_cObject) {
	rb_secure(4);
    }
    orig = search_method(klass, def, &amp;origin);
    if (!orig || !orig-&gt;nd_body) {
	if (TYPE(klass) == T_MODULE) {
	    orig = search_method(rb_cObject, def, &amp;origin);
	}
    }
    if (!orig || !orig-&gt;nd_body) {
	print_undef(klass, def);
    }
    if (FL_TEST(klass, FL_SINGLETON)) {
	singleton = rb_iv_get(klass, &quot;__attached__&quot;);
    }
    body = orig-&gt;nd_body;
    orig-&gt;nd_cnt++;
    if (nd_type(body) == NODE_FBODY) { /* was alias */
	def = body-&gt;nd_mid;
	origin = body-&gt;nd_orig;
	body = body-&gt;nd_head;
    }

    rb_clear_cache_by_id(name);
    if (RTEST(ruby_verbose) &amp;&amp; st_lookup(RCLASS(klass)-&gt;m_tbl, name, &amp;data)) {
	node = (NODE *)data;
	if (node-&gt;nd_cnt == 0 &amp;&amp; node-&gt;nd_body) {
	    rb_warning(&quot;discarding old %s&quot;, rb_id2name(name));
	}
    }
    st_insert(RCLASS(klass)-&gt;m_tbl, name,
	      (st_data_t)NEW_METHOD(NEW_FBODY(body, def, origin),
				    NOEX_WITH_SAFE(orig-&gt;nd_noex)));

    if (!ruby_running) return;

    if (singleton) {
	rb_funcall(singleton, singleton_added, 1, ID2SYM(name));
    }
    else {
	rb_funcall(klass, added, 1, ID2SYM(name));
    }
}

/*
 *  call-seq:
 *     alias_method(new_name, old_name)   =&gt; self
 *  
 *  Makes &lt;i&gt;new_name&lt;/i&gt; a new copy of the method &lt;i&gt;old_name&lt;/i&gt;. This can
 *  be used to retain access to methods that are overridden.
 *     
 *     module Mod
 *       alias_method :orig_exit, :exit
 *       def exit(code=0)
 *         puts &quot;Exiting with code #{code}&quot;
 *         orig_exit(code)
 *       end
 *     end
 *     include Mod
 *     exit(99)
 *     
 *  &lt;em&gt;produces:&lt;/em&gt;
 *     
 *     Exiting with code 99
 */

static VALUE
rb_mod_alias_method(mod, newname, oldname)
    VALUE mod, newname, oldname;
{
    rb_alias(mod, rb_to_id(newname), rb_to_id(oldname));
    return mod;
}

NODE *
rb_copy_node_scope(node, rval)
    NODE *node;
    NODE *rval;
{
    NODE *copy = NEW_NODE(NODE_SCOPE,0,rval,node-&gt;nd_next);

    if (node-&gt;nd_tbl) {
	copy-&gt;nd_tbl = ALLOC_N(ID, node-&gt;nd_tbl[0]+1);
	MEMCPY(copy-&gt;nd_tbl, node-&gt;nd_tbl, ID, node-&gt;nd_tbl[0]+1);
    }
    else {
	copy-&gt;nd_tbl = 0;
    }
    return copy;
}

#ifdef C_ALLOCA
# define TMP_PROTECT NODE * volatile tmp__protect_tmp=0
# define TMP_ALLOC(n)							\
    (tmp__protect_tmp = NEW_NODE(NODE_ALLOCA,				\
				 ALLOC_N(VALUE,n),tmp__protect_tmp,n),	\
     (void*)tmp__protect_tmp-&gt;nd_head)
#else
# define TMP_PROTECT typedef int foobazzz
# define TMP_ALLOC(n) ALLOCA_N(VALUE,n)
#endif

#define SETUP_ARGS0(anode,extra) do {\
    NODE *n = anode;\
    if (!n) {\
	argc = 0;\
	argv = 0;\
    }\
    else if (nd_type(n) == NODE_ARRAY) {\
	argc=anode-&gt;nd_alen;\
	if (argc &gt; 0) {\
	    int i;\
	    n = anode;\
	    argv = TMP_ALLOC(argc+extra);\
	    for (i=0;i&lt;argc;i++) {\
		argv[i] = rb_eval(self,n-&gt;nd_head);\
		n=n-&gt;nd_next;\
	    }\
	}\
	else {\
	    argc = 0;\
	    argv = 0;\
	}\
    }\
    else {\
	VALUE args = rb_eval(self,n);\
	if (TYPE(args) != T_ARRAY)\
	    args = rb_ary_to_ary(args);\
	argc = RARRAY(args)-&gt;len;\
	argv = TMP_ALLOC(argc+extra);\
	MEMCPY(argv, RARRAY(args)-&gt;ptr, VALUE, argc);\
    }\
} while (0)

#define SETUP_ARGS(anode) SETUP_ARGS0(anode,0)

#define BEGIN_CALLARGS do {\
    struct BLOCK *tmp_block = ruby_block;\
    int tmp_iter = ruby_iter-&gt;iter;\
    switch (tmp_iter) {\
      case ITER_PRE:\
	if (ruby_block) ruby_block = ruby_block-&gt;outer;\
      case ITER_PAS:\
	tmp_iter = ITER_NOT;\
    }\
    PUSH_ITER(tmp_iter)

#define END_CALLARGS \
    ruby_block = tmp_block;\
    POP_ITER();\
} while (0)

#define MATCH_DATA *rb_svar(node-&gt;nd_cnt)

static const char* is_defined _((VALUE, NODE*, char*));

static const char*
arg_defined(self, node, buf, type)
    VALUE self;
    NODE *node;
    char *buf;
    char *type;
{
    int argc;
    int i;

    if (!node) return type;	/* no args */
    if (nd_type(node) == NODE_ARRAY) {
	argc=node-&gt;nd_alen;
	if (argc &gt; 0) {
	    for (i=0;i&lt;argc;i++) {
		if (!is_defined(self, node-&gt;nd_head, buf))
		    return 0;
		node = node-&gt;nd_next;
	    }
	}
    }
    else if (!is_defined(self, node, buf)) {
	return 0;
    }
    return type;
}

static const char*
is_defined(self, node, buf)
    VALUE self;
    NODE *node;			/* OK */
    char *buf;
{
    VALUE val;			/* OK */
    int state;

  again:
    if (!node) return &quot;expression&quot;;
    switch (nd_type(node)) {
      case NODE_SUPER:
      case NODE_ZSUPER:
	if (ruby_frame-&gt;last_func == 0) return 0;
	else if (ruby_frame-&gt;last_class == 0) return 0;
	val = ruby_frame-&gt;last_class;
	if (rb_method_boundp(RCLASS(val)-&gt;super, ruby_frame-&gt;orig_func, 0)) {
	    if (nd_type(node) == NODE_SUPER) {
		return arg_defined(self, node-&gt;nd_args, buf, &quot;super&quot;);
	    }
	    return &quot;super&quot;;
	}
	break;

      case NODE_VCALL:
      case NODE_FCALL:
	val = self;
	goto check_bound;

      case NODE_ATTRASGN:
	val = self;
	if (node-&gt;nd_recv == (NODE *)1) goto check_bound;
      case NODE_CALL:
	PUSH_TAG(PROT_NONE);
	if ((state = EXEC_TAG()) == 0) {
	    val = rb_eval(self, node-&gt;nd_recv);
	}
	POP_TAG();
	if (state) {
	    ruby_errinfo = Qnil;
	    return 0;
	}
      check_bound:
	{
	    int call = nd_type(node)==NODE_CALL;

	    val = CLASS_OF(val);
	    if (call) {
		int noex;
		ID id = node-&gt;nd_mid;

		if (!rb_get_method_body(&amp;val, &amp;id, &amp;noex))
		    break;
		if ((noex &amp; NOEX_PRIVATE))
		    break;
		if ((noex &amp; NOEX_PROTECTED) &amp;&amp;
		    !rb_obj_is_kind_of(self, rb_class_real(val)))
		    break;
	    }
	    else if (!rb_method_boundp(val, node-&gt;nd_mid, call))
		break;
	    return arg_defined(self, node-&gt;nd_args, buf,
			       nd_type(node) == NODE_ATTRASGN ?
			       &quot;assignment&quot; : &quot;method&quot;);
	}
	break;

      case NODE_MATCH2:
      case NODE_MATCH3:
	return &quot;method&quot;;

      case NODE_YIELD:
	if (rb_block_given_p()) {
	    return &quot;yield&quot;;
	}
	break;

      case NODE_SELF:
	return &quot;self&quot;;

      case NODE_NIL:
	return &quot;nil&quot;;

      case NODE_TRUE:
	return &quot;true&quot;;

      case NODE_FALSE:
	return &quot;false&quot;;

      case NODE_ATTRSET:
      case NODE_OP_ASGN1:
      case NODE_OP_ASGN2:
      case NODE_OP_ASGN_OR:
      case NODE_OP_ASGN_AND:
      case NODE_MASGN:
      case NODE_LASGN:
      case NODE_DASGN:
      case NODE_DASGN_CURR:
      case NODE_GASGN:
      case NODE_IASGN:
      case NODE_CDECL:
      case NODE_CVDECL:
      case NODE_CVASGN:
	return &quot;assignment&quot;;

      case NODE_LVAR:
	return &quot;local-variable&quot;;
      case NODE_DVAR:
	return &quot;local-variable(in-block)&quot;;

      case NODE_GVAR:
	if (rb_gvar_defined(node-&gt;nd_entry)) {
	    return &quot;global-variable&quot;;
	}
	break;

      case NODE_IVAR:
	if (rb_ivar_defined(self, node-&gt;nd_vid)) {
	    return &quot;instance-variable&quot;;
	}
	break;

      case NODE_CONST:
	if (ev_const_defined(ruby_cref, node-&gt;nd_vid, self)) {
	    return &quot;constant&quot;;
	}
	break;

      case NODE_CVAR:
	if (rb_cvar_defined(cvar_cbase(), node-&gt;nd_vid)) {
	    return &quot;class variable&quot;;
	}
	break;

      case NODE_COLON2:
	PUSH_TAG(PROT_NONE);
	if ((state = EXEC_TAG()) == 0) {
	    val = rb_eval(self, node-&gt;nd_head);
	}
	POP_TAG();
	if (state) {
	    ruby_errinfo = Qnil;
	    return 0;
	}
	else {
	    switch (TYPE(val)) {
	      case T_CLASS:
	      case T_MODULE:
		if (rb_const_defined_from(val, node-&gt;nd_mid))
		    return &quot;constant&quot;;
		break;
	      default:
		if (rb_method_boundp(CLASS_OF(val), node-&gt;nd_mid, 1)) {
		    return &quot;method&quot;;
		}
	    }
	}
	break;

      case NODE_COLON3:
	if (rb_const_defined_from(rb_cObject, node-&gt;nd_mid)) {
	    return &quot;constant&quot;;
	}
	break;

      case NODE_NTH_REF:
	if (RTEST(rb_reg_nth_defined(node-&gt;nd_nth, MATCH_DATA))) {
	    sprintf(buf, &quot;$%d&quot;, (int)node-&gt;nd_nth);
	    return buf;
	}
	break;

      case NODE_BACK_REF:
	if (RTEST(rb_reg_nth_defined(0, MATCH_DATA))) {
	    sprintf(buf, &quot;$%c&quot;, (char)node-&gt;nd_nth);
	    return buf;
	}
	break;

      case NODE_NEWLINE:
	node = node-&gt;nd_next;
	goto again;

      default:
	PUSH_TAG(PROT_NONE);
	if ((state = EXEC_TAG()) == 0) {
	    rb_eval(self, node);
	}
	POP_TAG();
	if (!state) {
	    return &quot;expression&quot;;
	}
	ruby_errinfo = Qnil;
	break;
    }
    return 0;
}

static int handle_rescue _((VALUE,NODE*));

static void blk_free();

static VALUE
rb_obj_is_proc(proc)
    VALUE proc;
{
    if (TYPE(proc) == T_DATA &amp;&amp; RDATA(proc)-&gt;dfree == (RUBY_DATA_FUNC)blk_free) {
	return Qtrue;
    }
    return Qfalse;
}

void
rb_add_event_hook(func, events)
    rb_event_hook_func_t func;
    rb_event_t events;
{
    rb_event_hook_t *hook;

    hook = ALLOC(rb_event_hook_t);
    hook-&gt;func = func;
    hook-&gt;events = events;
    hook-&gt;next = event_hooks;
    event_hooks = hook;
}

int
rb_remove_event_hook(func)
    rb_event_hook_func_t func;
{
    rb_event_hook_t *prev, *hook;

    prev = NULL;
    hook = event_hooks;
    while (hook) {
	if (hook-&gt;func == func) {
	    if (prev) {
		prev-&gt;next = hook-&gt;next;
	    }
	    else {
		event_hooks = hook-&gt;next;
	    }
	    xfree(hook);
	    return 0;
	}
	prev = hook;
	hook = hook-&gt;next;
    }
    return -1;
}

/*
 *  call-seq:
 *     set_trace_func(proc)    =&gt; proc
 *     set_trace_func(nil)     =&gt; nil
 *  
 *  Establishes _proc_ as the handler for tracing, or disables
 *  tracing if the parameter is +nil+. _proc_ takes up
 *  to six parameters: an event name, a filename, a line number, an
 *  object id, a binding, and the name of a class. _proc_ is
 *  invoked whenever an event occurs. Events are: &lt;code&gt;c-call&lt;/code&gt;
 *  (call a C-language routine), &lt;code&gt;c-return&lt;/code&gt; (return from a
 *  C-language routine), &lt;code&gt;call&lt;/code&gt; (call a Ruby method),
 *  &lt;code&gt;class&lt;/code&gt; (start a class or module definition),
 *  &lt;code&gt;end&lt;/code&gt; (finish a class or module definition),
 *  &lt;code&gt;line&lt;/code&gt; (execute code on a new line), &lt;code&gt;raise&lt;/code&gt;
 *  (raise an exception), and &lt;code&gt;return&lt;/code&gt; (return from a Ruby
 *  method). Tracing is disabled within the context of _proc_.
 *
 *      class Test
 *	def test
 *	  a = 1
 *	  b = 2
 *	end
 *      end
 *
 *      set_trace_func proc { |event, file, line, id, binding, classname|
 *	   printf &quot;%8s %s:%-2d %10s %8s\n&quot;, event, file, line, id, classname
 *      }
 *      t = Test.new
 *      t.test
 *
 *	  line prog.rb:11               false
 *      c-call prog.rb:11        new    Class
 *      c-call prog.rb:11 initialize   Object
 *    c-return prog.rb:11 initialize   Object
 *    c-return prog.rb:11        new    Class
 *	  line prog.rb:12               false
 *  	  call prog.rb:2        test     Test
 *	  line prog.rb:3        test     Test
 *	  line prog.rb:4        test     Test
 *      return prog.rb:4        test     Test
 */


static VALUE
set_trace_func(obj, trace)
    VALUE obj, trace;
{
    rb_event_hook_t *hook;

    rb_secure(4);
    if (NIL_P(trace)) {
	trace_func = 0;
	rb_remove_event_hook(call_trace_func);
	return Qnil;
    }
    if (!rb_obj_is_proc(trace)) {
	rb_raise(rb_eTypeError, &quot;trace_func needs to be Proc&quot;);
    }
    trace_func = trace;
    for (hook = event_hooks; hook; hook = hook-&gt;next) {
	if (hook-&gt;func == call_trace_func)
	    return trace;
    }
    rb_add_event_hook(call_trace_func, RUBY_EVENT_ALL);
    return trace;
}

static const char *
get_event_name(rb_event_t event)
{
    switch (event) {
      case RUBY_EVENT_LINE:
	return &quot;line&quot;;
      case RUBY_EVENT_CLASS:
	return &quot;class&quot;;
      case RUBY_EVENT_END:
	return &quot;end&quot;;
      case RUBY_EVENT_CALL:
	return &quot;call&quot;;
      case RUBY_EVENT_RETURN:
	return &quot;return&quot;;
      case RUBY_EVENT_C_CALL:
	return &quot;c-call&quot;;
      case RUBY_EVENT_C_RETURN:
	return &quot;c-return&quot;;
      case RUBY_EVENT_RAISE:
	return &quot;raise&quot;;
      default:
	return &quot;unknown&quot;;
    }
}

static void
call_trace_func(event, node, self, id, klass)
    rb_event_t event;
    NODE *node;
    VALUE self;
    ID id;
    VALUE klass;		/* OK */
{
    int state, raised;
    struct FRAME *prev;
    NODE *node_save;
    VALUE srcfile;
    const char *event_name;

    if (!trace_func) return;
    if (tracing) return;
    if (ruby_in_compile) return;
    if (id == ID_ALLOCATOR) return;

    if (!(node_save = ruby_current_node)) {
	node_save = NEW_NEWLINE(0);
    }
    tracing = 1;
    prev = ruby_frame;
    PUSH_FRAME();
    *ruby_frame = *prev;
    ruby_frame-&gt;prev = prev;
    ruby_frame-&gt;iter = 0;	/* blocks not available anyway */

    if (node) {
	ruby_current_node = node;
	ruby_frame-&gt;node = node;
	ruby_sourcefile = node-&gt;nd_file;
	ruby_sourceline = nd_line(node);
    }
    if (klass) {
	if (TYPE(klass) == T_ICLASS) {
	    klass = RBASIC(klass)-&gt;klass;
	}
	else if (FL_TEST(klass, FL_SINGLETON)) {
	    klass = rb_iv_get(klass, &quot;__attached__&quot;);
	}
    }
    PUSH_TAG(PROT_NONE);
    raised = thread_reset_raised();
    if ((state = EXEC_TAG()) == 0) {
	srcfile = rb_str_new2(ruby_sourcefile?ruby_sourcefile:&quot;(ruby)&quot;);
	event_name = get_event_name(event);
	proc_invoke(trace_func, rb_ary_new3(6, rb_str_new2(event_name),
					    srcfile,
					    INT2FIX(ruby_sourceline),
					    id?ID2SYM(id):Qnil,
					    self?rb_f_binding(self):Qnil,
					    klass),
		    Qundef, 0);
    }
    if (raised) thread_set_raised();
    POP_TAG();
    POP_FRAME();

    tracing = 0;
    ruby_current_node = node_save;
    SET_CURRENT_SOURCE();
    if (state) JUMP_TAG(state);
}

static VALUE
avalue_to_svalue(v)
    VALUE v;
{
    VALUE tmp, top;

    tmp = rb_check_array_type(v);
    if (NIL_P(tmp)) {
	return v;
    }
    if (RARRAY(tmp)-&gt;len == 0) {
	return Qundef;
    }
    if (RARRAY(tmp)-&gt;len == 1) {
	top = rb_check_array_type(RARRAY(tmp)-&gt;ptr[0]);
	if (NIL_P(top)) {
	    return RARRAY(tmp)-&gt;ptr[0];
	}
	if (RARRAY(top)-&gt;len &gt; 1) {
	    return v;
	}
	return top;
    }
    return tmp;
}

static VALUE
svalue_to_avalue(v)
    VALUE v;
{
    VALUE tmp, top;

    if (v == Qundef) return rb_ary_new2(0);
    tmp = rb_check_array_type(v);
    if (NIL_P(tmp)) {
	return rb_ary_new3(1, v);
    }
    if (RARRAY(tmp)-&gt;len == 1) {
	top = rb_check_array_type(RARRAY(tmp)-&gt;ptr[0]);
	if (!NIL_P(top) &amp;&amp; RARRAY(top)-&gt;len &gt; 1) {
	    return tmp;
	}
	return rb_ary_new3(1, v);
    }
    return tmp;
}

static VALUE
svalue_to_mrhs(v, lhs)
    VALUE v;
    NODE *lhs;
{
    VALUE tmp;

    if (v == Qundef) return rb_ary_new2(0);
    tmp = rb_check_array_type(v);
    if (NIL_P(tmp)) {
	return rb_ary_new3(1, v);
    }
    /* no lhs means splat lhs only */
    if (!lhs) {
	return rb_ary_new3(1, v);
    }
    return tmp;
}

static VALUE
avalue_splat(v)
    VALUE v;
{
    if (RARRAY(v)-&gt;len == 0) {
	return Qundef;
    }
    if (RARRAY(v)-&gt;len == 1) {
	return RARRAY(v)-&gt;ptr[0];
    }
    return v;
}

#if 1
VALUE
rb_Array(val)
    VALUE val;
{
    VALUE tmp = rb_check_array_type(val);

    if (NIL_P(tmp)) {
	/* hack to avoid invoke Object#to_a */
	VALUE origin;
	ID id = rb_intern(&quot;to_a&quot;);

	if (search_method(CLASS_OF(val), id, &amp;origin) &amp;&amp;
	    RCLASS(origin)-&gt;m_tbl != RCLASS(rb_mKernel)-&gt;m_tbl) { /* exclude Kernel#to_a */
	    val = rb_funcall(val, id, 0);
	    if (TYPE(val) != T_ARRAY) {
		rb_raise(rb_eTypeError, &quot;`to_a' did not return Array&quot;);
	    }
	    return val;
	}
	else {
	    return rb_ary_new3(1, val);
	}
    }
    return tmp;
}
#endif

static VALUE
splat_value(v)
    VALUE v;
{
    if (NIL_P(v)) return rb_ary_new3(1, Qnil);
    return rb_Array(v);
}

static VALUE
class_prefix(self, cpath)
    VALUE self;
    NODE *cpath;
{
    if (!cpath) {
	rb_bug(&quot;class path missing&quot;);
    }
    if (cpath-&gt;nd_head) {
	VALUE c = rb_eval(self, cpath-&gt;nd_head);
	switch (TYPE(c)) {
	  case T_CLASS:
	  case T_MODULE:
	    break;
	  default:
	    rb_raise(rb_eTypeError, &quot;%s is not a class/module&quot;,
		     RSTRING(rb_obj_as_string(c))-&gt;ptr);
	}
	return c;
    }
    else if (nd_type(cpath) == NODE_COLON2) {
	return ruby_cbase;
    }
    else if (ruby_wrapper) {
	return ruby_wrapper;
    }
    else {
	return rb_cObject;
    }
}

#define return_value(v) do {\
  if ((prot_tag-&gt;retval = (v)) == Qundef) {\
    prot_tag-&gt;retval = Qnil;\
  }\
} while (0)

NORETURN(static void return_jump _((VALUE)));
NORETURN(static void break_jump _((VALUE)));
NORETURN(static void next_jump _((VALUE)));
NORETURN(static void unknown_node _((NODE * volatile)));

static void
unknown_node(node)
    NODE *volatile node;
{
    ruby_current_node = 0;
    if (node-&gt;flags == 0) {
        rb_bug(&quot;terminated node (0x%lx)&quot;, node);
    }
    else if (BUILTIN_TYPE(node) != T_NODE) {
        rb_bug(&quot;not a node 0x%02lx (0x%lx)&quot;, BUILTIN_TYPE(node), node);
    }
    else {
        rb_bug(&quot;unknown node type %d (0x%lx)&quot;, nd_type(node), node);
    }
}

static VALUE
rb_eval(self, n)
    VALUE self;
    NODE *n;
{
    NODE * volatile contnode = 0;
    NODE * volatile node = n;
    int state;
    volatile VALUE result = Qnil;
    st_data_t data;

#define RETURN(v) do { \
    result = (v); \
    goto finish; \
} while (0)

  again:
    if (!node) RETURN(Qnil);

    ruby_current_node = node;
    switch (nd_type(node)) {
      case NODE_BLOCK:
	if (contnode) {
	    result = rb_eval(self, node);
	    break;
	}
	contnode = node-&gt;nd_next;
	node = node-&gt;nd_head;
	goto again;

      case NODE_POSTEXE:
	rb_f_END();
	nd_set_type(node, NODE_NIL); /* exec just once */
	result = Qnil;
	break;

	/* begin .. end without clauses */
      case NODE_BEGIN:
	node = node-&gt;nd_body;
	goto again;

	/* nodes for speed-up(default match) */
      case NODE_MATCH:
	result = rb_reg_match2(node-&gt;nd_lit);
	break;

	/* nodes for speed-up(literal match) */
      case NODE_MATCH2:
	{
	    VALUE l = rb_eval(self,node-&gt;nd_recv);
	    VALUE r = rb_eval(self,node-&gt;nd_value);
	    result = rb_reg_match(l, r);
	}
	break;

	/* nodes for speed-up(literal match) */
      case NODE_MATCH3:
	{
	    VALUE r = rb_eval(self,node-&gt;nd_recv);
	    VALUE l = rb_eval(self,node-&gt;nd_value);
	    if (TYPE(l) == T_STRING) {
		result = rb_reg_match(r, l);
	    }
	    else {
		result = rb_funcall(l, match, 1, r);
	    }
	}
	break;

	/* node for speed-up(top-level loop for -n/-p) */
      case NODE_OPT_N:
	PUSH_TAG(PROT_LOOP);
	switch (state = EXEC_TAG()) {
	  case 0:
	  opt_n_next:
	    while (!NIL_P(rb_gets())) {
	      opt_n_redo:
		rb_eval(self, node-&gt;nd_body);
	    }
	    break;

	  case TAG_REDO:
	    state = 0;
	    goto opt_n_redo;
	  case TAG_NEXT:
	    state = 0;
	    goto opt_n_next;
	  case TAG_BREAK:
	    state = 0;
	  default:
	    break;
	}
	POP_TAG();
	if (state) JUMP_TAG(state);
	RETURN(Qnil);

      case NODE_SELF:
	RETURN(self);

      case NODE_NIL:
	RETURN(Qnil);

      case NODE_TRUE:
	RETURN(Qtrue);

      case NODE_FALSE:
	RETURN(Qfalse);

      case NODE_IF:
	if (RTEST(rb_eval(self, node-&gt;nd_cond))) {
	    EXEC_EVENT_HOOK(RUBY_EVENT_LINE, node, self,
			    ruby_frame-&gt;last_func,
			    ruby_frame-&gt;last_class);
	    node = node-&gt;nd_body;
	}
	else {
	    EXEC_EVENT_HOOK(RUBY_EVENT_LINE, node, self,
			    ruby_frame-&gt;last_func,
			    ruby_frame-&gt;last_class);
	    node = node-&gt;nd_else;
	}
	goto again;

      case NODE_WHEN:
	while (node) {
	    NODE *tag;

	    if (nd_type(node) != NODE_WHEN) goto again;
	    tag = node-&gt;nd_head;
	    while (tag) {
		EXEC_EVENT_HOOK(RUBY_EVENT_LINE, tag, self,
				ruby_frame-&gt;last_func,
				ruby_frame-&gt;last_class);
		if (tag-&gt;nd_head &amp;&amp; nd_type(tag-&gt;nd_head) == NODE_WHEN) {
		    VALUE v = rb_eval(self, tag-&gt;nd_head-&gt;nd_head);
		    long i;

		    if (TYPE(v) != T_ARRAY) v = rb_ary_to_ary(v);
		    for (i=0; i&lt;RARRAY(v)-&gt;len; i++) {
			if (RTEST(RARRAY(v)-&gt;ptr[i])) {
			    node = node-&gt;nd_body;
			    goto again;
			}
		    }
		    tag = tag-&gt;nd_next;
		    continue;
		}
		if (RTEST(rb_eval(self, tag-&gt;nd_head))) {
		    node = node-&gt;nd_body;
		    goto again;
		}
		tag = tag-&gt;nd_next;
	    }
	    node = node-&gt;nd_next;
	}
	RETURN(Qnil);

      case NODE_CASE:
	{
	    VALUE val;

	    val = rb_eval(self, node-&gt;nd_head);
	    node = node-&gt;nd_body;
	    while (node) {
		NODE *tag;

		if (nd_type(node) != NODE_WHEN) {
		    goto again;
		}
		tag = node-&gt;nd_head;
		while (tag) {
		    EXEC_EVENT_HOOK(RUBY_EVENT_LINE, tag, self,
				    ruby_frame-&gt;last_func,
				    ruby_frame-&gt;last_class);
		    if (tag-&gt;nd_head &amp;&amp; nd_type(tag-&gt;nd_head) == NODE_WHEN) {
			VALUE v = rb_eval(self, tag-&gt;nd_head-&gt;nd_head);
			long i;

			if (TYPE(v) != T_ARRAY) v = rb_ary_to_ary(v);
			for (i=0; i&lt;RARRAY(v)-&gt;len; i++) {
			    if (RTEST(rb_funcall2(RARRAY(v)-&gt;ptr[i], eqq, 1, &amp;val))){
				node = node-&gt;nd_body;
				goto again;
			    }
			}
			tag = tag-&gt;nd_next;
			continue;
		    }
		    if (RTEST(rb_funcall2(rb_eval(self, tag-&gt;nd_head), eqq, 1, &amp;val))) {
			node = node-&gt;nd_body;
			goto again;
		    }
		    tag = tag-&gt;nd_next;
		}
		node = node-&gt;nd_next;
	    }
	}
	RETURN(Qnil);

      case NODE_WHILE:
	PUSH_TAG(PROT_LOOP);
	result = Qnil;
	switch (state = EXEC_TAG()) {
	  case 0:
	    if (node-&gt;nd_state &amp;&amp; !RTEST(rb_eval(self, node-&gt;nd_cond)))
		goto while_out;
	    do {
	      while_redo:
		rb_eval(self, node-&gt;nd_body);
	      while_next:
		;
	    } while (RTEST(rb_eval(self, node-&gt;nd_cond)));
	    break;

	  case TAG_REDO:
	    state = 0;
	    goto while_redo;
	  case TAG_NEXT:
	    state = 0;
	    goto while_next;
	  case TAG_BREAK:
	    if (TAG_DST()) {
		state = 0;
		result = prot_tag-&gt;retval;
	    }
	    /* fall through */
	  default:
	    break;
	}
      while_out:
	POP_TAG();
	if (state) JUMP_TAG(state);
	RETURN(result);

      case NODE_UNTIL:
	PUSH_TAG(PROT_LOOP);
	result = Qnil;
	switch (state = EXEC_TAG()) {
	  case 0:
	    if (node-&gt;nd_state &amp;&amp; RTEST(rb_eval(self, node-&gt;nd_cond)))
		goto until_out;
	    do {
	      until_redo:
		rb_eval(self, node-&gt;nd_body);
	      until_next:
		;
	    } while (!RTEST(rb_eval(self, node-&gt;nd_cond)));
	    break;

	  case TAG_REDO:
	    state = 0;
	    goto until_redo;
	  case TAG_NEXT:
	    state = 0;
	    goto until_next;
	  case TAG_BREAK:
	    if (TAG_DST()) {
		state = 0;
		result = prot_tag-&gt;retval;
	    }
	    /* fall through */
	  default:
	    break;
	}
      until_out:
	POP_TAG();
	if (state) JUMP_TAG(state);
	RETURN(result);

      case NODE_BLOCK_PASS:
	result = block_pass(self, node);
	break;

      case NODE_ITER:
      case NODE_FOR:
	{
	    PUSH_TAG(PROT_LOOP);
	    PUSH_BLOCK(node-&gt;nd_var, node-&gt;nd_body);

	    state = EXEC_TAG();
	    if (state == 0) {
	      iter_retry:
		PUSH_ITER(ITER_PRE);
		if (nd_type(node) == NODE_ITER) {
		    result = rb_eval(self, node-&gt;nd_iter);
		}
		else {
		    VALUE recv;

		    _block.flags &amp;= ~BLOCK_D_SCOPE;
		    BEGIN_CALLARGS;
		    recv = rb_eval(self, node-&gt;nd_iter);
		    END_CALLARGS;
		    ruby_current_node = node;
		    SET_CURRENT_SOURCE();
		    result = rb_call(CLASS_OF(recv),recv,each,0,0,0,self);
		}
		POP_ITER();
	    }
	    else if (state == TAG_BREAK &amp;&amp; TAG_DST()) {
		result = prot_tag-&gt;retval;
		state = 0;
	    }
	    else if (state == TAG_RETRY) {
		state = 0;
		goto iter_retry;
	    }
	    POP_BLOCK();
	    POP_TAG();
	    switch (state) {
	      case 0:
		break;
	      default:
		JUMP_TAG(state);
	    }
	}
	break;

      case NODE_BREAK:
	break_jump(rb_eval(self, node-&gt;nd_stts));
	break;

      case NODE_NEXT:
	CHECK_INTS;
	next_jump(rb_eval(self, node-&gt;nd_stts));
	break;

      case NODE_REDO:
	CHECK_INTS;
	JUMP_TAG(TAG_REDO);
	break;

      case NODE_RETRY:
	CHECK_INTS;
	JUMP_TAG(TAG_RETRY);
	break;

      case NODE_SPLAT:
	result = splat_value(rb_eval(self, node-&gt;nd_head));
	break;

      case NODE_TO_ARY:
	result = rb_ary_to_ary(rb_eval(self, node-&gt;nd_head));
	break;

      case NODE_SVALUE:
	result = avalue_splat(rb_eval(self, node-&gt;nd_head));
	if (result == Qundef) result = Qnil;
	break;

      case NODE_YIELD:
	if (node-&gt;nd_head) {
	    result = rb_eval(self, node-&gt;nd_head);
	    ruby_current_node = node;
	}
	else {
	    result = Qundef;	/* no arg */
	}
	SET_CURRENT_SOURCE();
	result = rb_yield_0(result, 0, 0, 0, node-&gt;nd_state);
	break;

      case NODE_RESCUE:
	{
	    volatile VALUE e_info = ruby_errinfo;
	    volatile int rescuing = 0;

	    PUSH_TAG(PROT_NONE);
	    if ((state = EXEC_TAG()) == 0) {
	      retry_entry:
		result = rb_eval(self, node-&gt;nd_head);
	    }
	    else if (rescuing) {
		if (rescuing &lt; 0) {
		    /* in rescue argument, just reraise */
		}
		else if (state == TAG_RETRY) {
		    rescuing = state = 0;
		    ruby_errinfo = e_info;
		    goto retry_entry;
		}
		else if (state != TAG_RAISE) {
		    result = prot_tag-&gt;retval;
		}
	    }
	    else if (state == TAG_RAISE) {
		NODE *resq = node-&gt;nd_resq;

		rescuing = -1;
		while (resq) {
		    ruby_current_node = resq;
		    if (handle_rescue(self, resq)) {
			state = 0;
			rescuing = 1;
			result = rb_eval(self, resq-&gt;nd_body);
			break;
		    }
		    resq = resq-&gt;nd_head; /* next rescue */
		}
	    }
	    else {
		result = prot_tag-&gt;retval;
	    }
	    POP_TAG();
	    if (state != TAG_RAISE) ruby_errinfo = e_info;
	    if (state) {
		JUMP_TAG(state);
	    }
	    /* no exception raised */
	    if (!rescuing &amp;&amp; (node = node-&gt;nd_else)) { /* else clause given */
		goto again;
	    }
	}
	break;

      case NODE_ENSURE:
	PUSH_TAG(PROT_NONE);
	if ((state = EXEC_TAG()) == 0) {
	    result = rb_eval(self, node-&gt;nd_head);
	}
	POP_TAG();
	if (node-&gt;nd_ensr &amp;&amp; !thread_no_ensure()) {
	    VALUE retval = prot_tag-&gt;retval; /* save retval */
	    VALUE errinfo = ruby_errinfo;

	    rb_eval(self, node-&gt;nd_ensr);
	    return_value(retval);
	    ruby_errinfo = errinfo;
	}
	if (state) JUMP_TAG(state);
	break;

      case NODE_AND:
	result = rb_eval(self, node-&gt;nd_1st);
	if (!RTEST(result)) break;
	node = node-&gt;nd_2nd;
	goto again;

      case NODE_OR:
	result = rb_eval(self, node-&gt;nd_1st);
	if (RTEST(result)) break;
	node = node-&gt;nd_2nd;
	goto again;

      case NODE_NOT:
	if (RTEST(rb_eval(self, node-&gt;nd_body))) result = Qfalse;
	else result = Qtrue;
	break;

      case NODE_DOT2:
      case NODE_DOT3:
        {
	    VALUE beg = rb_eval(self, node-&gt;nd_beg);
	    VALUE end = rb_eval(self, node-&gt;nd_end);
	    result = rb_range_new(beg, end, nd_type(node) == NODE_DOT3);
	}	
	break;

      case NODE_FLIP2:		/* like AWK */
	{
	    VALUE *flip = rb_svar(node-&gt;nd_cnt);
	    if (!flip) rb_bug(&quot;unexpected local variable&quot;);
	    if (!RTEST(*flip)) {
		if (RTEST(rb_eval(self, node-&gt;nd_beg))) {
		    *flip = RTEST(rb_eval(self, node-&gt;nd_end))?Qfalse:Qtrue;
		    result = Qtrue;
		}
		else {
		    result = Qfalse;
		}
	    }
	    else {
		if (RTEST(rb_eval(self, node-&gt;nd_end))) {
		    *flip = Qfalse;
		}
		result = Qtrue;
	    }
	}
	break;

      case NODE_FLIP3:		/* like SED */
	{
	    VALUE *flip = rb_svar(node-&gt;nd_cnt);
	    if (!flip) rb_bug(&quot;unexpected local variable&quot;);
	    if (!RTEST(*flip)) {
		result = RTEST(rb_eval(self, node-&gt;nd_beg)) ? Qtrue : Qfalse;
		*flip = result;
	    }
	    else {
		if (RTEST(rb_eval(self, node-&gt;nd_end))) {
		    *flip = Qfalse;
		}
		result = Qtrue;
	    }
	}
	break;

      case NODE_RETURN:
	return_jump(rb_eval(self, node-&gt;nd_stts));
	break;

      case NODE_ARGSCAT:
	{
	    VALUE args = rb_eval(self, node-&gt;nd_head);
	    result = rb_ary_concat(args, splat_value(rb_eval(self, node-&gt;nd_body)));
	}
	break;

      case NODE_ARGSPUSH:
	{
	    VALUE args = rb_ary_dup(rb_eval(self, node-&gt;nd_head));
	    result = rb_ary_push(args, rb_eval(self, node-&gt;nd_body));
	}
	break;

      case NODE_ATTRASGN:
	{
	    VALUE recv;
	    int argc; VALUE *argv; /* used in SETUP_ARGS */
	    int scope;
	    TMP_PROTECT;

	    BEGIN_CALLARGS;
	    if (node-&gt;nd_recv == (NODE *)1) {
		recv = self;
		scope = 1;
	    }
	    else {
		recv = rb_eval(self, node-&gt;nd_recv);
		scope = 0;
	    }
	    SETUP_ARGS(node-&gt;nd_args);
	    END_CALLARGS;

	    ruby_current_node = node;
	    SET_CURRENT_SOURCE();
	    rb_call(CLASS_OF(recv),recv,node-&gt;nd_mid,argc,argv,scope,self);
	    result = argv[argc-1];
	}
	break;

      case NODE_CALL:
	{
	    VALUE recv;
	    int argc; VALUE *argv; /* used in SETUP_ARGS */
	    TMP_PROTECT;

	    BEGIN_CALLARGS;
	    recv = rb_eval(self, node-&gt;nd_recv);
	    SETUP_ARGS(node-&gt;nd_args);
	    END_CALLARGS;

	    ruby_current_node = node;
	    SET_CURRENT_SOURCE();
	    result = rb_call(CLASS_OF(recv),recv,node-&gt;nd_mid,argc,argv,0,self);
	}
	break;

      case NODE_FCALL:
	{
	    int argc; VALUE *argv; /* used in SETUP_ARGS */
	    TMP_PROTECT;

	    BEGIN_CALLARGS;
	    SETUP_ARGS(node-&gt;nd_args);
	    END_CALLARGS;

	    ruby_current_node = node;
	    SET_CURRENT_SOURCE();
	    result = rb_call(CLASS_OF(self),self,node-&gt;nd_mid,argc,argv,1,self);
	}
	break;

      case NODE_VCALL:
	SET_CURRENT_SOURCE();
	result = rb_call(CLASS_OF(self),self,node-&gt;nd_mid,0,0,2,self);
	break;

      case NODE_SUPER:
      case NODE_ZSUPER:
	{
	    int argc; VALUE *argv; /* used in SETUP_ARGS */
	    TMP_PROTECT;

	    if (ruby_frame-&gt;last_class == 0) {
		if (ruby_frame-&gt;last_func) {
		    rb_name_error(ruby_frame-&gt;last_func,
				  &quot;superclass method `%s' disabled&quot;,
				  rb_id2name(ruby_frame-&gt;orig_func));
		}
		else {
		    rb_raise(rb_eNoMethodError, &quot;super called outside of method&quot;);
		}
	    }
	    if (nd_type(node) == NODE_ZSUPER) {
		argc = ruby_frame-&gt;argc;
		if (argc &amp;&amp; DMETHOD_P()) {
		    if (TYPE(RBASIC(ruby_scope)-&gt;klass) != T_ARRAY ||
			RARRAY(RBASIC(ruby_scope)-&gt;klass)-&gt;len != argc) {
			rb_raise(rb_eRuntimeError, 
				 &quot;super: specify arguments explicitly&quot;);
		    }
		    argv = RARRAY(RBASIC(ruby_scope)-&gt;klass)-&gt;ptr;
		}
		else if (!ruby_scope-&gt;local_vars) {
		    argc = 0;
		    argv = 0;
		}
		else {
		    argv = ruby_scope-&gt;local_vars + 2;
		}
	    }
	    else {
		BEGIN_CALLARGS;
		SETUP_ARGS(node-&gt;nd_args);
		END_CALLARGS;
		ruby_current_node = node;
	    }

	    SET_CURRENT_SOURCE();
	    result = rb_call_super(argc, argv);
	}
	break;

      case NODE_SCOPE:
	{
	    struct FRAME frame;
	    NODE *saved_cref = 0;

	    frame = *ruby_frame;
	    frame.tmp = ruby_frame;
	    ruby_frame = &amp;frame;

	    PUSH_SCOPE();
	    PUSH_TAG(PROT_NONE);
	    if (node-&gt;nd_rval) {
		saved_cref = ruby_cref;
		ruby_cref = (NODE*)node-&gt;nd_rval;
	    }
	    if (node-&gt;nd_tbl) {
		VALUE *vars = ALLOCA_N(VALUE, node-&gt;nd_tbl[0]+1);
		*vars++ = (VALUE)node;
		ruby_scope-&gt;local_vars = vars;
		rb_mem_clear(ruby_scope-&gt;local_vars, node-&gt;nd_tbl[0]);
		ruby_scope-&gt;local_tbl = node-&gt;nd_tbl;
	    }
	    else {
		ruby_scope-&gt;local_vars = 0;
		ruby_scope-&gt;local_tbl  = 0;
	    }
	    if ((state = EXEC_TAG()) == 0) {
		result = rb_eval(self, node-&gt;nd_next);
	    }
	    POP_TAG();
	    POP_SCOPE();
	    ruby_frame = frame.tmp;
	    if (saved_cref)
		ruby_cref = saved_cref;
	    if (state) JUMP_TAG(state);
	}
	break;

      case NODE_OP_ASGN1:
	{
	    int argc; VALUE *argv; /* used in SETUP_ARGS */
	    VALUE recv, val, tmp;
	    NODE *rval;
	    TMP_PROTECT;

	    recv = rb_eval(self, node-&gt;nd_recv);
	    rval = node-&gt;nd_args-&gt;nd_head;
	    SETUP_ARGS0(node-&gt;nd_args-&gt;nd_body, 1);
	    val = rb_funcall3(recv, aref, argc, argv);
	    switch (node-&gt;nd_mid) {
	    case 0: /* OR */
	      if (RTEST(val)) RETURN(val);
	      val = rb_eval(self, rval);
	      break;
	    case 1: /* AND */
	      if (!RTEST(val)) RETURN(val);
	      val = rb_eval(self, rval);
	      break;
	    default:
	      tmp = rb_eval(self, rval);
	      val = rb_funcall3(val, node-&gt;nd_mid, 1, &amp;tmp);
	    }
	    argv[argc] = val;
	    rb_funcall2(recv, aset, argc+1, argv);
	    result = val;
	}
	break;

      case NODE_OP_ASGN2:
	{
	    ID id = node-&gt;nd_next-&gt;nd_vid;
	    VALUE recv, val, tmp;

	    recv = rb_eval(self, node-&gt;nd_recv);
	    val = rb_funcall3(recv, id, 0, 0);
	    switch (node-&gt;nd_next-&gt;nd_mid) {
	    case 0: /* OR */
	      if (RTEST(val)) RETURN(val);
	      val = rb_eval(self, node-&gt;nd_value);
	      break;
	    case 1: /* AND */
	      if (!RTEST(val)) RETURN(val);
	      val = rb_eval(self, node-&gt;nd_value);
	      break;
	    default:
	      tmp = rb_eval(self, node-&gt;nd_value);
	      val = rb_funcall3(val, node-&gt;nd_next-&gt;nd_mid, 1, &amp;tmp);
	    }

	    rb_funcall2(recv, node-&gt;nd_next-&gt;nd_aid, 1, &amp;val);
	    result = val;
	}
	break;

      case NODE_OP_ASGN_AND:
	result = rb_eval(self, node-&gt;nd_head);
	if (!RTEST(result)) break;
	node = node-&gt;nd_value;
	goto again;

      case NODE_OP_ASGN_OR:
	if ((node-&gt;nd_aid &amp;&amp; !is_defined(self, node-&gt;nd_head, 0)) ||
	    !RTEST(result = rb_eval(self, node-&gt;nd_head))) {
	    node = node-&gt;nd_value;
	    goto again;
	}
	break;

      case NODE_MASGN:
	result = massign(self, node, rb_eval(self, node-&gt;nd_value), 0);
	break;

      case NODE_LASGN:
	if (ruby_scope-&gt;local_vars == 0)
	    rb_bug(&quot;unexpected local variable assignment&quot;);
	result = rb_eval(self, node-&gt;nd_value);
	ruby_scope-&gt;local_vars[node-&gt;nd_cnt] = result;
	break;

      case NODE_DASGN:
	result = rb_eval(self, node-&gt;nd_value);
	dvar_asgn(node-&gt;nd_vid, result);
	break;

      case NODE_DASGN_CURR:
	result = rb_eval(self, node-&gt;nd_value);
	dvar_asgn_curr(node-&gt;nd_vid, result);
	break;

      case NODE_GASGN:
	result = rb_eval(self, node-&gt;nd_value);
	rb_gvar_set(node-&gt;nd_entry, result);
	break;

      case NODE_IASGN:
	result = rb_eval(self, node-&gt;nd_value);
	rb_ivar_set(self, node-&gt;nd_vid, result);
	break;

      case NODE_CDECL:
	result = rb_eval(self, node-&gt;nd_value);
	if (node-&gt;nd_vid == 0) {
	    rb_const_set(class_prefix(self, node-&gt;nd_else), node-&gt;nd_else-&gt;nd_mid, result);
	}
	else {
	    rb_const_set(ruby_cbase, node-&gt;nd_vid, result);
	}
	break;

      case NODE_CVDECL:
	if (NIL_P(ruby_cbase)) {
	    rb_raise(rb_eTypeError, &quot;no class/module to define class variable&quot;);
	}
	result = rb_eval(self, node-&gt;nd_value);
	rb_cvar_set(cvar_cbase(), node-&gt;nd_vid, result, Qtrue);
	break;

      case NODE_CVASGN:
	result = rb_eval(self, node-&gt;nd_value);
	rb_cvar_set(cvar_cbase(), node-&gt;nd_vid, result, Qfalse);
	break;

      case NODE_LVAR:
	if (ruby_scope-&gt;local_vars == 0) {
	    rb_bug(&quot;unexpected local variable&quot;);
	}
	result = ruby_scope-&gt;local_vars[node-&gt;nd_cnt];
	break;

      case NODE_DVAR:
	result = rb_dvar_ref(node-&gt;nd_vid);
	break;

      case NODE_GVAR:
	result = rb_gvar_get(node-&gt;nd_entry);
	break;

      case NODE_IVAR:
	result = rb_ivar_get(self, node-&gt;nd_vid);
	break;

      case NODE_CONST:
	result = ev_const_get(ruby_cref, node-&gt;nd_vid, self);
	break;

      case NODE_CVAR:
	result = rb_cvar_get(cvar_cbase(), node-&gt;nd_vid);
	break;

      case NODE_BLOCK_ARG:
	if (ruby_scope-&gt;local_vars == 0)
	    rb_bug(&quot;unexpected block argument&quot;);
	if (rb_block_given_p()) {
	    result = rb_block_proc();
	    ruby_scope-&gt;local_vars[node-&gt;nd_cnt] = result;
	}
	else {
	    result = Qnil;
	}
	break;

      case NODE_COLON2:
	{
	    VALUE klass;

	    klass = rb_eval(self, node-&gt;nd_head);
	    if (rb_is_const_id(node-&gt;nd_mid)) {
		switch (TYPE(klass)) {
		  case T_CLASS:
		  case T_MODULE:
		    result = rb_const_get_from(klass, node-&gt;nd_mid);
		    break;
		  default:
		    rb_raise(rb_eTypeError, &quot;%s is not a class/module&quot;,
			     RSTRING(rb_obj_as_string(klass))-&gt;ptr);
		    break;
		}
	    }
	    else {
		result = rb_funcall(klass, node-&gt;nd_mid, 0, 0);
	    }
	}
	break;

      case NODE_COLON3:
	result = rb_const_get_from(rb_cObject, node-&gt;nd_mid);
	break;

      case NODE_NTH_REF:
	result = rb_reg_nth_match(node-&gt;nd_nth, MATCH_DATA);
	break;

      case NODE_BACK_REF:
	switch (node-&gt;nd_nth) {
	  case '&amp;':
	    result = rb_reg_last_match(MATCH_DATA);
	    break;
	  case '`':
	    result = rb_reg_match_pre(MATCH_DATA);
	    break;
	  case '\'':
	    result = rb_reg_match_post(MATCH_DATA);
	    break;
	  case '+':
	    result = rb_reg_match_last(MATCH_DATA);
	    break;
	  default:
	    rb_bug(&quot;unexpected back-ref&quot;);
	}
	break;

      case NODE_HASH:
	{
	    NODE *list;
	    VALUE hash = rb_hash_new();
	    VALUE key, val;

	    list = node-&gt;nd_head;
	    while (list) {
		key = rb_eval(self, list-&gt;nd_head);
		list = list-&gt;nd_next;
		if (list == 0)
		    rb_bug(&quot;odd number list for Hash&quot;);
		val = rb_eval(self, list-&gt;nd_head);
		list = list-&gt;nd_next;
		rb_hash_aset(hash, key, val);
	    }
	    result = hash;
	}
	break;

      case NODE_ZARRAY:		/* zero length list */
	result = rb_ary_new();
	break;

      case NODE_ARRAY:
	{
	    VALUE ary;
	    long i;

	    i = node-&gt;nd_alen;
	    ary = rb_ary_new2(i);
	    for (i=0;node;node=node-&gt;nd_next) {
		RARRAY(ary)-&gt;ptr[i++] = rb_eval(self, node-&gt;nd_head);
		RARRAY(ary)-&gt;len = i;
	    }

	    result = ary;
	}
	break;

      case NODE_STR:
	result = rb_str_new3(node-&gt;nd_lit);
	break;

      case NODE_EVSTR:
	result = rb_obj_as_string(rb_eval(self, node-&gt;nd_body));
	break;

      case NODE_DSTR:
      case NODE_DXSTR:
      case NODE_DREGX:
      case NODE_DREGX_ONCE:
      case NODE_DSYM:
	{
	    VALUE str, str2;
	    NODE *list = node-&gt;nd_next;

	    str = rb_str_new3(node-&gt;nd_lit);
	    while (list) {
		if (list-&gt;nd_head) {
		    switch (nd_type(list-&gt;nd_head)) {
		      case NODE_STR:
			str2 = list-&gt;nd_head-&gt;nd_lit;
			break;
		      default:
			str2 = rb_eval(self, list-&gt;nd_head);
			break;
		    }
		    rb_str_append(str, str2);
		    OBJ_INFECT(str, str2);
		}
		list = list-&gt;nd_next;
	    }
	    switch (nd_type(node)) {
	      case NODE_DREGX:
		result = rb_reg_new(RSTRING(str)-&gt;ptr, RSTRING(str)-&gt;len,
				    node-&gt;nd_cflag);
		break;
	      case NODE_DREGX_ONCE:	/* regexp expand once */
		result = rb_reg_new(RSTRING(str)-&gt;ptr, RSTRING(str)-&gt;len,
				    node-&gt;nd_cflag);
		nd_set_type(node, NODE_LIT);
		node-&gt;nd_lit = result;
		break;
	      case NODE_LIT:
		/* other thread may replace NODE_DREGX_ONCE to NODE_LIT */
		goto again;
	      case NODE_DXSTR:
		result = rb_funcall(self, '`', 1, str);
		break;
	      case NODE_DSYM:
		result = rb_str_intern(str);
		break;
	      default:
		result = str;
		break;
	    }
	}
	break;

      case NODE_XSTR:
	result = rb_funcall(self, '`', 1, rb_str_new3(node-&gt;nd_lit));
	break;

      case NODE_LIT:
	result = node-&gt;nd_lit;
	break;

      case NODE_DEFN:
	if (node-&gt;nd_defn) {
	    NODE *body,  *defn;
	    VALUE origin = 0;
	    int noex;

	    if (NIL_P(ruby_class)) {
		rb_raise(rb_eTypeError, &quot;no class/module to add method&quot;);
	    }
	    if (ruby_class == rb_cObject &amp;&amp; node-&gt;nd_mid == init) {
		rb_warn(&quot;redefining Object#initialize may cause infinite loop&quot;);
	    }
	    if (node-&gt;nd_mid == __id__ || node-&gt;nd_mid == __send__) {
		rb_warn(&quot;redefining `%s' may cause serious problem&quot;,
			rb_id2name(node-&gt;nd_mid));
	    }
	    rb_frozen_class_p(ruby_class);
	    body = search_method(ruby_class, node-&gt;nd_mid, &amp;origin);
	    if (body){
		if (RTEST(ruby_verbose) &amp;&amp; ruby_class == origin &amp;&amp; body-&gt;nd_cnt == 0 &amp;&amp; body-&gt;nd_body) {
		    rb_warning(&quot;method redefined; discarding old %s&quot;, rb_id2name(node-&gt;nd_mid));
		}
	    }

	    if (SCOPE_TEST(SCOPE_PRIVATE) || node-&gt;nd_mid == init) {
		noex = NOEX_PRIVATE;
	    }
	    else if (SCOPE_TEST(SCOPE_PROTECTED)) {
		noex = NOEX_PROTECTED;
	    }
	    else {
		noex = NOEX_PUBLIC;
	    }
	    if (body &amp;&amp; origin == ruby_class &amp;&amp; body-&gt;nd_body == 0) {
		noex |= NOEX_NOSUPER;
	    }

	    defn = rb_copy_node_scope(node-&gt;nd_defn, ruby_cref);
	    rb_add_method(ruby_class, node-&gt;nd_mid, defn, noex);
	    if (scope_vmode == SCOPE_MODFUNC) {
		rb_add_method(rb_singleton_class(ruby_class),
			      node-&gt;nd_mid, defn, NOEX_PUBLIC);
	    }
	    result = Qnil;
	}
	break;

      case NODE_DEFS:
	if (node-&gt;nd_defn) {
	    VALUE recv = rb_eval(self, node-&gt;nd_recv);
	    VALUE klass;
	    NODE *body = 0, *defn;

	    if (ruby_safe_level &gt;= 4 &amp;&amp; !OBJ_TAINTED(recv)) {
		rb_raise(rb_eSecurityError, &quot;Insecure: can't define singleton method&quot;);
	    }
	    if (FIXNUM_P(recv) || SYMBOL_P(recv)) {
		rb_raise(rb_eTypeError,
			 &quot;can't define singleton method \&quot;%s\&quot; for %s&quot;,
			 rb_id2name(node-&gt;nd_mid),
			 rb_obj_classname(recv));
	    }

	    if (OBJ_FROZEN(recv)) rb_error_frozen(&quot;object&quot;);
	    klass = rb_singleton_class(recv);
	    if (st_lookup(RCLASS(klass)-&gt;m_tbl, node-&gt;nd_mid, &amp;data)) {
		body = (NODE *)data;
		if (ruby_safe_level &gt;= 4) {
		    rb_raise(rb_eSecurityError, &quot;redefining method prohibited&quot;);
		}
		if (RTEST(ruby_verbose)) {
		    rb_warning(&quot;redefine %s&quot;, rb_id2name(node-&gt;nd_mid));
		}
	    }
	    defn = rb_copy_node_scope(node-&gt;nd_defn, ruby_cref);
	    rb_add_method(klass, node-&gt;nd_mid, defn,
			  NOEX_PUBLIC|(body?body-&gt;nd_noex&amp;NOEX_UNDEF:0));
	    result = Qnil;
	}
	break;

      case NODE_UNDEF:
	if (NIL_P(ruby_class)) {
	    rb_raise(rb_eTypeError, &quot;no class to undef method&quot;);
	}
	rb_undef(ruby_class, rb_to_id(rb_eval(self, node-&gt;u2.node)));
	result = Qnil;
	break;

      case NODE_ALIAS:
	if (NIL_P(ruby_class)) {
	    rb_raise(rb_eTypeError, &quot;no class to make alias&quot;);
	}
	rb_alias(ruby_class, rb_to_id(rb_eval(self, node-&gt;u1.node)),
		             rb_to_id(rb_eval(self, node-&gt;u2.node)));
	result = Qnil;
	break;

      case NODE_VALIAS:
	rb_alias_variable(node-&gt;u1.id, node-&gt;u2.id);
	result = Qnil;
	break;

      case NODE_CLASS:
	{
	    VALUE super, klass, tmp, cbase;
	    ID cname;
	    int gen = Qfalse;

	    cbase = class_prefix(self, node-&gt;nd_cpath);
	    cname = node-&gt;nd_cpath-&gt;nd_mid;

	    if (NIL_P(ruby_cbase)) {
		rb_raise(rb_eTypeError, &quot;no outer class/module&quot;);
	    }
	    if (node-&gt;nd_super) {
	       super = rb_eval(self, node-&gt;nd_super);
	       rb_check_inheritable(super);
	    }
	    else {
		super = 0;
	    }

	    if (rb_const_defined_at(cbase, cname)) {
		klass = rb_const_get_at(cbase, cname);
		if (TYPE(klass) != T_CLASS) {
		    rb_raise(rb_eTypeError, &quot;%s is not a class&quot;,
			     rb_id2name(cname));
		}
		if (super) {
		    tmp = rb_class_real(RCLASS(klass)-&gt;super);
		    if (tmp != super) {
			rb_raise(rb_eTypeError, &quot;superclass mismatch for class %s&quot;,
				 rb_id2name(cname));
		    }
		    super = 0;
		}
		if (ruby_safe_level &gt;= 4) {
		    rb_raise(rb_eSecurityError, &quot;extending class prohibited&quot;);
		}
	    }
	    else {
		if (!super) super = rb_cObject;
		klass = rb_define_class_id(cname, super);
		rb_set_class_path(klass, cbase, rb_id2name(cname));
		rb_const_set(cbase, cname, klass);
		gen = Qtrue;
	    }
	    if (ruby_wrapper) {
		rb_extend_object(klass, ruby_wrapper);
		rb_include_module(klass, ruby_wrapper);
	    }
	    if (super &amp;&amp; gen) {
		rb_class_inherited(super, klass);
	    }
	    result = module_setup(klass, node);
	}
	break;

      case NODE_MODULE:
	{
	    VALUE module, cbase;
	    ID cname;

	    if (NIL_P(ruby_cbase)) {
		rb_raise(rb_eTypeError, &quot;no outer class/module&quot;);
	    }
	    cbase = class_prefix(self, node-&gt;nd_cpath);
	    cname = node-&gt;nd_cpath-&gt;nd_mid;
	    if (rb_const_defined_at(cbase, cname)) {
		module = rb_const_get_at(cbase, cname);
		if (TYPE(module) != T_MODULE) {
		    rb_raise(rb_eTypeError, &quot;%s is not a module&quot;,
			     rb_id2name(cname));
		}
		if (ruby_safe_level &gt;= 4) {
		    rb_raise(rb_eSecurityError, &quot;extending module prohibited&quot;);
		}
	    }
	    else {
		module = rb_define_module_id(cname);
		rb_set_class_path(module, cbase, rb_id2name(cname));
		rb_const_set(cbase, cname, module);
	    }
	    if (ruby_wrapper) {
		rb_extend_object(module, ruby_wrapper);
		rb_include_module(module, ruby_wrapper);
	    }

	    result = module_setup(module, node);
	}
	break;

      case NODE_SCLASS:
	{
	    VALUE klass;

	    result = rb_eval(self, node-&gt;nd_recv);
	    if (FIXNUM_P(result) || SYMBOL_P(result)) {
		rb_raise(rb_eTypeError, &quot;no virtual class for %s&quot;,
			 rb_obj_classname(result));
	    }
	    if (ruby_safe_level &gt;= 4 &amp;&amp; !OBJ_TAINTED(result))
		rb_raise(rb_eSecurityError, &quot;Insecure: can't extend object&quot;);
	    klass = rb_singleton_class(result);

	    if (ruby_wrapper) {
		rb_extend_object(klass, ruby_wrapper);
		rb_include_module(klass, ruby_wrapper);
	    }

	    result = module_setup(klass, node);
	}
	break;

      case NODE_DEFINED:
	{
	    char buf[20];
	    const char *desc = is_defined(self, node-&gt;nd_head, buf);

	    if (desc) result = rb_str_new2(desc);
	    else result = Qnil;
	}
	break;

      case NODE_NEWLINE:
	EXEC_EVENT_HOOK(RUBY_EVENT_LINE, node, self, 
			ruby_frame-&gt;last_func,
			ruby_frame-&gt;last_class);
	node = node-&gt;nd_next;
	goto again;

      default:
	unknown_node(node);
    }
  finish:
    CHECK_INTS;
    if (contnode) {
	node = contnode;
	contnode = 0;
	goto again;
    }
    return result;
}

static VALUE
module_setup(module, n)
    VALUE module;
    NODE *n;
{
    NODE * volatile node = n-&gt;nd_body;
    int state;
    struct FRAME frame;
    VALUE result = Qnil;	/* OK */
    TMP_PROTECT;

    frame = *ruby_frame;
    frame.tmp = ruby_frame;
    ruby_frame = &amp;frame;

    PUSH_CLASS(module);
    PUSH_SCOPE();
    PUSH_VARS();

    if (node-&gt;nd_tbl) {
	VALUE *vars = TMP_ALLOC(node-&gt;nd_tbl[0]+1);
	*vars++ = (VALUE)node;
	ruby_scope-&gt;local_vars = vars;
	rb_mem_clear(ruby_scope-&gt;local_vars, node-&gt;nd_tbl[0]);
	ruby_scope-&gt;local_tbl = node-&gt;nd_tbl;
    }
    else {
	ruby_scope-&gt;local_vars = 0;
	ruby_scope-&gt;local_tbl  = 0;
    }

    PUSH_CREF(module);
    PUSH_TAG(PROT_NONE);
    if ((state = EXEC_TAG()) == 0) {
	EXEC_EVENT_HOOK(RUBY_EVENT_CLASS, n, ruby_cbase,
			ruby_frame-&gt;last_func, ruby_frame-&gt;last_class);
	result = rb_eval(ruby_cbase, node-&gt;nd_next);
    }
    POP_TAG();
    POP_CREF();
    POP_VARS();
    POP_SCOPE();
    POP_CLASS();

    ruby_frame = frame.tmp;
    EXEC_EVENT_HOOK(RUBY_EVENT_END, n, 0,
		    ruby_frame-&gt;last_func, ruby_frame-&gt;last_class);
    if (state) JUMP_TAG(state);

    return result;
}

static NODE *basic_respond_to = 0;

int
rb_obj_respond_to(obj, id, priv)
    VALUE obj;
    ID id;
    int priv;
{
    VALUE klass = CLASS_OF(obj);

    if (rb_method_node(klass, respond_to) == basic_respond_to) {
	return rb_method_boundp(klass, id, !priv);
    }
    else {
	VALUE args[2];
	int n = 0;
	args[n++] = ID2SYM(id);
	if (priv) args[n++] = Qtrue;
	return rb_funcall2(obj, respond_to, n, args);
    }
}

int
rb_respond_to(obj, id)
    VALUE obj;
    ID id;
{
    return rb_obj_respond_to(obj, id, Qfalse);
}

/*
 *  call-seq:
 *     obj.respond_to?(symbol, include_private=false) =&gt; true or false
 *  
 *  Returns +true+&gt; if _obj_ responds to the given
 *  method. Private methods are included in the search only if the
 *  optional second parameter evaluates to +true+.
 */

static VALUE
obj_respond_to(argc, argv, obj)
    int argc;
    VALUE *argv;
    VALUE obj;
{
    VALUE mid, priv;
    ID id;

    rb_scan_args(argc, argv, &quot;11&quot;, &amp;mid, &amp;priv);
    id = rb_to_id(mid);
    if (rb_method_boundp(CLASS_OF(obj), id, !RTEST(priv))) {
	return Qtrue;
    }
    return Qfalse;
}

/*
 *  call-seq:
 *     mod.method_defined?(symbol)    =&gt; true or false
 *  
 *  Returns +true+ if the named method is defined by
 *  _mod_ (or its included modules and, if _mod_ is a class,
 *  its ancestors). Public and protected methods are matched.
 *     
 *     module A
 *       def method1()  end
 *     end
 *     class B
 *       def method2()  end
 *     end
 *     class C &lt; B
 *       include A
 *       def method3()  end
 *     end
 *     
 *     A.method_defined? :method1    #=&gt; true
 *     C.method_defined? &quot;method1&quot;   #=&gt; true
 *     C.method_defined? &quot;method2&quot;   #=&gt; true
 *     C.method_defined? &quot;method3&quot;   #=&gt; true
 *     C.method_defined? &quot;method4&quot;   #=&gt; false
 */

static VALUE
rb_mod_method_defined(mod, mid)
    VALUE mod, mid;
{
    return rb_method_boundp(mod, rb_to_id(mid), 1);
}

#define VISI_CHECK(x,f) (((x)&amp;NOEX_MASK) == (f))

/*
 *  call-seq:
 *     mod.public_method_defined?(symbol)   =&gt; true or false
 *  
 *  Returns +true+ if the named public method is defined by
 *  _mod_ (or its included modules and, if _mod_ is a class,
 *  its ancestors).
 *     
 *     module A
 *       def method1()  end
 *     end
 *     class B
 *       protected
 *       def method2()  end
 *     end
 *     class C &lt; B
 *       include A
 *       def method3()  end
 *     end
 *     
 *     A.method_defined? :method1           #=&gt; true
 *     C.public_method_defined? &quot;method1&quot;   #=&gt; true
 *     C.public_method_defined? &quot;method2&quot;   #=&gt; false
 *     C.method_defined? &quot;method2&quot;          #=&gt; true
 */

static VALUE
rb_mod_public_method_defined(mod, mid)
    VALUE mod, mid;
{
    ID id = rb_to_id(mid);
    int noex;

    if (rb_get_method_body(&amp;mod, &amp;id, &amp;noex)) {
	if (VISI_CHECK(noex, NOEX_PUBLIC))
	    return Qtrue;
    }
    return Qfalse;
}

/*
 *  call-seq:
 *     mod.private_method_defined?(symbol)    =&gt; true or false
 *  
 *  Returns +true+ if the named private method is defined by
 *  _ mod_ (or its included modules and, if _mod_ is a class,
 *  its ancestors).
 *     
 *     module A
 *       def method1()  end
 *     end
 *     class B
 *       private
 *       def method2()  end
 *     end
 *     class C &lt; B
 *       include A
 *       def method3()  end
 *     end
 *     
 *     A.method_defined? :method1            #=&gt; true
 *     C.private_method_defined? &quot;method1&quot;   #=&gt; false
 *     C.private_method_defined? &quot;method2&quot;   #=&gt; true
 *     C.method_defined? &quot;method2&quot;           #=&gt; false
 */

static VALUE
rb_mod_private_method_defined(mod, mid)
    VALUE mod, mid;
{
    ID id = rb_to_id(mid);
    int noex;

    if (rb_get_method_body(&amp;mod, &amp;id, &amp;noex)) {
	if (VISI_CHECK(noex, NOEX_PRIVATE))
	    return Qtrue;
    }
    return Qfalse;
}

/*
 *  call-seq:
 *     mod.protected_method_defined?(symbol)   =&gt; true or false
 *  
 *  Returns +true+ if the named protected method is defined
 *  by _mod_ (or its included modules and, if _mod_ is a
 *  class, its ancestors).
 *     
 *     module A
 *       def method1()  end
 *     end
 *     class B
 *       protected
 *       def method2()  end
 *     end
 *     class C &lt; B
 *       include A
 *       def method3()  end
 *     end
 *     
 *     A.method_defined? :method1              #=&gt; true
 *     C.protected_method_defined? &quot;method1&quot;   #=&gt; false
 *     C.protected_method_defined? &quot;method2&quot;   #=&gt; true
 *     C.method_defined? &quot;method2&quot;             #=&gt; true
 */

static VALUE
rb_mod_protected_method_defined(mod, mid)
    VALUE mod, mid;
{
    ID id = rb_to_id(mid);
    int noex;

    if (rb_get_method_body(&amp;mod, &amp;id, &amp;noex)) {
	if (VISI_CHECK(noex, NOEX_PROTECTED))
	    return Qtrue;
    }
    return Qfalse;
}

NORETURN(static VALUE terminate_process _((int, VALUE)));
static VALUE
terminate_process(status, mesg)
    int status;
    VALUE mesg;
{
    VALUE args[2];
    args[0] = INT2NUM(status);
    args[1] = mesg;

    rb_exc_raise(rb_class_new_instance(2, args, rb_eSystemExit));
}

void
rb_exit(status)
    int status;
{
    if (prot_tag) {
	terminate_process(status, rb_str_new(&quot;exit&quot;, 4));
    }
    ruby_finalize();
    exit(status);
}


/*
 *  call-seq:
 *     exit(integer=0)
 *     Kernel::exit(integer=0)
 *     Process::exit(integer=0)
 *  
 *  Initiates the termination of the Ruby script by raising the
 *  &lt;code&gt;SystemExit&lt;/code&gt; exception. This exception may be caught. The
 *  optional parameter is used to return a status code to the invoking
 *  environment.
 *     
 *     begin
 *       exit
 *       puts &quot;never get here&quot;
 *     rescue SystemExit
 *       puts &quot;rescued a SystemExit exception&quot;
 *     end
 *     puts &quot;after begin block&quot;
 *     
 *  &lt;em&gt;produces:&lt;/em&gt;
 *     
 *     rescued a SystemExit exception
 *     after begin block
 *     
 *  Just prior to termination, Ruby executes any &lt;code&gt;at_exit&lt;/code&gt; functions
 *  (see Kernel::at_exit) and runs any object finalizers (see
 *  ObjectSpace::define_finalizer).
 *     
 *     at_exit { puts &quot;at_exit function&quot; }
 *     ObjectSpace.define_finalizer(&quot;string&quot;,  proc { puts &quot;in finalizer&quot; })
 *     exit
 *     
 *  &lt;em&gt;produces:&lt;/em&gt;
 *     
 *     at_exit function
 *     in finalizer
 */

VALUE
rb_f_exit(argc, argv)
    int argc;
    VALUE *argv;
{
    VALUE status;
    int istatus;

    rb_secure(4);
    if (rb_scan_args(argc, argv, &quot;01&quot;, &amp;status) == 1) {
	switch (status) {
	  case Qtrue:
	    istatus = EXIT_SUCCESS;
	    break;
	  case Qfalse:
	    istatus = EXIT_FAILURE;
	    break;
	  default:
	    istatus = NUM2INT(status);
#if EXIT_SUCCESS != 0
	    if (istatus == 0) istatus = EXIT_SUCCESS;
#endif
	    break;
	}
    }
    else {
	istatus = EXIT_SUCCESS;
    }
    rb_exit(istatus);
    return Qnil;		/* not reached */
}


/*
 *  call-seq:
 *     abort
 *     Kernel::abort
 *     Process::abort
 *  
 *  Terminate execution immediately, effectively by calling
 *  &lt;code&gt;Kernel.exit(1)&lt;/code&gt;. If _msg_ is given, it is written
 *  to STDERR prior to terminating.
 */

VALUE
rb_f_abort(argc, argv)
    int argc;
    VALUE *argv;
{
    rb_secure(4);
    if (argc == 0) {
	if (!NIL_P(ruby_errinfo)) {
	    error_print();
	}
	rb_exit(EXIT_FAILURE);
    }
    else {
	VALUE mesg;

	rb_scan_args(argc, argv, &quot;1&quot;, &amp;mesg);
	StringValue(mesg);
	rb_io_puts(1, &amp;mesg, rb_stderr);
	terminate_process(EXIT_FAILURE, mesg);
    }
    return Qnil;		/* not reached */
}

void
rb_iter_break()
{
    break_jump(Qnil);
}

NORETURN(static void rb_longjmp _((int, VALUE)));
static VALUE make_backtrace _((void));

static void
rb_longjmp(tag, mesg)
    int tag;
    VALUE mesg;
{
    VALUE at;

    if (thread_set_raised()) {
	ruby_errinfo = exception_error;
	JUMP_TAG(TAG_FATAL);
    }
    if (NIL_P(mesg)) mesg = ruby_errinfo;
    if (NIL_P(mesg)) {
	mesg = rb_exc_new(rb_eRuntimeError, 0, 0);
    }

    ruby_set_current_source();
    if (ruby_sourcefile &amp;&amp; !NIL_P(mesg)) {
	at = get_backtrace(mesg);
	if (NIL_P(at)) {
	    at = make_backtrace();
	    set_backtrace(mesg, at);
	}
    }
    if (!NIL_P(mesg)) {
	ruby_errinfo = mesg;
    }

    if (RTEST(ruby_debug) &amp;&amp; !NIL_P(ruby_errinfo)
	&amp;&amp; !rb_obj_is_kind_of(ruby_errinfo, rb_eSystemExit)) {
	VALUE e = ruby_errinfo;
	int status;

	PUSH_TAG(PROT_NONE);
	if ((status = EXEC_TAG()) == 0) {
	    StringValue(e);
	    warn_printf(&quot;Exception `%s' at %s:%d - %s\n&quot;,
			rb_obj_classname(ruby_errinfo),
			ruby_sourcefile, ruby_sourceline,
			RSTRING(e)-&gt;ptr);
	}
	POP_TAG();
	if (status == TAG_FATAL &amp;&amp; ruby_errinfo == exception_error) {
	    ruby_errinfo = mesg;
	}
	else if (status) {
	    thread_reset_raised();
	    JUMP_TAG(status);
	}
    }

    rb_trap_restore_mask();
    if (tag != TAG_FATAL) {
	EXEC_EVENT_HOOK(RUBY_EVENT_RAISE, ruby_current_node,
			ruby_frame-&gt;self,
			ruby_frame-&gt;last_func,
			ruby_frame-&gt;last_class);
    }
    if (!prot_tag) {
	error_print();
    }
    thread_reset_raised();
    JUMP_TAG(tag);
}

void
rb_exc_raise(mesg)
    VALUE mesg;
{
    rb_longjmp(TAG_RAISE, mesg);
}

void
rb_exc_fatal(mesg)
    VALUE mesg;
{
    rb_longjmp(TAG_FATAL, mesg);
}

void
rb_interrupt()
{
    static const char fmt[1] = {'\0'};
    rb_raise(rb_eInterrupt, fmt);
}

/*
 *  call-seq:
 *     raise
 *     raise(string)
 *     raise(exception [, string [, array]])
 *     fail
 *     fail(string)
 *     fail(exception [, string [, array]])
 *  
 *  With no arguments, raises the exception in &lt;code&gt;$!&lt;/code&gt; or raises
 *  a &lt;code&gt;RuntimeError&lt;/code&gt; if &lt;code&gt;$!&lt;/code&gt; is +nil+.
 *  With a single +String+ argument, raises a
 *  +RuntimeError+ with the string as a message. Otherwise,
 *  the first parameter should be the name of an +Exception+
 *  class (or an object that returns an +Exception+ object when sent
 *  an +exception+ message). The optional second parameter sets the
 *  message associated with the exception, and the third parameter is an
 *  array of callback information. Exceptions are caught by the
 *  +rescue+ clause of &lt;code&gt;begin...end&lt;/code&gt; blocks.
 *     
 *     raise &quot;Failed to create socket&quot;
 *     raise ArgumentError, &quot;No parameters&quot;, caller
 */

static VALUE
rb_f_raise(argc, argv)
    int argc;
    VALUE *argv;
{
    rb_raise_jump(rb_make_exception(argc, argv));
    return Qnil;		/* not reached */
}

static VALUE
rb_make_exception(argc, argv)
    int argc;
    VALUE *argv;
{
    VALUE mesg;
    ID exception;
    int n;

    mesg = Qnil;
    switch (argc) {
      case 0:
	mesg = Qnil;
	break;
      case 1:
	if (NIL_P(argv[0])) break;
	if (TYPE(argv[0]) == T_STRING) {
	    mesg = rb_exc_new3(rb_eRuntimeError, argv[0]);
	    break;
	}
	n = 0;
	goto exception_call;

      case 2:
      case 3:
	n = 1;
      exception_call:
	exception = rb_intern(&quot;exception&quot;);
	if (!rb_respond_to(argv[0], exception)) {
	    rb_raise(rb_eTypeError, &quot;exception class/object expected&quot;);
	}
	mesg = rb_funcall(argv[0], exception, n, argv[1]);
	break;
      default:
	rb_raise(rb_eArgError, &quot;wrong number of arguments&quot;);
	break;
    }
    if (argc &gt; 0) {
	if (!rb_obj_is_kind_of(mesg, rb_eException))
	    rb_raise(rb_eTypeError, &quot;exception object expected&quot;);
	if (argc&gt;2)
	    set_backtrace(mesg, argv[2]);
    }

    return mesg;
}

static void
rb_raise_jump(mesg)
    VALUE mesg;
{
    if (ruby_frame != top_frame) {
	PUSH_FRAME();		/* fake frame */
	*ruby_frame = *_frame.prev-&gt;prev;
	rb_longjmp(TAG_RAISE, mesg);
	POP_FRAME();
    }
    rb_longjmp(TAG_RAISE, mesg);
}

void
rb_jump_tag(tag)
    int tag;
{
    JUMP_TAG(tag);
}

int
rb_block_given_p()
{
    if (ruby_frame-&gt;iter == ITER_CUR &amp;&amp; ruby_block)
	return Qtrue;
    return Qfalse;
}

int
rb_iterator_p()
{
    return rb_block_given_p();
}

/*
 *  call-seq:
 *     block_given?   =&gt; true or false
 *     iterator?      =&gt; true or false
 *  
 *  Returns &lt;code&gt;true&lt;/code&gt; if &lt;code&gt;yield&lt;/code&gt; would execute a
 *  block in the current context. The &lt;code&gt;iterator?&lt;/code&gt; form
 *  is mildly deprecated.
 *     
 *     def try
 *       if block_given?
 *         yield
 *       else
 *         &quot;no block&quot;
 *       end
 *     end
 *     try                  #=&gt; &quot;no block&quot;
 *     try { &quot;hello&quot; }      #=&gt; &quot;hello&quot;
 *     try do &quot;hello&quot; end   #=&gt; &quot;hello&quot;
 */


static VALUE
rb_f_block_given_p()
{
    if (ruby_frame-&gt;prev &amp;&amp; ruby_frame-&gt;prev-&gt;iter == ITER_CUR &amp;&amp; ruby_block)
	return Qtrue;
    return Qfalse;
}

VALUE rb_eThreadError;

NORETURN(static void proc_jump_error(int, VALUE));
static void
proc_jump_error(state, result)
    int state;
    VALUE result;
{
    char mesg[32];
    const char *statement;

    switch (state) {
      case TAG_BREAK:
	statement = &quot;break&quot;; break;
      case TAG_RETURN:
	statement = &quot;return&quot;; break;
      case TAG_RETRY:
	statement = &quot;retry&quot;; break;
      default:
	statement = &quot;local-jump&quot;; break; /* should not happen */
    }
    snprintf(mesg, sizeof mesg, &quot;%s from proc-closure&quot;, statement);
    localjump_error(mesg, result, state);
}

static void
return_jump(retval)
    VALUE retval;
{
    struct tag *tt = prot_tag;
    int yield = Qfalse;

    if (retval == Qundef) retval = Qnil;
    while (tt) {
	if (tt-&gt;tag == PROT_YIELD) {
	    yield = Qtrue;
	    tt = tt-&gt;prev;
	}
	if (tt-&gt;tag == PROT_FUNC &amp;&amp; tt-&gt;frame-&gt;uniq == ruby_frame-&gt;uniq) {
	    tt-&gt;dst = (VALUE)ruby_frame-&gt;uniq;
	    tt-&gt;retval = retval;
	    JUMP_TAG(TAG_RETURN);
	}
	if (tt-&gt;tag == PROT_LAMBDA &amp;&amp; !yield) {
	    tt-&gt;dst = (VALUE)tt-&gt;frame-&gt;uniq;
	    tt-&gt;retval = retval;
	    JUMP_TAG(TAG_RETURN);
	}
	if (tt-&gt;tag == PROT_THREAD) {
	    rb_raise(rb_eThreadError, &quot;return can't jump across threads&quot;);
	}
	tt = tt-&gt;prev;
    }
    localjump_error(&quot;unexpected return&quot;, retval, TAG_RETURN);
}

static void
break_jump(retval)
    VALUE retval;
{
    struct tag *tt = prot_tag;

    if (retval == Qundef) retval = Qnil;
    while (tt) {
	switch (tt-&gt;tag) {
	  case PROT_THREAD:
	  case PROT_YIELD:
	  case PROT_LOOP:
	  case PROT_LAMBDA:
	    tt-&gt;dst = (VALUE)tt-&gt;frame-&gt;uniq;
	    tt-&gt;retval = retval;
	    JUMP_TAG(TAG_BREAK);
	    break;
	  case PROT_FUNC:
	    tt = 0;
	    continue;
	  default:
	    break;
	}
	tt = tt-&gt;prev;
    }
    localjump_error(&quot;unexpected break&quot;, retval, TAG_BREAK);
}

static void
next_jump(retval)
    VALUE retval;
{
    struct tag *tt = prot_tag;

    if (retval == Qundef) retval = Qnil;
    while (tt) {
	switch (tt-&gt;tag) {
	  case PROT_THREAD:
	  case PROT_YIELD:
	  case PROT_LOOP:
	  case PROT_LAMBDA:
	  case PROT_FUNC:
	    tt-&gt;dst = (VALUE)tt-&gt;frame-&gt;uniq;
	    tt-&gt;retval = retval;
	    JUMP_TAG(TAG_NEXT);
	    break;
	  default:
	    break;
	}
	tt = tt-&gt;prev;
    }
    localjump_error(&quot;unexpected next&quot;, retval, TAG_NEXT);
}

void
rb_need_block()
{
    if (!rb_block_given_p()) {
	localjump_error(&quot;no block given&quot;, Qnil, 0);
    }
}

static VALUE
rb_yield_0(val, self, klass, flags, avalue)
    VALUE val, self, klass;	/* OK */
    int flags, avalue;
{
    NODE *node, *var;
    volatile VALUE result = Qnil;
    volatile VALUE old_cref;
    volatile VALUE old_wrapper;
    struct BLOCK * volatile block;
    struct SCOPE * volatile old_scope;
    int old_vmode;
    struct FRAME frame;
    NODE *cnode = ruby_current_node;
    int lambda = flags &amp; YIELD_LAMBDA_CALL;
    int state;

    rb_need_block();

    PUSH_VARS();
    block = ruby_block;
    frame = block-&gt;frame;
    frame.prev = ruby_frame;
    frame.node = cnode;
    ruby_frame = &amp;(frame);
    old_cref = (VALUE)ruby_cref;
    ruby_cref = block-&gt;cref;
    old_wrapper = ruby_wrapper;
    ruby_wrapper = block-&gt;wrapper;
    old_scope = ruby_scope;
    ruby_scope = block-&gt;scope;
    old_vmode = scope_vmode;
    scope_vmode = (flags &amp; YIELD_PUBLIC_DEF) ? SCOPE_PUBLIC : block-&gt;vmode;
    ruby_block = block-&gt;prev;
    if (block-&gt;flags &amp; BLOCK_D_SCOPE) {
	/* put place holder for dynamic (in-block) local variables */
	ruby_dyna_vars = new_dvar(0, 0, block-&gt;dyna_vars);
    }
    else {
	/* FOR does not introduce new scope */
	ruby_dyna_vars = block-&gt;dyna_vars;
    }
    PUSH_CLASS(klass ? klass : block-&gt;klass);
    if (!klass) {
	self = block-&gt;self;
    }
    node = block-&gt;body;
    var = block-&gt;var;

    if (var) {
	PUSH_TAG(PROT_NONE);
	if ((state = EXEC_TAG()) == 0) {
	    NODE *bvar = NULL;
	  block_var:
	    if (var == (NODE*)1) { /* no parameter || */
		if (lambda &amp;&amp; RARRAY(val)-&gt;len != 0) {
		    rb_raise(rb_eArgError, &quot;wrong number of arguments (%ld for 0)&quot;,
			     RARRAY(val)-&gt;len);
		}
	    }
	    else if (var == (NODE*)2) {
		if (TYPE(val) == T_ARRAY &amp;&amp; RARRAY(val)-&gt;len != 0) {
		    rb_raise(rb_eArgError, &quot;wrong number of arguments (%ld for 0)&quot;,
			     RARRAY(val)-&gt;len);
		}
	    }
	    else if (!bvar &amp;&amp; nd_type(var) == NODE_BLOCK_PASS) {
		bvar = var-&gt;nd_body;
		var = var-&gt;nd_args;
		goto block_var;
	    }
	    else if (nd_type(var) == NODE_MASGN) {
		if (!avalue) {
		    val = svalue_to_mrhs(val, var-&gt;nd_head);
		}
		massign(self, var, val, lambda);
	    }
	    else {
		int len = 0;
		if (avalue) {
		    len = RARRAY(val)-&gt;len;
		    if (len == 0) {
			goto zero_arg;
		    }
		    if (len == 1) {
			val = RARRAY(val)-&gt;ptr[0];
		    }
		    else {
			goto multi_values;
		    }
		}
		else if (val == Qundef) {
		  zero_arg:
		    val = Qnil;
		  multi_values:
		    {
			ruby_current_node = var;
			rb_warn(&quot;multiple values for a block parameter (%d for 1)\n\tfrom %s:%d&quot;,
				len, cnode-&gt;nd_file, nd_line(cnode));
			ruby_current_node = cnode;
		    }
		}
		assign(self, var, val, lambda);
	    }
	    if (bvar) {
		VALUE blk;
		if (flags &amp; YIELD_PROC_CALL)
		    blk = block-&gt;block_obj;
		else
		    blk = rb_block_proc();
		assign(self, bvar, blk, 0);
	    }
	}
	POP_TAG();
	if (state) goto pop_state;
    }
    if (!node) {
	state = 0;
	goto pop_state;
    }
    ruby_current_node = node;

    PUSH_ITER(block-&gt;iter);
    PUSH_TAG(lambda ? PROT_NONE : PROT_YIELD);
    if ((state = EXEC_TAG()) == 0) {
      redo:
	if (nd_type(node) == NODE_CFUNC || nd_type(node) == NODE_IFUNC) {
	    switch (node-&gt;nd_state) {
	      case YIELD_FUNC_LAMBDA:
		if (!avalue) {
		    val = rb_ary_new3(1, val);
		}
		break;
	      case YIELD_FUNC_AVALUE:
		if (!avalue) {
		    val = svalue_to_avalue(val);
		}
		break;
	      default:
		if (avalue) {
		    val = avalue_to_svalue(val);
		}
		if (val == Qundef &amp;&amp; node-&gt;nd_state != YIELD_FUNC_SVALUE)
		    val = Qnil;
	    }
	    result = (*node-&gt;nd_cfnc)(val, node-&gt;nd_tval, self);
	}
	else {
	    result = rb_eval(self, node);
	}
    }
    else {
	switch (state) {
	  case TAG_REDO:
	    state = 0;
	    CHECK_INTS;
	    goto redo;
	  case TAG_NEXT:
	    if (!lambda) {
		state = 0;
		result = prot_tag-&gt;retval;
	    }
	    break;
	  case TAG_BREAK:
	    if (TAG_DST()) {
		result = prot_tag-&gt;retval;
	    }
	    else {
		lambda = Qtrue;	/* just pass TAG_BREAK */
	    }
	    break;
	  default:
	    break;
	}
    }
    POP_TAG();
    POP_ITER();
  pop_state:
    POP_CLASS();
    if (ruby_dyna_vars &amp;&amp; (block-&gt;flags &amp; BLOCK_D_SCOPE) &amp;&amp;
	!FL_TEST(ruby_dyna_vars, DVAR_DONT_RECYCLE)) {
	struct RVarmap *vars = ruby_dyna_vars;

	if (ruby_dyna_vars-&gt;id == 0) {
	    vars = ruby_dyna_vars-&gt;next;
	    rb_gc_force_recycle((VALUE)ruby_dyna_vars);
	    while (vars &amp;&amp; vars-&gt;id != 0 &amp;&amp; vars != block-&gt;dyna_vars) {
		struct RVarmap *tmp = vars-&gt;next;
		rb_gc_force_recycle((VALUE)vars);
		vars = tmp;
	    }
	}
    }
    POP_VARS();
    ruby_block = block;
    ruby_frame = ruby_frame-&gt;prev;
    ruby_cref = (NODE*)old_cref;
    ruby_wrapper = old_wrapper;
    if (ruby_scope-&gt;flags &amp; SCOPE_DONT_RECYCLE)
	scope_dup(old_scope);
    ruby_scope = old_scope;
    scope_vmode = old_vmode;
    switch (state) {
      case 0:
	break;
      case TAG_BREAK:
	if (!lambda) {
	    struct tag *tt = prot_tag;

	    while (tt) {
		if (tt-&gt;tag == PROT_LOOP &amp;&amp; tt-&gt;blkid == ruby_block-&gt;uniq) {
		    tt-&gt;dst = (VALUE)tt-&gt;frame-&gt;uniq;
		    tt-&gt;retval = result;
		    JUMP_TAG(TAG_BREAK);
		}
		tt = tt-&gt;prev;
	    }
	    proc_jump_error(TAG_BREAK, result);
	}
	/* fall through */
      default:
	JUMP_TAG(state);
	break;
    }
    ruby_current_node = cnode;
    return result;
}

VALUE
rb_yield(val)
    VALUE val;
{
    return rb_yield_0(val, 0, 0, 0, Qfalse);
}

VALUE
#ifdef HAVE_STDARG_PROTOTYPES
rb_yield_values(int n, ...)
#else
rb_yield_values(n, va_alist)
    int n;
    va_dcl
#endif
{
    va_list args;
    VALUE ary;

    if (n == 0) {
	return rb_yield_0(Qundef, 0, 0, 0, Qfalse);
    }
    ary = rb_ary_new2(n);
    va_init_list(args, n);
    while (n--) {
	rb_ary_push(ary, va_arg(args, VALUE));
    }
    va_end(args);
    return rb_yield_0(ary, 0, 0, 0, Qtrue);
}

VALUE
rb_yield_splat(values)
    VALUE values;
{
    int avalue = Qfalse;

    if (TYPE(values) == T_ARRAY) {
	if (RARRAY(values)-&gt;len == 0) {
	    values = Qundef;
	}
	else {
	    avalue = Qtrue;
	}
    }
    return rb_yield_0(values, 0, 0, 0, avalue);
}

static VALUE
loop_i()
{
    for (;;) {
	rb_yield_0(Qundef, 0, 0, 0, Qfalse);
	CHECK_INTS;
    }
    return Qnil;
}

/*
 *  call-seq:
 *     loop {|| block } 
 *  
 *  Repeatedly executes the block.
 *     
 *     loop do
 *       print &quot;Input: &quot;
 *       line = gets
 *       break if !line or line =~ /^qQ/
 *       # ...
 *     end
 *
 *  StopIteration raised in the block breaks the loop.
 */

static VALUE
rb_f_loop()
{
    rb_rescue2(loop_i, (VALUE)0, 0, 0, rb_eStopIteration, (VALUE)0);
    return Qnil;		/* dummy */
}

static VALUE
massign(self, node, val, pcall)
    VALUE self;
    NODE *node;
    VALUE val;
    int pcall;
{
    NODE *list;
    long i = 0, len;

    len = RARRAY(val)-&gt;len;
    list = node-&gt;nd_head;
    for (; list &amp;&amp; i&lt;len; i++) {
	assign(self, list-&gt;nd_head, RARRAY(val)-&gt;ptr[i], pcall);
	list = list-&gt;nd_next;
    }
    if (pcall &amp;&amp; list) goto arg_error;
    if (node-&gt;nd_args) {
	if ((long)(node-&gt;nd_args) == -1) {
	    /* no check for mere `*' */
	}
	else if (!list &amp;&amp; i&lt;len) {
	    assign(self, node-&gt;nd_args, rb_ary_new4(len-i, RARRAY(val)-&gt;ptr+i), pcall);
	}
	else {
	    assign(self, node-&gt;nd_args, rb_ary_new2(0), pcall);
	}
    }
    else if (pcall &amp;&amp; i &lt; len) {
	goto arg_error;
    }

    while (list) {
	i++;
	assign(self, list-&gt;nd_head, Qnil, pcall);
	list = list-&gt;nd_next;
    }
    return val;

  arg_error:
    while (list) {
	i++;
	list = list-&gt;nd_next;
    }
    rb_raise(rb_eArgError, &quot;wrong number of arguments (%ld for %ld)&quot;, len, i);
}

static void
assign(self, lhs, val, pcall)
    VALUE self;
    NODE *lhs;
    VALUE val;
    int pcall;
{
    ruby_current_node = lhs;
    if (val == Qundef) {
	rb_warning(&quot;assigning void value&quot;);
	val = Qnil;
    }
    switch (nd_type(lhs)) {
      case NODE_GASGN:
	rb_gvar_set(lhs-&gt;nd_entry, val);
	break;

      case NODE_IASGN:
	rb_ivar_set(self, lhs-&gt;nd_vid, val);
	break;

      case NODE_LASGN:
	if (ruby_scope-&gt;local_vars == 0)
	    rb_bug(&quot;unexpected local variable assignment&quot;);
	ruby_scope-&gt;local_vars[lhs-&gt;nd_cnt] = val;
	break;

      case NODE_DASGN:
	dvar_asgn(lhs-&gt;nd_vid, val);
	break;

      case NODE_DASGN_CURR:
	dvar_asgn_curr(lhs-&gt;nd_vid, val);
	break;

      case NODE_CDECL:
	if (lhs-&gt;nd_vid == 0) {
	    rb_const_set(class_prefix(self, lhs-&gt;nd_else), lhs-&gt;nd_else-&gt;nd_mid, val);
	}
	else {
	    rb_const_set(ruby_cbase, lhs-&gt;nd_vid, val);
	}
	break;

      case NODE_CVDECL:
	if (RTEST(ruby_verbose) &amp;&amp; FL_TEST(ruby_cbase, FL_SINGLETON)) {
	    rb_warn(&quot;declaring singleton class variable&quot;);
	}
	rb_cvar_set(cvar_cbase(), lhs-&gt;nd_vid, val, Qtrue);
	break;

      case NODE_CVASGN:
	rb_cvar_set(cvar_cbase(), lhs-&gt;nd_vid, val, Qfalse);
	break;

      case NODE_MASGN:
	massign(self, lhs, svalue_to_mrhs(val, lhs-&gt;nd_head), pcall);
	break;

      case NODE_CALL:
      case NODE_ATTRASGN:
	{
	    VALUE recv;
	    int scope;
	    if (lhs-&gt;nd_recv == (NODE *)1) {
		recv = self;
		scope = 1;
	    }
	    else {
		recv = rb_eval(self, lhs-&gt;nd_recv);
		scope = 0;
	    }
	    if (!lhs-&gt;nd_args) {
		/* attr set */
		ruby_current_node = lhs;
		SET_CURRENT_SOURCE();
		rb_call(CLASS_OF(recv), recv, lhs-&gt;nd_mid, 1, &amp;val, scope, self);
	    }
	    else {
		/* array set */
		VALUE args;

		args = rb_eval(self, lhs-&gt;nd_args);
		rb_ary_push(args, val);
		ruby_current_node = lhs;
		SET_CURRENT_SOURCE();
		rb_call(CLASS_OF(recv), recv, lhs-&gt;nd_mid,
			RARRAY(args)-&gt;len, RARRAY(args)-&gt;ptr, scope, self);
	    }
	}
	break;

      default:
	rb_bug(&quot;bug in variable assignment&quot;);
	break;
    }
}

VALUE
rb_iterate(it_proc, data1, bl_proc, data2)
    VALUE (*it_proc) _((VALUE)), (*bl_proc)(ANYARGS);
    VALUE data1, data2;
{
    int state;
    volatile VALUE retval = Qnil;
    NODE *node = NEW_IFUNC(bl_proc, data2);
    VALUE self = ruby_top_self;

    PUSH_TAG(PROT_LOOP);
    PUSH_BLOCK(0, node);
    PUSH_ITER(ITER_PRE);
    state = EXEC_TAG();
    if (state == 0) {
  iter_retry:
	retval = (*it_proc)(data1);
    }
    else if (state == TAG_BREAK &amp;&amp; TAG_DST()) {
	retval = prot_tag-&gt;retval;
	state = 0;
    }
    else if (state == TAG_RETRY) {
	state = 0;
	goto iter_retry;
    }
    POP_ITER();
    POP_BLOCK();
    POP_TAG();

    switch (state) {
      case 0:
	break;
      default:
	JUMP_TAG(state);
    }
    return retval;
}

static int
handle_rescue(self, node)
    VALUE self;
    NODE *node;
{
    int argc; VALUE *argv; /* used in SETUP_ARGS */
    TMP_PROTECT;

    if (!node-&gt;nd_args) {
	return rb_obj_is_kind_of(ruby_errinfo, rb_eStandardError);
    }

    BEGIN_CALLARGS;
    SETUP_ARGS(node-&gt;nd_args);
    END_CALLARGS;

    while (argc--) {
	if (!rb_obj_is_kind_of(argv[0], rb_cModule)) {
	    rb_raise(rb_eTypeError, &quot;class or module required for rescue clause&quot;);
	}
	if (RTEST(rb_funcall(*argv, eqq, 1, ruby_errinfo))) return 1;
	argv++;
    }
    return 0;
}

VALUE
#ifdef HAVE_STDARG_PROTOTYPES
rb_rescue2(VALUE (*b_proc)(ANYARGS), VALUE data1, VALUE (*r_proc)(ANYARGS), VALUE data2, ...)
#else
rb_rescue2(b_proc, data1, r_proc, data2, va_alist)
    VALUE (*b_proc)(ANYARGS), (*r_proc)(ANYARGS);
    VALUE data1, data2;
    va_dcl
#endif
{
    int state;
    volatile VALUE result;
    volatile VALUE e_info = ruby_errinfo;
    volatile int handle = Qfalse;
    VALUE eclass;
    va_list args;

    PUSH_TAG(PROT_NONE);
    switch (state = EXEC_TAG()) {
      case TAG_RETRY:
	if (!handle) break;
	handle = Qfalse;
	state = 0;
	ruby_errinfo = Qnil;
      case 0:
	result = (*b_proc)(data1);
	break;
      case TAG_RAISE:
	if (handle) break;
	handle = Qfalse;
	va_init_list(args, data2);
	while ((eclass = va_arg(args, VALUE)) != 0) {
	    if (rb_obj_is_kind_of(ruby_errinfo, eclass)) {
		handle = Qtrue;
		break;
	    }
	}
	va_end(args);

	if (handle) {
	    state = 0;
	    if (r_proc) {
		result = (*r_proc)(data2, ruby_errinfo);
	    }
	    else {
		result = Qnil;
	    }
	    ruby_errinfo = e_info;
	}
    }
    POP_TAG();
    if (state) JUMP_TAG(state);

    return result;
}

VALUE
rb_rescue(b_proc, data1, r_proc, data2)
    VALUE (*b_proc)(), (*r_proc)();
    VALUE data1, data2;
{
    return rb_rescue2(b_proc, data1, r_proc, data2, rb_eStandardError, (VALUE)0);
}

static VALUE cont_protect;

VALUE
rb_protect(proc, data, state)
    VALUE (*proc) _((VALUE));
    VALUE data;
    int *state;
{
    VALUE result = Qnil;	/* OK */
    int status;

    PUSH_TAG(PROT_NONE);
    cont_protect = (VALUE)rb_node_newnode(NODE_MEMO, cont_protect, 0, 0);
    if ((status = EXEC_TAG()) == 0) {
	result = (*proc)(data);
    }
    cont_protect = ((NODE *)cont_protect)-&gt;u1.value;
    POP_TAG();
    if (state) {
	*state = status;
    }
    if (status != 0) {
	return Qnil;
    }

    return result;
}

VALUE
rb_ensure(b_proc, data1, e_proc, data2)
    VALUE (*b_proc)();
    VALUE data1;
    VALUE (*e_proc)();
    VALUE data2;
{
    int state;
    volatile VALUE result = Qnil;
    VALUE retval;

    PUSH_TAG(PROT_NONE);
    if ((state = EXEC_TAG()) == 0) {
	result = (*b_proc)(data1);
    }
    POP_TAG();
    retval = prot_tag ? prot_tag-&gt;retval : Qnil;	/* save retval */
    if (!thread_no_ensure()) {
	(*e_proc)(data2);
    }
    if (prot_tag) return_value(retval);
    if (state) JUMP_TAG(state);
    return result;
}

VALUE
rb_with_disable_interrupt(proc, data)
    VALUE (*proc)();
    VALUE data;
{
    VALUE result = Qnil;	/* OK */
    int status;

    DEFER_INTS;
    {
	int thr_critical = rb_thread_critical;

	rb_thread_critical = Qtrue;
	PUSH_TAG(PROT_NONE);
	if ((status = EXEC_TAG()) == 0) {
	    result = (*proc)(data);
	}
	POP_TAG();
	rb_thread_critical = thr_critical;
    }
    ENABLE_INTS;
    if (status) JUMP_TAG(status);

    return result;
}

static void
stack_check()
{
    static int overflowing = 0;

    if (!overflowing &amp;&amp; ruby_stack_check()) {
	int state;
	overflowing = 1;
	PUSH_TAG(PROT_NONE);
	if ((state = EXEC_TAG()) == 0) {
	    rb_exc_raise(sysstack_error);
	}
	POP_TAG();
	overflowing = 0;
	JUMP_TAG(state);
    }
}

static int last_call_status;

#define CSTAT_PRIV  1
#define CSTAT_PROT  2
#define CSTAT_VCALL 4
#define CSTAT_SUPER 8

/*
 *  call-seq:
 *     obj.method_missing(symbol [, *args] )   =&gt; result
 *  
 *  Invoked by Ruby when &lt;i&gt;obj&lt;/i&gt; is sent a message it cannot handle.
 *  &lt;i&gt;symbol&lt;/i&gt; is the symbol for the method called, and &lt;i&gt;args&lt;/i&gt;
 *  are any arguments that were passed to it. By default, the interpreter
 *  raises an error when this method is called. However, it is possible
 *  to override the method to provide more dynamic behavior.
 *  The example below creates
 *  a class &lt;code&gt;Roman&lt;/code&gt;, which responds to methods with names
 *  consisting of roman numerals, returning the corresponding integer
 *  values.
 *     
 *     class Roman
 *       def romanToInt(str)
 *         # ...
 *       end
 *       def method_missing(methId)
 *         str = methId.id2name
 *         romanToInt(str)
 *       end
 *     end
 *     
 *     r = Roman.new
 *     r.iv      #=&gt; 4
 *     r.xxiii   #=&gt; 23
 *     r.mm      #=&gt; 2000
 */

static VALUE
rb_method_missing(argc, argv, obj)
    int argc;
    VALUE *argv;
    VALUE obj;
{
    ID id;
    VALUE exc = rb_eNoMethodError;
    const char *format = 0;
    NODE *cnode = ruby_current_node;

    if (argc == 0 || !SYMBOL_P(argv[0])) {
	rb_raise(rb_eArgError, &quot;no id given&quot;);
    }

    stack_check();

    id = SYM2ID(argv[0]);

    if (last_call_status &amp; CSTAT_PRIV) {
	format = &quot;private method `%s' called for %s&quot;;
    }
    else if (last_call_status &amp; CSTAT_PROT) {
	format = &quot;protected method `%s' called for %s&quot;;
    }
    else if (last_call_status &amp; CSTAT_VCALL) {
	format = &quot;undefined local variable or method `%s' for %s&quot;;
	exc = rb_eNameError;
    }
    else if (last_call_status &amp; CSTAT_SUPER) {
	format = &quot;super: no superclass method `%s'&quot;;
    }
    if (!format) {
	format = &quot;undefined method `%s' for %s&quot;;
    }

    ruby_current_node = cnode;
    {
	int n = 0;
	VALUE args[3];

	args[n++] = rb_funcall(rb_const_get(exc, rb_intern(&quot;message&quot;)), '!',
			       3, rb_str_new2(format), obj, argv[0]);
	args[n++] = argv[0];
	if (exc == rb_eNoMethodError) {
	    args[n++] = rb_ary_new4(argc-1, argv+1);
	}
	exc = rb_class_new_instance(n, args, exc);
	ruby_frame = ruby_frame-&gt;prev; /* pop frame for &quot;method_missing&quot; */
	rb_exc_raise(exc);
    }

    return Qnil;		/* not reached */
}

static VALUE
method_missing(obj, id, argc, argv, call_status)
    VALUE obj;
    ID    id;
    int   argc;
    const VALUE *argv;
    int   call_status;
{
    VALUE *nargv;

    last_call_status = call_status;

    if (id == missing) {
	PUSH_FRAME();
	rb_method_missing(argc, argv, obj);
	POP_FRAME();
    }
    else if (id == ID_ALLOCATOR) {
	rb_raise(rb_eTypeError, &quot;allocator undefined for %s&quot;, rb_class2name(obj));
    }
    if (argc &lt; 0) {
	VALUE tmp;

	argc = -argc-1;
	tmp = splat_value(argv[argc]);
	nargv = ALLOCA_N(VALUE, argc + RARRAY(tmp)-&gt;len + 1);
	MEMCPY(nargv+1, argv, VALUE, argc);
	MEMCPY(nargv+1+argc, RARRAY(tmp)-&gt;ptr, VALUE, RARRAY(tmp)-&gt;len);
	argc += RARRAY(tmp)-&gt;len;
    }
    else {
	nargv = ALLOCA_N(VALUE, argc+1);
	MEMCPY(nargv+1, argv, VALUE, argc);
    }
    nargv[0] = ID2SYM(id);
    return rb_funcall2(obj, missing, argc+1, nargv);
}

static inline VALUE
call_cfunc(func, recv, len, argc, argv)
    VALUE (*func)();
    VALUE recv;
    int len, argc;
    VALUE *argv;
{
    if (len &gt;= 0 &amp;&amp; argc != len) {
	rb_raise(rb_eArgError, &quot;wrong number of arguments (%d for %d)&quot;,
		 argc, len);
    }

    switch (len) {
      case -2:
	return (*func)(recv, rb_ary_new4(argc, argv));
	break;
      case -1:
	return (*func)(argc, argv, recv);
	break;
      case 0:
	return (*func)(recv);
	break;
      case 1:
	return (*func)(recv, argv[0]);
	break;
      case 2:
	return (*func)(recv, argv[0], argv[1]);
	break;
      case 3:
	return (*func)(recv, argv[0], argv[1], argv[2]);
	break;
      case 4:
	return (*func)(recv, argv[0], argv[1], argv[2], argv[3]);
	break;
      case 5:
	return (*func)(recv, argv[0], argv[1], argv[2], argv[3], argv[4]);
	break;
      case 6:
	return (*func)(recv, argv[0], argv[1], argv[2], argv[3], argv[4],
		       argv[5]);
	break;
      case 7:
	return (*func)(recv, argv[0], argv[1], argv[2], argv[3], argv[4],
		       argv[5], argv[6]);
	break;
      case 8:
	return (*func)(recv, argv[0], argv[1], argv[2], argv[3], argv[4],
		       argv[5], argv[6], argv[7]);
	break;
      case 9:
	return (*func)(recv, argv[0], argv[1], argv[2], argv[3], argv[4],
		       argv[5], argv[6], argv[7], argv[8]);
	break;
      case 10:
	return (*func)(recv, argv[0], argv[1], argv[2], argv[3], argv[4],
		       argv[5], argv[6], argv[7], argv[8], argv[9]);
	break;
      case 11:
	return (*func)(recv, argv[0], argv[1], argv[2], argv[3], argv[4],
		       argv[5], argv[6], argv[7], argv[8], argv[9], argv[10]);
	break;
      case 12:
	return (*func)(recv, argv[0], argv[1], argv[2], argv[3], argv[4],
		       argv[5], argv[6], argv[7], argv[8], argv[9],
		       argv[10], argv[11]);
	break;
      case 13:
	return (*func)(recv, argv[0], argv[1], argv[2], argv[3], argv[4],
		       argv[5], argv[6], argv[7], argv[8], argv[9], argv[10],
		       argv[11], argv[12]);
	break;
      case 14:
	return (*func)(recv, argv[0], argv[1], argv[2], argv[3], argv[4],
		       argv[5], argv[6], argv[7], argv[8], argv[9], argv[10],
		       argv[11], argv[12], argv[13]);
	break;
      case 15:
	return (*func)(recv, argv[0], argv[1], argv[2], argv[3], argv[4],
		       argv[5], argv[6], argv[7], argv[8], argv[9], argv[10],
		       argv[11], argv[12], argv[13], argv[14]);
	break;
      default:
	rb_raise(rb_eArgError, &quot;too many arguments (%d)&quot;, len);
	break;
    }
    return Qnil;		/* not reached */
}

static VALUE
rb_call0(klass, recv, id, oid, argc, argv, body, flags)
    VALUE klass, recv;
    ID    id;
    ID    oid;
    int argc;			/* OK */
    VALUE *argv;		/* OK */
    NODE * volatile body;
    int flags;
{
    NODE *b2;		/* OK */
    volatile VALUE result = Qnil;
    int itr;
    static int tick;
    TMP_PROTECT;
    volatile int safe = -1;

    if (NOEX_SAFE(flags) &gt; ruby_safe_level &amp;&amp;
	ruby_safe_level == 0 &amp;&amp; NOEX_SAFE(flags) &gt; 2) {
	rb_raise(rb_eSecurityError, &quot;calling insecure method: %s&quot;,
		 rb_id2name(id));
    }
    switch (ruby_iter-&gt;iter) {
      case ITER_PRE:
      case ITER_PAS:
	itr = ITER_CUR;
	break;
      case ITER_CUR:
      default:
	itr = ITER_NOT;
	break;
    }

    if ((++tick &amp; 0xff) == 0) {
	CHECK_INTS;		/* better than nothing */
	stack_check();
	rb_gc_finalize_deferred();
    }
    if (argc &lt; 0) {
	VALUE tmp;
	VALUE *nargv;

	argc = -argc-1;
	tmp = splat_value(argv[argc]);
	nargv = TMP_ALLOC(argc + RARRAY(tmp)-&gt;len);
	MEMCPY(nargv, argv, VALUE, argc);
	MEMCPY(nargv+argc, RARRAY(tmp)-&gt;ptr, VALUE, RARRAY(tmp)-&gt;len);
	argc += RARRAY(tmp)-&gt;len;
	argv = nargv;
    }
    PUSH_ITER(itr);
    PUSH_FRAME();

    ruby_frame-&gt;last_func = id;
    ruby_frame-&gt;orig_func = oid;
    ruby_frame-&gt;last_class = (flags &amp; NOEX_NOSUPER)?0:klass;
    ruby_frame-&gt;self = recv;
    ruby_frame-&gt;argc = argc;
    ruby_frame-&gt;flags = 0;

    switch (nd_type(body)) {
      case NODE_CFUNC:
	{
	    int len = body-&gt;nd_argc;

	    if (len &lt; -2) {
		rb_bug(&quot;bad argc (%d) specified for `%s(%s)'&quot;,
		       len, rb_class2name(klass), rb_id2name(id));
	    }
	    if (event_hooks) {
		int state;

		EXEC_EVENT_HOOK(RUBY_EVENT_C_CALL, ruby_current_node,
				recv, id, klass);
		PUSH_TAG(PROT_FUNC);
		if ((state = EXEC_TAG()) == 0) {
		    result = call_cfunc(body-&gt;nd_cfnc, recv, len, argc, argv);
		}
		POP_TAG();
		ruby_current_node = ruby_frame-&gt;node;
		EXEC_EVENT_HOOK(RUBY_EVENT_C_RETURN, ruby_current_node,
				recv, id, klass);
		if (state) JUMP_TAG(state);
	    }
	    else {
		result = call_cfunc(body-&gt;nd_cfnc, recv, len, argc, argv);
	    }
	}
	break;

	/* for attr get/set */
      case NODE_IVAR:
	if (argc != 0) {
	    rb_raise(rb_eArgError, &quot;wrong number of arguments (%d for 0)&quot;, argc);
	}
	result = rb_attr_get(recv, body-&gt;nd_vid);
	break;

      case NODE_ATTRSET:
	if (argc != 1)
	    rb_raise(rb_eArgError, &quot;wrong number of arguments (%d for 1)&quot;, argc);
	result = rb_ivar_set(recv, body-&gt;nd_vid, argv[0]);
	break;

      case NODE_ZSUPER:
	result = rb_call_super(argc, argv);
	break;

      case NODE_DMETHOD:
	result = method_call(argc, argv, umethod_bind(body-&gt;nd_cval, recv));
	break;

      case NODE_BMETHOD:
	ruby_frame-&gt;flags |= FRAME_DMETH;
	if (event_hooks) {
	    struct BLOCK *data;
	    Data_Get_Struct(body-&gt;nd_cval, struct BLOCK, data);
	    EXEC_EVENT_HOOK(RUBY_EVENT_CALL, data-&gt;body, recv, id, klass);
	}
	result = proc_invoke(body-&gt;nd_cval, rb_ary_new4(argc, argv), recv, klass);
	if (event_hooks) {
	    EXEC_EVENT_HOOK(RUBY_EVENT_RETURN, ruby_current_node, recv, id, klass);
	}
	break;

      case NODE_SCOPE:
	{
	    int state;
	    VALUE *local_vars;	/* OK */
	    NODE *saved_cref = 0;

	    PUSH_SCOPE();
	    if (body-&gt;nd_rval) {
		saved_cref = ruby_cref;
		ruby_cref = (NODE*)body-&gt;nd_rval;
	    }
	    PUSH_CLASS(ruby_cbase);
	    if (body-&gt;nd_tbl) {
		local_vars = TMP_ALLOC(body-&gt;nd_tbl[0]+1);
		*local_vars++ = (VALUE)body;
		rb_mem_clear(local_vars, body-&gt;nd_tbl[0]);
		ruby_scope-&gt;local_tbl = body-&gt;nd_tbl;
		ruby_scope-&gt;local_vars = local_vars;
	    }
	    else {
		local_vars = ruby_scope-&gt;local_vars = 0;
		ruby_scope-&gt;local_tbl  = 0;
	    }
	    b2 = body = body-&gt;nd_next;

	    if (NOEX_SAFE(flags) &gt; ruby_safe_level) {
		safe = ruby_safe_level;
		ruby_safe_level = NOEX_SAFE(flags);
	    }
	    PUSH_VARS();
	    PUSH_TAG(PROT_FUNC);
	    if ((state = EXEC_TAG()) == 0) {
		NODE *node = 0;
		int i, nopt = 0;

		if (nd_type(body) == NODE_ARGS) {
		    node = body;
		    body = 0;
		}
		else if (nd_type(body) == NODE_BLOCK) {
		    node = body-&gt;nd_head;
		    body = body-&gt;nd_next;
		}
		if (node) {
		    if (nd_type(node) != NODE_ARGS) {
			rb_bug(&quot;no argument-node&quot;);
		    }

		    i = node-&gt;nd_cnt;
		    if (i &gt; argc) {
			rb_raise(rb_eArgError, &quot;wrong number of arguments (%d for %d)&quot;,
				 argc, i);
		    }
		    if (!node-&gt;nd_rest) {
			NODE *optnode = node-&gt;nd_opt;

			nopt = i;
			while (optnode) {
			    nopt++;
			    optnode = optnode-&gt;nd_next;
			}
			if (nopt &lt; argc) {
			    rb_raise(rb_eArgError,
				     &quot;wrong number of arguments (%d for %d)&quot;,
				     argc, nopt);
			}
		    }
		    if (local_vars) {
			if (i &gt; 0) {
			    /* +2 for $_ and $~ */
			    MEMCPY(local_vars+2, argv, VALUE, i);
			}
		    }
		    argv += i; argc -= i;
		    if (node-&gt;nd_opt) {
			NODE *opt = node-&gt;nd_opt;

			while (opt &amp;&amp; argc) {
			    assign(recv, opt-&gt;nd_head, *argv, 1);
			    argv++; argc--;
			    ++i;
			    opt = opt-&gt;nd_next;
			}
			if (opt) {
			    rb_eval(recv, opt);
			    while (opt) {
				opt = opt-&gt;nd_next;
				++i;
			    }
			}
		    }
		    if (!node-&gt;nd_rest) {
			i = nopt;
		    }
		    else {
			VALUE v;
			
			if (argc &gt; 0) {
			    v = rb_ary_new4(argc,argv);
			    i = -i - 1;
			}
			else {
			    v = rb_ary_new2(0);
			}
			assign(recv, node-&gt;nd_rest, v, 1);
		    }
		    ruby_frame-&gt;argc = i;
		}
		if (event_hooks) {
		    EXEC_EVENT_HOOK(RUBY_EVENT_CALL, b2, recv, id, klass);
		}
		result = rb_eval(recv, body);
	    }
	    else if (state == TAG_RETURN &amp;&amp; TAG_DST()) {
		result = prot_tag-&gt;retval;
		state = 0;
	    }
	    POP_TAG();
	    if (event_hooks) {
		EXEC_EVENT_HOOK(RUBY_EVENT_RETURN, ruby_current_node, recv, id, klass);
	    }
	    POP_VARS();
	    POP_CLASS();
	    POP_SCOPE();
	    ruby_cref = saved_cref;
	    if (safe &gt;= 0) ruby_safe_level = safe;
	    switch (state) {
	      case 0:
		break;

	      case TAG_BREAK:
	      case TAG_RETURN:
		JUMP_TAG(state);
		break;

	      case TAG_RETRY:
		if (rb_block_given_p()) JUMP_TAG(state);
		/* fall through */
	      default:
		jump_tag_but_local_jump(state, result);
		break;
	    }
	}
	break;

      default:
	unknown_node(body);
	break;
    }
    POP_FRAME();
    POP_ITER();
    return result;
}

static VALUE
rb_call(klass, recv, mid, argc, argv, scope, self)
    VALUE klass, recv;
    ID    mid;
    int argc;			/* OK */
    const VALUE *argv;		/* OK */
    int scope;
    VALUE self;
{
    NODE  *body;		/* OK */
    int    noex;
    ID     id = mid;
    struct cache_entry *ent;

    if (!klass) {
	rb_raise(rb_eNotImpError, &quot;method `%s' called on terminated object (0x%lx)&quot;,
		 rb_id2name(mid), recv);
    }
    /* is it in the method cache? */
    ent = cache + EXPR1(klass, mid);
    if (ent-&gt;mid == mid &amp;&amp; ent-&gt;klass == klass) {
	if (!ent-&gt;method)
	    return method_missing(recv, mid, argc, argv, scope==2?CSTAT_VCALL:0);
	klass = ent-&gt;origin;
	id    = ent-&gt;mid0;
	noex  = ent-&gt;noex;
	body  = ent-&gt;method;
    }
    else if ((body = rb_get_method_body(&amp;klass, &amp;id, &amp;noex)) == 0) {
	if (scope == 3) {
	    return method_missing(recv, mid, argc, argv, CSTAT_SUPER);
	}
	return method_missing(recv, mid, argc, argv, scope==2?CSTAT_VCALL:0);
    }

    if (mid != missing &amp;&amp; scope == 0) {
	/* receiver specified form for private method */
	if (noex &amp; NOEX_PRIVATE)
	    return method_missing(recv, mid, argc, argv, CSTAT_PRIV);

	/* self must be kind of a specified form for protected method */
	if (noex &amp; NOEX_PROTECTED) {
	    VALUE defined_class = klass;

	    if (self == Qundef) self = ruby_frame-&gt;self;
	    if (TYPE(defined_class) == T_ICLASS) {
		defined_class = RBASIC(defined_class)-&gt;klass;
	    }
	    if (!rb_obj_is_kind_of(self, rb_class_real(defined_class)))
		return method_missing(recv, mid, argc, argv, CSTAT_PROT);
	}
    }

    return rb_call0(klass, recv, mid, id, argc, argv, body, noex);
}

VALUE
rb_apply(recv, mid, args)
    VALUE recv;
    ID mid;
    VALUE args;
{
    int argc;
    VALUE *argv;

    argc = RARRAY(args)-&gt;len; /* Assigns LONG, but argc is INT */
    argv = ALLOCA_N(VALUE, argc);
    MEMCPY(argv, RARRAY(args)-&gt;ptr, VALUE, argc);
    return rb_call(CLASS_OF(recv), recv, mid, argc, argv, 1, Qundef);
}

/*
 *  call-seq:
 *     obj.send(symbol [, args...])        =&gt; obj
 *     obj.__send__(symbol [, args...])    =&gt; obj
 *  
 *  Invokes the method identified by _symbol_, passing it any
 *  arguments specified. You can use &lt;code&gt;\_\_send__&lt;/code&gt; if the name
 *  +send+ clashes with an existing method in _obj_.
 *     
 *     class Klass
 *       def hello(*args)
 *         &quot;Hello &quot; + args.join(' ')
 *       end
 *     end
 *     k = Klass.new
 *     k.send :hello, &quot;gentle&quot;, &quot;readers&quot;   #=&gt; &quot;Hello gentle readers&quot;
 */

static VALUE
rb_f_send(argc, argv, recv)
    int argc;
    VALUE *argv;
    VALUE recv;
{
    VALUE vid;

    if (argc == 0) rb_raise(rb_eArgError, &quot;no method name given&quot;);

    vid = *argv++; argc--;
    PUSH_ITER(rb_block_given_p()?ITER_PRE:ITER_NOT);
    vid = rb_call(CLASS_OF(recv), recv, rb_to_id(vid), argc, argv, 1, Qundef);
    POP_ITER();

    return vid;
}

static VALUE
vafuncall(recv, mid, n, ar)
    VALUE recv;
    ID mid;
    int n;
    va_list *ar;
{
    VALUE *argv;

    if (n &gt; 0) {
	long i;

	argv = ALLOCA_N(VALUE, n);

	for (i=0;i&lt;n;i++) {
	    argv[i] = va_arg(*ar, VALUE);
	}
	va_end(*ar);
    }
    else {
	argv = 0;
    }

    return rb_call(CLASS_OF(recv), recv, mid, n, argv, 1, Qundef);
}

VALUE
#ifdef HAVE_STDARG_PROTOTYPES
rb_funcall(VALUE recv, ID mid, int n, ...)
#else
rb_funcall(recv, mid, n, va_alist)
    VALUE recv;
    ID mid;
    int n;
    va_dcl
#endif
{
    va_list ar;
    va_init_list(ar, n);

    return vafuncall(recv, mid, n, &amp;ar);
}

VALUE
#ifdef HAVE_STDARG_PROTOTYPES
rb_funcall_rescue(VALUE recv, ID mid, int n, ...)
#else
rb_funcall_rescue(recv, mid, n, va_alist)
    VALUE recv;
    ID mid;
    int n;
    va_dcl
#endif
{
    VALUE result = Qnil;	/* OK */
    int status;
    va_list ar;

    va_init_list(ar, n);

    PUSH_TAG(PROT_NONE);
    if ((status = EXEC_TAG()) == 0) {
	result = vafuncall(recv, mid, n, &amp;ar);
    }
    POP_TAG();
    switch (status) {
      case 0:
	return result;
      case TAG_RAISE:
	return Qundef;
      default:
	JUMP_TAG(status);
    }
}

VALUE
rb_funcall2(recv, mid, argc, argv)
    VALUE recv;
    ID mid;
    int argc;
    const VALUE *argv;
{
    return rb_call(CLASS_OF(recv), recv, mid, argc, argv, 1, Qundef);
}

VALUE
rb_funcall3(recv, mid, argc, argv)
    VALUE recv;
    ID mid;
    int argc;
    const VALUE *argv;
{
    return rb_call(CLASS_OF(recv), recv, mid, argc, argv, 0, Qundef);
}

VALUE
rb_call_super(argc, argv)
    int argc;
    const VALUE *argv;
{
    VALUE result, self, klass;

    if (ruby_frame-&gt;last_class == 0) {
	rb_name_error(ruby_frame-&gt;last_func, &quot;calling `super' from `%s' is prohibited&quot;,
		      rb_id2name(ruby_frame-&gt;orig_func));
    }

    self = ruby_frame-&gt;self;
    klass = ruby_frame-&gt;last_class;
    if (RCLASS(klass)-&gt;super == 0) {
	return method_missing(self, ruby_frame-&gt;orig_func, argc, argv, CSTAT_SUPER);
    }

    PUSH_ITER(ruby_iter-&gt;iter ? ITER_PRE : ITER_NOT);
    result = rb_call(RCLASS(klass)-&gt;super, self, ruby_frame-&gt;orig_func, argc, argv, 3, Qundef);
    POP_ITER();

    return result;
}

static VALUE
backtrace(lev)
    int lev;
{
    struct FRAME *frame = ruby_frame;
    char buf[BUFSIZ];
    VALUE ary;
    NODE *n;

    ary = rb_ary_new();
    if (frame-&gt;last_func == ID_ALLOCATOR) {
	frame = frame-&gt;prev;
    }
    if (lev &lt; 0) {
	ruby_set_current_source();
	if (frame-&gt;last_func) {
	    snprintf(buf, BUFSIZ, &quot;%s:%d:in `%s'&quot;,
		     ruby_sourcefile, ruby_sourceline,
		     rb_id2name(frame-&gt;last_func));
	}
	else if (ruby_sourceline == 0) {
	    snprintf(buf, BUFSIZ, &quot;%s&quot;, ruby_sourcefile);
	}
	else {
	    snprintf(buf, BUFSIZ, &quot;%s:%d&quot;, ruby_sourcefile, ruby_sourceline);
	}
	rb_ary_push(ary, rb_str_new2(buf));
	if (lev &lt; -1) return ary;
    }
    else {
	while (lev-- &gt; 0) {
	    frame = frame-&gt;prev;
	    if (!frame) {
		ary = Qnil;
		break;
	    }
	}
    }
    for (; frame &amp;&amp; (n = frame-&gt;node); frame = frame-&gt;prev) {
	if (frame-&gt;prev &amp;&amp; frame-&gt;prev-&gt;last_func) {
	    if (frame-&gt;prev-&gt;node == n) {
		if (frame-&gt;prev-&gt;last_func == frame-&gt;last_func) continue;
	    }
	    snprintf(buf, BUFSIZ, &quot;%s:%d:in `%s'&quot;,
		     n-&gt;nd_file, nd_line(n),
		     rb_id2name(frame-&gt;prev-&gt;last_func));
	}
	else {
	    snprintf(buf, BUFSIZ, &quot;%s:%d&quot;, n-&gt;nd_file, nd_line(n));
	}
	rb_ary_push(ary, rb_str_new2(buf));
    }

    return ary;
}

/*
 *  call-seq:
 *     caller(start=1)    =&gt; array
 *  
 *  Returns the current execution stack---an array containing strings in
 *  the form ``&lt;em&gt;file:line&lt;/em&gt;'' or ``&lt;em&gt;file:line: in
 *  `method'&lt;/em&gt;''. The optional _start_ parameter
 *  determines the number of initial stack entries to omit from the
 *  result.
 *     
 *     def a(skip)
 *       caller(skip)
 *     end
 *     def b(skip)
 *       a(skip)
 *     end
 *     def c(skip)
 *       b(skip)
 *     end
 *     c(0)   #=&gt; [&quot;prog:2:in `a'&quot;, &quot;prog:5:in `b'&quot;, &quot;prog:8:in `c'&quot;, &quot;prog:10&quot;]
 *     c(1)   #=&gt; [&quot;prog:5:in `b'&quot;, &quot;prog:8:in `c'&quot;, &quot;prog:11&quot;]
 *     c(2)   #=&gt; [&quot;prog:8:in `c'&quot;, &quot;prog:12&quot;]
 *     c(3)   #=&gt; [&quot;prog:13&quot;]
 */

static VALUE
rb_f_caller(argc, argv)
    int argc;
    VALUE *argv;
{
    VALUE level;
    int lev;

    rb_scan_args(argc, argv, &quot;01&quot;, &amp;level);

    if (NIL_P(level)) lev = 1;
    else lev = NUM2INT(level);
    if (lev &lt; 0) rb_raise(rb_eArgError, &quot;negative level (%d)&quot;, lev);

    return backtrace(lev);
}

void
rb_backtrace()
{
    long i;
    VALUE ary;

    ary = backtrace(-1);
    for (i=0; i&lt;RARRAY(ary)-&gt;len; i++) {
	printf(&quot;\tfrom %s\n&quot;, RSTRING(RARRAY(ary)-&gt;ptr[i])-&gt;ptr);
    }
}

static VALUE
make_backtrace()
{
    return backtrace(-1);
}

ID
rb_frame_last_func()
{
    return ruby_frame-&gt;last_func;
}

ID
rb_frame_this_func()
{
    return ruby_frame-&gt;orig_func;
}

static NODE*
compile(src, file, line)
    VALUE src;
    const char *file;
    int line;
{
    NODE *node;
    int critical;

    ruby_nerrs = 0;
    StringValue(src);
    critical = rb_thread_critical;
    rb_thread_critical = Qtrue;
    node = rb_compile_string(file, src, line);
    rb_thread_critical = critical;

    if (ruby_nerrs == 0) return node;
    return 0;
}

static VALUE
eval(self, src, scope, file, line)
    VALUE self, src, scope;
    const char *file;
    int line;
{
    struct BLOCK *data = NULL;
    volatile VALUE result = Qnil;
    struct SCOPE * volatile old_scope;
    struct BLOCK * volatile old_block;
    struct RVarmap * volatile old_dyna_vars;
    VALUE volatile old_cref;
    int volatile old_vmode;
    volatile VALUE old_wrapper;
    struct FRAME frame;
    NODE *nodesave = ruby_current_node;
    volatile int iter = ruby_frame-&gt;iter;
    volatile int safe = ruby_safe_level;
    int state;

    if (!NIL_P(scope)) {
	if (!rb_obj_is_proc(scope)) {
	    rb_raise(rb_eTypeError, &quot;wrong argument type %s (expected Proc/Binding)&quot;,
		     rb_obj_classname(scope));
	}

	Data_Get_Struct(scope, struct BLOCK, data);
	/* PUSH BLOCK from data */
	frame = data-&gt;frame;
	frame.tmp = ruby_frame;	/* gc protection */
	ruby_frame = &amp;(frame);
	old_scope = ruby_scope;
	ruby_scope = data-&gt;scope;
	old_block = ruby_block;
	ruby_block = data-&gt;prev;
	old_dyna_vars = ruby_dyna_vars;
	ruby_dyna_vars = data-&gt;dyna_vars;
	old_vmode = scope_vmode;
	scope_vmode = data-&gt;vmode;
	old_cref = (VALUE)ruby_cref;
	ruby_cref = data-&gt;cref;
	old_wrapper = ruby_wrapper;
	ruby_wrapper = data-&gt;wrapper;
	if ((file == 0 || (line == 1 &amp;&amp; strcmp(file, &quot;(eval)&quot;) == 0)) &amp;&amp; data-&gt;frame.node) {
	    file = data-&gt;frame.node-&gt;nd_file;
	    if (!file) file = &quot;__builtin__&quot;;
	    line = nd_line(data-&gt;frame.node);
	}

	self = data-&gt;self;
	ruby_frame-&gt;iter = data-&gt;iter;
    }
    else {
	if (ruby_frame-&gt;prev) {
	    ruby_frame-&gt;iter = ruby_frame-&gt;prev-&gt;iter;
	}
    }
    if (file == 0) {
	ruby_set_current_source();
	file = ruby_sourcefile;
	line = ruby_sourceline;
    }
    PUSH_CLASS(data ? data-&gt;klass : ruby_class);
    ruby_in_eval++;
    if (TYPE(ruby_class) == T_ICLASS) {
	ruby_class = RBASIC(ruby_class)-&gt;klass;
    }
    PUSH_TAG(PROT_NONE);
    if ((state = EXEC_TAG()) == 0) {
	NODE *node;

	ruby_safe_level = 0;
	result = ruby_errinfo;
	ruby_errinfo = Qnil;
	node = compile(src, file, line);
	ruby_safe_level = safe;
	if (ruby_nerrs &gt; 0) {
	    compile_error(0);
	}
	if (!NIL_P(result)) ruby_errinfo = result;
	result = eval_node(self, node);
    }
    POP_TAG();
    POP_CLASS();
    ruby_in_eval--;
    if (!NIL_P(scope)) {
	int dont_recycle = ruby_scope-&gt;flags &amp; SCOPE_DONT_RECYCLE;

	ruby_wrapper = old_wrapper;
	ruby_cref  = (NODE*)old_cref;
	ruby_frame = frame.tmp;
	ruby_scope = old_scope;
	ruby_block = old_block;
	ruby_dyna_vars = old_dyna_vars;
	data-&gt;vmode = scope_vmode; /* write back visibility mode */
	scope_vmode = old_vmode;
	if (dont_recycle) {
	    struct tag *tag;
	    struct RVarmap *vars;

	    scope_dup(ruby_scope);
	    for (tag=prot_tag; tag; tag=tag-&gt;prev) {
		scope_dup(tag-&gt;scope);
	    }
	    for (vars = ruby_dyna_vars; vars; vars = vars-&gt;next) {
		FL_SET(vars, DVAR_DONT_RECYCLE);
	    }
	}
    }
    else {
	ruby_frame-&gt;iter = iter;
    }
    ruby_current_node = nodesave;
    ruby_set_current_source();
    if (state) {
	if (state == TAG_RAISE) {
	    if (strcmp(file, &quot;(eval)&quot;) == 0) {
		VALUE mesg, errat, bt2;

		errat = get_backtrace(ruby_errinfo);
		mesg = rb_attr_get(ruby_errinfo, rb_intern(&quot;mesg&quot;));
		if (!NIL_P(errat) &amp;&amp; TYPE(errat) == T_ARRAY &amp;&amp;
		    (bt2 = backtrace(-2), RARRAY_LEN(bt2) &gt; 0)) {
		    if (!NIL_P(mesg) &amp;&amp; TYPE(mesg) == T_STRING) {
			rb_str_update(mesg, 0, 0, rb_str_new2(&quot;: &quot;));
			rb_str_update(mesg, 0, 0, RARRAY_PTR(errat)[0]);
		    }
		    RARRAY_PTR(errat)[0] = RARRAY_PTR(bt2)[0];
		}
	    }
	    rb_exc_raise(ruby_errinfo);
	}
	JUMP_TAG(state);
    }

    return result;
}

/*
 *  call-seq:
 *     eval(string [, binding [, filename [,lineno]]])  =&gt; obj
 *  
 *  Evaluates the Ruby expression(s) in &lt;em&gt;string&lt;/em&gt;. If
 *  &lt;em&gt;binding&lt;/em&gt; is given, the evaluation is performed in its
 *  context. The binding may be a &lt;code&gt;Binding&lt;/code&gt; object or a
 *  &lt;code&gt;Proc&lt;/code&gt; object. If the optional &lt;em&gt;filename&lt;/em&gt; and
 *  &lt;em&gt;lineno&lt;/em&gt; parameters are present, they will be used when
 *  reporting syntax errors.
 *     
 *     def getBinding(str)
 *       return binding
 *     end
 *     str = &quot;hello&quot;
 *     eval &quot;str + ' Fred'&quot;                      #=&gt; &quot;hello Fred&quot;
 *     eval &quot;str + ' Fred'&quot;, getBinding(&quot;bye&quot;)   #=&gt; &quot;bye Fred&quot;
 */

static VALUE
rb_f_eval(argc, argv, self)
    int argc;
    VALUE *argv;
    VALUE self;
{
    VALUE src, scope, vfile, vline;
    const char *file = &quot;(eval)&quot;;
    int line = 1;

    rb_scan_args(argc, argv, &quot;13&quot;, &amp;src, &amp;scope, &amp;vfile, &amp;vline);
    if (ruby_safe_level &gt;= 4) {
	StringValue(src);
	if (!NIL_P(scope) &amp;&amp; !OBJ_TAINTED(scope)) {
	    rb_raise(rb_eSecurityError, &quot;Insecure: can't modify trusted binding&quot;);
	}
    }
    else {
	SafeStringValue(src);
    }
    if (argc &gt;= 3) {
	StringValue(vfile);
    }
    if (argc &gt;= 4) {
	line = NUM2INT(vline);
    }

    if (!NIL_P(vfile)) file = RSTRING(vfile)-&gt;ptr;
    if (NIL_P(scope) &amp;&amp; ruby_frame-&gt;prev) {
	struct FRAME *prev;
	VALUE val;

	prev = ruby_frame;
	PUSH_FRAME();
	*ruby_frame = *prev-&gt;prev;
	ruby_frame-&gt;prev = prev;
	val = eval(self, src, scope, file, line);
	POP_FRAME();

	return val;
    }
    return eval(self, src, scope, file, line);
}

/* function to call func under the specified class/module context */
static VALUE
exec_under(func, under, cbase, args)
    VALUE (*func)();
    VALUE under, cbase;
    void *args;
{
    VALUE val = Qnil;		/* OK */
    int state;
    int mode;
    struct FRAME *f = ruby_frame;

    PUSH_CLASS(under);
    PUSH_FRAME();
    ruby_frame-&gt;self = f-&gt;self;
    ruby_frame-&gt;last_func = f-&gt;last_func;
    ruby_frame-&gt;orig_func = f-&gt;orig_func;
    ruby_frame-&gt;last_class = f-&gt;last_class;
    ruby_frame-&gt;argc = f-&gt;argc;
    if (cbase) {
	PUSH_CREF(cbase);
    }

    mode = scope_vmode;
    SCOPE_SET(SCOPE_PUBLIC);
    PUSH_TAG(PROT_NONE);
    if ((state = EXEC_TAG()) == 0) {
	val = (*func)(args);
    }
    POP_TAG();
    if (cbase) POP_CREF();
    SCOPE_SET(mode);
    POP_FRAME();
    POP_CLASS();
    if (state) JUMP_TAG(state);

    return val;
}

static VALUE
eval_under_i(args)
    VALUE *args;
{
    struct FRAME *f = ruby_frame;

    if (f &amp;&amp; (f = f-&gt;prev) &amp;&amp; (f = f-&gt;prev)) {
	ruby_frame = f;
    }
    return eval(args[0], args[1], Qnil, (char*)args[2], (int)args[3]);
}

/* string eval under the class/module context */
static VALUE
eval_under(under, self, src, file, line)
    VALUE under, self, src;
    const char *file;
    int line;
{
    VALUE args[4];

    if (ruby_safe_level &gt;= 4) {
	StringValue(src);
    }
    else {
	SafeStringValue(src);
    }
    args[0] = self;
    args[1] = src;
    args[2] = (VALUE)file;
    args[3] = (VALUE)line;
    return exec_under(eval_under_i, under, under, args);
}

static VALUE
yield_under_i(self)
    VALUE self;
{
    return rb_yield_0(self, self, ruby_class, YIELD_PUBLIC_DEF, Qfalse);
}

static VALUE
yield_args_under_i(vinfo)
    VALUE vinfo;
{
    VALUE *info = (VALUE *)vinfo;

    return rb_yield_0(info[0], info[1], ruby_class, YIELD_PUBLIC_DEF, Qtrue);
}

/* block eval under the class/module context */
static VALUE
yield_under(under, self, args)
    VALUE under, self, args;
{
    if (args == Qundef) {
	return exec_under(yield_under_i, under, 0, self);
    }
    else {
	VALUE info[2] = { args, self };

	return exec_under(yield_args_under_i, under, 0, (VALUE)info);
    }
}

static VALUE
specific_eval(argc, argv, klass, self)
    int argc;
    VALUE *argv;
    VALUE klass, self;
{
    if (rb_block_given_p()) {
	if (argc &gt; 0) {
	    rb_raise(rb_eArgError, &quot;wrong number of arguments (%d for 0)&quot;, argc);
	}
	return yield_under(klass, self, Qundef);
    }
    else {
	const char *file = &quot;(eval)&quot;;
	int   line = 1;

	if (argc == 0) {
	    rb_raise(rb_eArgError, &quot;block not supplied&quot;);
	}
	else {
	    if (ruby_safe_level &gt;= 4) {
		StringValue(argv[0]);
	    }
	    else {
		SafeStringValue(argv[0]);
	    }
	    if (argc &gt; 3) {
		rb_raise(rb_eArgError, &quot;wrong number of arguments: %s(src) or %s{..}&quot;,
			 rb_id2name(ruby_frame-&gt;last_func),
			 rb_id2name(ruby_frame-&gt;last_func));
	    }
	    if (argc &gt; 2) line = NUM2INT(argv[2]);
	    if (argc &gt; 1) {
		file = StringValuePtr(argv[1]);
	    }
	}
	return eval_under(klass, self, argv[0], file, line);
    }
}

/*
 *  call-seq:
 *     obj.instance_eval(string [, filename [, lineno]] )   =&gt; obj
 *     obj.instance_eval {| | block }                       =&gt; obj
 *  
 *  Evaluates a string containing Ruby source code, or the given block,
 *  within the context of the receiver (_obj_). In order to set the
 *  context, the variable +self+ is set to _obj_ while
 *  the code is executing, giving the code access to _obj_'s
 *  instance variables. In the version of &lt;code&gt;instance_eval&lt;/code&gt;
 *  that takes a +String+, the optional second and third
 *  parameters supply a filename and starting line number that are used
 *  when reporting compilation errors.
 *     
 *     class Klass
 *       def initialize
 *         @secret = 99
 *       end
 *     end
 *     k = Klass.new
 *     k.instance_eval { @secret }   #=&gt; 99
 */

VALUE
rb_obj_instance_eval(argc, argv, self)
    int argc;
    VALUE *argv;
    VALUE self;
{
    VALUE klass;

    if (SPECIAL_CONST_P(self)) {
	klass = Qnil;
    }
    else {
	klass = rb_singleton_class(self);
    }
    return specific_eval(argc, argv, klass, self);
}

/*
 *  call-seq:
 *     obj.instance_exec(arg...) {|var...| block }                       =&gt; obj
 *
 *  Executes the given block within the context of the receiver
 *  (_obj_). In order to set the context, the variable +self+ is set
 *  to _obj_ while the code is executing, giving the code access to
 *  _obj_'s instance variables.  Arguments are passed as block parameters.
 *
 *     class KlassWithSecret
 *       def initialize
 *         @secret = 99
 *       end
 *     end
 *     k = KlassWithSecret.new
 *     k.instance_exec(5) {|x| @secret+x }   #=&gt; 104
 */

VALUE
rb_obj_instance_exec(argc, argv, self)
    int argc;
    VALUE *argv;
    VALUE self;
{
    VALUE klass;

    if (SPECIAL_CONST_P(self)) {
	klass = Qnil;
    }
    else {
	klass = rb_singleton_class(self);
    }
    return yield_under(klass, self, rb_ary_new4(argc, argv));
}

/*
 *  call-seq:
 *     mod.class_eval(string [, filename [, lineno]])  =&gt; obj
 *     mod.module_eval {|| block }                     =&gt; obj
 *  
 *  Evaluates the string or block in the context of _mod_. This can
 *  be used to add methods to a class. &lt;code&gt;module_eval&lt;/code&gt; returns
 *  the result of evaluating its argument. The optional _filename_
 *  and _lineno_ parameters set the text for error messages.
 *     
 *     class Thing
 *     end
 *     a = %q{def hello() &quot;Hello there!&quot; end}
 *     Thing.module_eval(a)
 *     puts Thing.new.hello()
 *     Thing.module_eval(&quot;invalid code&quot;, &quot;dummy&quot;, 123)
 *     
 *  &lt;em&gt;produces:&lt;/em&gt;
 *     
 *     Hello there!
 *     dummy:123:in `module_eval': undefined local variable
 *         or method `code' for Thing:Class
 */

VALUE
rb_mod_module_eval(argc, argv, mod)
    int argc;
    VALUE *argv;
    VALUE mod;
{
    return specific_eval(argc, argv, mod, mod);
}

/*
 *  call-seq:
 *     mod.module_exec(arg...) {|var...| block }       =&gt; obj
 *     mod.class_exec(arg...) {|var...| block }        =&gt; obj
 *
 *  Evaluates the given block in the context of the class/module.
 *  The method defined in the block will belong to the receiver.
 *
 *     class Thing
 *     end
 *     Thing.class_exec{
 *       def hello() &quot;Hello there!&quot; end
 *     }
 *     puts Thing.new.hello()
 *
 *  &lt;em&gt;produces:&lt;/em&gt;
 *
 *     Hello there!
 */

VALUE
rb_mod_module_exec(argc, argv, mod)
    int argc;
    VALUE *argv;
    VALUE mod;
{
    return yield_under(mod, mod, rb_ary_new4(argc, argv));
}

VALUE rb_load_path;

NORETURN(static void load_failed _((VALUE)));

void
rb_load(fname, wrap)
    VALUE fname;
    int wrap;
{
    VALUE tmp;
    int state;
    volatile int prohibit_int = rb_prohibit_interrupt;
    volatile ID last_func;
    volatile VALUE wrapper = ruby_wrapper;
    volatile VALUE self = ruby_top_self;
    NODE *volatile last_node;
    NODE *saved_cref = ruby_cref;

    if (wrap &amp;&amp; ruby_safe_level &gt;= 4) {
	StringValue(fname);
    }
    else {
	SafeStringValue(fname);
    }
    fname = rb_str_new4(fname);
    tmp = rb_find_file(fname);
    if (!tmp) {
	load_failed(fname);
    }
    fname = tmp;

    ruby_errinfo = Qnil;	/* ensure */
    PUSH_VARS();
    PUSH_CLASS(ruby_wrapper);
    ruby_cref = ruby_top_cref;
    if (!wrap) {
	rb_secure(4);		/* should alter global state */
	ruby_class = rb_cObject;
	ruby_wrapper = 0;
    }
    else {
	/* load in anonymous module as toplevel */
	ruby_class = ruby_wrapper = rb_module_new();
	self = rb_obj_clone(ruby_top_self);
	rb_extend_object(self, ruby_wrapper);
	PUSH_CREF(ruby_wrapper);
    }
    PUSH_ITER(ITER_NOT);
    PUSH_FRAME();
    ruby_frame-&gt;last_func = 0;
    ruby_frame-&gt;last_class = 0;
    ruby_frame-&gt;self = self;
    PUSH_SCOPE();
    /* default visibility is private at loading toplevel */
    SCOPE_SET(SCOPE_PRIVATE);
    PUSH_TAG(PROT_NONE);
    state = EXEC_TAG();
    last_func = ruby_frame-&gt;last_func;
    last_node = ruby_current_node;
    if (!ruby_current_node &amp;&amp; ruby_sourcefile) {
	last_node = NEW_NEWLINE(0);
    }
    ruby_current_node = 0;
    if (state == 0) {
	NODE *node;
	volatile int critical;

	DEFER_INTS;
	ruby_in_eval++;
	critical = rb_thread_critical;
	rb_thread_critical = Qtrue;
	rb_load_file(RSTRING(fname)-&gt;ptr);
	ruby_in_eval--;
	node = ruby_eval_tree;
	rb_thread_critical = critical;
	ALLOW_INTS;
	if (ruby_nerrs == 0) {
	    eval_node(self, node);
	}
    }
    ruby_frame-&gt;last_func = last_func;
    ruby_current_node = last_node;
    ruby_sourcefile = 0;
    ruby_set_current_source();
    if (ruby_scope-&gt;flags == SCOPE_ALLOCA &amp;&amp; ruby_class == rb_cObject) {
	if (ruby_scope-&gt;local_tbl) /* toplevel was empty */
	    free(ruby_scope-&gt;local_tbl);
    }
    POP_TAG();
    rb_prohibit_interrupt = prohibit_int;
    ruby_cref = saved_cref;
    POP_SCOPE();
    POP_FRAME();
    POP_ITER();
    POP_CLASS();
    POP_VARS();
    ruby_wrapper = wrapper;
    if (ruby_nerrs &gt; 0) {
	ruby_nerrs = 0;
	rb_exc_raise(ruby_errinfo);
    }
    if (state) jump_tag_but_local_jump(state, Qundef);
    if (!NIL_P(ruby_errinfo))	/* exception during load */
	rb_exc_raise(ruby_errinfo);
}

void
rb_load_protect(fname, wrap, state)
    VALUE fname;
    int wrap;
    int *state;
{
    int status;

    PUSH_TAG(PROT_NONE);
    if ((status = EXEC_TAG()) == 0) {
	rb_load(fname, wrap);
    }
    POP_TAG();
    if (state) *state = status;
}

/*
 *  call-seq:
 *     load(filename, wrap=false)   =&gt; true
 *  
 *  Loads and executes the Ruby
 *  program in the file _filename_. If the filename does not
 *  resolve to an absolute path, the file is searched for in the library
 *  directories listed in &lt;code&gt;$:&lt;/code&gt;. If the optional _wrap_
 *  parameter is +true+, the loaded script will be executed
 *  under an anonymous module, protecting the calling program's global
 *  namespace. In no circumstance will any local variables in the loaded
 *  file be propagated to the loading environment.
 */


static VALUE
rb_f_load(argc, argv)
    int argc;
    VALUE *argv;
{
    VALUE fname, wrap;

    rb_scan_args(argc, argv, &quot;11&quot;, &amp;fname, &amp;wrap);
    rb_load(fname, RTEST(wrap));
    return Qtrue;
}

VALUE ruby_dln_librefs;
static VALUE rb_features;
static st_table *loading_tbl;

#define IS_SOEXT(e) (strcmp(e, &quot;.so&quot;) == 0 || strcmp(e, &quot;.o&quot;) == 0)
#ifdef DLEXT2
#define IS_DLEXT(e) (strcmp(e, DLEXT) == 0 || strcmp(e, DLEXT2) == 0)
#else
#define IS_DLEXT(e) (strcmp(e, DLEXT) == 0)
#endif


static const char *const loadable_ext[] = {
    &quot;.rb&quot;, DLEXT,
#ifdef DLEXT2
    DLEXT2,
#endif
    0
};

static int rb_feature_p _((const char *, const char *, int));
static int search_required _((VALUE, VALUE *, VALUE *));

static int
rb_feature_p(feature, ext, rb)
    const char *feature, *ext;
    int rb;
{
    VALUE v;
    const char *f, *e;
    long i, len, elen;

    if (ext) {
	len = ext - feature;
	elen = strlen(ext);
    }
    else {
	len = strlen(feature);
	elen = 0;
    }
    for (i = 0; i &lt; RARRAY_LEN(rb_features); ++i) {
	v = RARRAY_PTR(rb_features)[i];
	f = StringValuePtr(v);
	if (RSTRING_LEN(v) &lt; len || strncmp(f, feature, len) != 0)
	    continue;
	if (!*(e = f + len)) {
	    if (ext) continue;
	    return 'u';
	}
	if (*e != '.') continue;
	if ((!rb || !ext) &amp;&amp; (IS_SOEXT(e) || IS_DLEXT(e))) {
	    return 's';
	}
	if ((rb || !ext) &amp;&amp; (strcmp(e, &quot;.rb&quot;) == 0)) {
	    return 'r';
	}
    }
    if (loading_tbl) {
	if (st_lookup(loading_tbl, (st_data_t)feature, 0)) {
	    if (!ext) return 'u';
	    return strcmp(ext, &quot;.rb&quot;) ? 's' : 'r';
	}
	else {
	    char *buf;

	    if (ext &amp;&amp; *ext) return 0;
	    buf = ALLOCA_N(char, len + DLEXT_MAXLEN + 1);
	    MEMCPY(buf, feature, char, len);
	    for (i = 0; (e = loadable_ext[i]) != 0; i++) {
		strncpy(buf + len, e, DLEXT_MAXLEN + 1);
		if (st_lookup(loading_tbl, (st_data_t)buf, 0)) {
		    return i ? 's' : 'r';
		}
	    }
	}
    }
    return 0;
}

int
rb_provided(feature)
    const char *feature;
{
    const char *ext = strrchr(feature, '.');

    if (ext &amp;&amp; !strchr(ext, '/')) {
	if (strcmp(&quot;.rb&quot;, ext) == 0) {
	    if (rb_feature_p(feature, ext, Qtrue)) return Qtrue;
	    return Qfalse;
	}
	else if (IS_SOEXT(ext) || IS_DLEXT(ext)) {
	    if (rb_feature_p(feature, ext, Qfalse)) return Qtrue;
	    return Qfalse;
	}
    }
    if (rb_feature_p(feature, feature + strlen(feature), Qtrue))
	return Qtrue;

    return Qfalse;
}

static void
rb_provide_feature(feature)
    VALUE feature;
{
    rb_ary_push(rb_features, feature);
}

void
rb_provide(feature)
    const char *feature;
{
    rb_provide_feature(rb_str_new2(feature));
}

static char *
load_lock(ftptr)
    const char *ftptr;
{
    st_data_t th;

    if (!loading_tbl ||
	!st_lookup(loading_tbl, (st_data_t)ftptr, &amp;th))
    {
	/* loading ruby library should be serialized. */
	if (!loading_tbl) {
	    loading_tbl = st_init_strtable();
	}
	/* partial state */
	ftptr = ruby_strdup(ftptr);
	st_insert(loading_tbl, (st_data_t)ftptr, (st_data_t)curr_thread);
	return (char *)ftptr;
    }
    do {
	if ((rb_thread_t)th == curr_thread) return 0;
	CHECK_INTS;
    } while (st_lookup(loading_tbl, (st_data_t)ftptr, &amp;th));
    return 0;
}

static void
load_unlock(const char *ftptr)
{
    if (ftptr) {
	st_data_t key = (st_data_t)ftptr;
	
	if (st_delete(loading_tbl, &amp;key, 0)) {
	    free((char *)key);
	}
    }
}

/*
 *  call-seq:
 *     require(string)    =&gt; true or false
 *  
 *  Ruby tries to load the library named _string_, returning
 *  +true+ if successful. If the filename does not resolve to
 *  an absolute path, it will be searched for in the directories listed
 *  in &lt;code&gt;$:&lt;/code&gt;. If the file has the extension ``.rb'', it is
 *  loaded as a source file; if the extension is ``.so'', ``.o'', or
 *  ``.dll'', or whatever the default shared library extension is on
 *  the current platform, Ruby loads the shared library as a Ruby
 *  extension. Otherwise, Ruby tries adding ``.rb'', ``.so'', and so on
 *  to the name. The name of the loaded feature is added to the array in
 *  &lt;code&gt;$&quot;&lt;/code&gt;. A feature will not be loaded if it's name already
 *  appears in &lt;code&gt;$&quot;&lt;/code&gt;. However, the file name is not converted
 *  to an absolute path, so that ``&lt;code&gt;require 'a';require
 *  './a'&lt;/code&gt;'' will load &lt;code&gt;a.rb&lt;/code&gt; twice.
 *     
 *     require &quot;my-library.rb&quot;
 *     require &quot;db-driver&quot;
 */

VALUE
rb_f_require(obj, fname)
    VALUE obj, fname;
{
    return rb_require_safe(fname, ruby_safe_level);
}

static int
search_required(fname, featurep, path)
    VALUE fname, *featurep, *path;
{
    VALUE tmp;
    char *ext, *ftptr;
    int type;

    *featurep = fname;
    *path = 0;
    ext = strrchr(ftptr = RSTRING_PTR(fname), '.');
    if (ext &amp;&amp; !strchr(ext, '/')) {
	if (strcmp(&quot;.rb&quot;, ext) == 0) {
	    if (rb_feature_p(ftptr, ext, Qtrue)) return 'r';
	    if ((*path = rb_find_file(fname)) != 0) return 'r';
	    return 0;
	}
	else if (IS_SOEXT(ext)) {
	    if (rb_feature_p(ftptr, ext, Qfalse)) return 's';
	    tmp = rb_str_new(RSTRING_PTR(fname), ext-RSTRING_PTR(fname));
	    *featurep = tmp;
#ifdef DLEXT2
	    OBJ_FREEZE(tmp);
	    if (rb_find_file_ext(&amp;tmp, loadable_ext+1)) {
		*featurep = tmp;
		*path = rb_find_file(tmp);
		return 's';
	    }
#else
	    rb_str_cat2(tmp, DLEXT);
	    OBJ_FREEZE(tmp);
	    if ((*path = rb_find_file(tmp)) != 0) {
		return 's';
	    }
#endif
	}
	else if (IS_DLEXT(ext)) {
	    if (rb_feature_p(ftptr, ext, Qfalse)) return 's';
	    if ((*path = rb_find_file(fname)) != 0) return 's';
	}
    }
    tmp = fname;
    type = rb_find_file_ext(&amp;tmp, loadable_ext);
    *featurep = tmp;
    switch (type) {
      case 0:
	ftptr = RSTRING_PTR(tmp);
	return rb_feature_p(ftptr, 0, Qfalse);

      default:
	ext = strrchr(ftptr = RSTRING(tmp)-&gt;ptr, '.');
	if (rb_feature_p(ftptr, ext, !--type)) break;
	*path = rb_find_file(tmp);
    }
    return type ? 's' : 'r';
}

static void
load_failed(fname)
    VALUE fname;
{
    rb_raise(rb_eLoadError, &quot;no such file to load -- %s&quot;, RSTRING(fname)-&gt;ptr);
}

VALUE
rb_require_safe(fname, safe)
    VALUE fname;
    int safe;
{
    VALUE result = Qnil;
    volatile VALUE errinfo = ruby_errinfo;
    int state;
    struct {
	NODE *node;
	ID func;
	int vmode, safe;
    } volatile saved;
    char *volatile ftptr = 0;

    if (OBJ_TAINTED(fname)) {
	rb_check_safe_obj(fname);
    }
    StringValue(fname);
    fname = rb_str_new4(fname);
    saved.vmode = scope_vmode;
    saved.node = ruby_current_node;
    saved.func = ruby_frame-&gt;last_func;
    saved.safe = ruby_safe_level;
    PUSH_TAG(PROT_NONE);
    if ((state = EXEC_TAG()) == 0) {
	VALUE feature, path;
	long handle;
	int found;

	ruby_safe_level = safe;
	found = search_required(fname, &amp;feature, &amp;path);
	if (found) {
	    if (!path || !(ftptr = load_lock(RSTRING_PTR(feature)))) {
		result = Qfalse;
	    }
	    else {
		ruby_safe_level = 0;
		switch (found) {
		  case 'r':
		    rb_load(path, 0);
		    break;

		  case 's':
		    ruby_current_node = 0;
		    ruby_sourcefile = rb_source_filename(RSTRING(path)-&gt;ptr);
		    ruby_sourceline = 0;
		    ruby_frame-&gt;last_func = 0;
		    SCOPE_SET(SCOPE_PUBLIC);
		    handle = (long)dln_load(RSTRING(path)-&gt;ptr);
		    rb_ary_push(ruby_dln_librefs, LONG2NUM(handle));
		    break;
		}
		rb_provide_feature(feature);
		result = Qtrue;
	    }
	}
    }
    POP_TAG();
    ruby_current_node = saved.node;
    ruby_set_current_source();
    ruby_frame-&gt;last_func = saved.func;
    SCOPE_SET(saved.vmode);
    ruby_safe_level = saved.safe;
    load_unlock(ftptr);
    if (state) JUMP_TAG(state);
    if (NIL_P(result)) {
	load_failed(fname);
    }
    ruby_errinfo = errinfo;

    return result;
}

VALUE
rb_require(fname)
    const char *fname;
{
    VALUE fn = rb_str_new2(fname);
    OBJ_FREEZE(fn);
    return rb_require_safe(fn, ruby_safe_level);
}

void
ruby_init_ext(name, init)
    const char *name;
    void (*init) _((void));
{
    ruby_current_node = 0;
    ruby_sourcefile = rb_source_filename(name);
    ruby_sourceline = 0;
    ruby_frame-&gt;last_func = 0;
    ruby_frame-&gt;orig_func = 0;
    SCOPE_SET(SCOPE_PUBLIC);
    if (load_lock(name)) {
	(*init)();
	rb_provide(name);
	load_unlock(name);
    }
}

static void
secure_visibility(self)
    VALUE self;
{
    if (ruby_safe_level &gt;= 4 &amp;&amp; !OBJ_TAINTED(self)) {
	rb_raise(rb_eSecurityError, &quot;Insecure: can't change method visibility&quot;);
    }
}

static void
set_method_visibility(self, argc, argv, ex)
    VALUE self;
    int argc;
    VALUE *argv;
    ID ex;
{
    int i;

    secure_visibility(self);
    for (i=0; i&lt;argc; i++) {
	rb_export_method(self, rb_to_id(argv[i]), ex);
    }
    rb_clear_cache_by_class(self);
}

/*
 *  call-seq:
 *     public                 =&gt; self
 *     public(symbol, ...)    =&gt; self
 *  
 *  With no arguments, sets the default visibility for subsequently
 *  defined methods to public. With arguments, sets the named methods to
 *  have public visibility.
 */

static VALUE
rb_mod_public(argc, argv, module)
    int argc;
    VALUE *argv;
    VALUE module;
{
    secure_visibility(module);
    if (argc == 0) {
	SCOPE_SET(SCOPE_PUBLIC);
    }
    else {
	set_method_visibility(module, argc, argv, NOEX_PUBLIC);
    }
    return module;
}

/*
 *  call-seq:
 *     protected                =&gt; self
 *     protected(symbol, ...)   =&gt; self
 *  
 *  With no arguments, sets the default visibility for subsequently
 *  defined methods to protected. With arguments, sets the named methods
 *  to have protected visibility.
 */

static VALUE
rb_mod_protected(argc, argv, module)
    int argc;
    VALUE *argv;
    VALUE module;
{
    secure_visibility(module);
    if (argc == 0) {
	SCOPE_SET(SCOPE_PROTECTED);
    }
    else {
	set_method_visibility(module, argc, argv, NOEX_PROTECTED);
    }
    return module;
}

/*
 *  call-seq:
 *     private                 =&gt; self
 *     private(symbol, ...)    =&gt; self
 *  
 *  With no arguments, sets the default visibility for subsequently
 *  defined methods to private. With arguments, sets the named methods
 *  to have private visibility.
 *     
 *     module Mod
 *       def a()  end
 *       def b()  end
 *       private
 *       def c()  end
 *       private :a
 *     end
 *     Mod.private_instance_methods   #=&gt; [&quot;a&quot;, &quot;c&quot;]
 */

static VALUE
rb_mod_private(argc, argv, module)
    int argc;
    VALUE *argv;
    VALUE module;
{
    secure_visibility(module);
    if (argc == 0) {
	SCOPE_SET(SCOPE_PRIVATE);
    }
    else {
	set_method_visibility(module, argc, argv, NOEX_PRIVATE);
    }
    return module;
}

/*
 *  call-seq:
 *     mod.public_class_method(symbol, ...)    =&gt; mod
 *  
 *  Makes a list of existing class methods public.
 */

static VALUE
rb_mod_public_method(argc, argv, obj)
    int argc;
    VALUE *argv;
    VALUE obj;
{
    set_method_visibility(CLASS_OF(obj), argc, argv, NOEX_PUBLIC);
    return obj;
}

/*
 *  call-seq:
 *     mod.private_class_method(symbol, ...)   =&gt; mod
 *  
 *  Makes existing class methods private. Often used to hide the default
 *  constructor &lt;code&gt;new&lt;/code&gt;.
 *     
 *     class SimpleSingleton  # Not thread safe
 *       private_class_method :new
 *       def SimpleSingleton.create(*args, &amp;block)
 *         @me = new(*args, &amp;block) if ! @me
 *         @me
 *       end
 *     end
 */

static VALUE
rb_mod_private_method(argc, argv, obj)
    int argc;
    VALUE *argv;
    VALUE obj;
{
    set_method_visibility(CLASS_OF(obj), argc, argv, NOEX_PRIVATE);
    return obj;
}

/*
 *  call-seq:
 *     public
 *     public(symbol, ...)
 *  
 *  With no arguments, sets the default visibility for subsequently
 *  defined methods to public. With arguments, sets the named methods to
 *  have public visibility.
 */

static VALUE
top_public(argc, argv)
    int argc;
    VALUE *argv;
{
    return rb_mod_public(argc, argv, rb_cObject);
}

static VALUE
top_private(argc, argv)
    int argc;
    VALUE *argv;
{
    return rb_mod_private(argc, argv, rb_cObject);
}

/*
 *  call-seq:
 *     module_function(symbol, ...)    =&gt; self
 *  
 *  Creates module functions for the named methods. These functions may
 *  be called with the module as a receiver, and also become available
 *  as instance methods to classes that mix in the module. Module
 *  functions are copies of the original, and so may be changed
 *  independently. The instance-method versions are made private. If
 *  used with no arguments, subsequently defined methods become module
 *  functions.
 *     
 *     module Mod
 *       def one
 *         &quot;This is one&quot;
 *       end
 *       module_function :one
 *     end
 *     class Cls
 *       include Mod
 *       def callOne
 *         one
 *       end
 *     end
 *     Mod.one     #=&gt; &quot;This is one&quot;
 *     c = Cls.new
 *     c.callOne   #=&gt; &quot;This is one&quot;
 *     module Mod
 *       def one
 *         &quot;This is the new one&quot;
 *       end
 *     end
 *     Mod.one     #=&gt; &quot;This is one&quot;
 *     c.callOne   #=&gt; &quot;This is the new one&quot;
 */

static VALUE
rb_mod_modfunc(argc, argv, module)
    int argc;
    VALUE *argv;
    VALUE module;
{
    int i;
    ID id;
    NODE *body;

    if (TYPE(module) != T_MODULE) {
	rb_raise(rb_eTypeError, &quot;module_function must be called for modules&quot;);
    }

    secure_visibility(module);
    if (argc == 0) {
	SCOPE_SET(SCOPE_MODFUNC);
	return module;
    }

    set_method_visibility(module, argc, argv, NOEX_PRIVATE);
    for (i=0; i&lt;argc; i++) {
	VALUE m = module;

	id = rb_to_id(argv[i]);
	for (;;) {
	    body = search_method(m, id, &amp;m);
	    if (body == 0) {
		body = search_method(rb_cObject, id, &amp;m);
	    }
	    if (body == 0 || body-&gt;nd_body == 0) {
		rb_bug(&quot;undefined method `%s'; can't happen&quot;, rb_id2name(id));
	    }
	    if (nd_type(body-&gt;nd_body) != NODE_ZSUPER) {
		break;		/* normal case: need not to follow 'super' link */
	    }
	    m = RCLASS(m)-&gt;super;
	    if (!m) break;
	}
	rb_add_method(rb_singleton_class(module), id, body-&gt;nd_body, NOEX_PUBLIC);
    }
    return module;
}

/*
 *  call-seq:
 *     append_features(mod)   =&gt; mod
 *  
 *  When this module is included in another, Ruby calls
 *  &lt;code&gt;append_features&lt;/code&gt; in this module, passing it the
 *  receiving module in _mod_. Ruby's default implementation is
 *  to add the constants, methods, and module variables of this module
 *  to _mod_ if this module has not already been added to
 *  _mod_ or one of its ancestors. See also &lt;code&gt;Module#include&lt;/code&gt;.
 */

static VALUE
rb_mod_append_features(module, include)
    VALUE module, include;
{
    switch (TYPE(include)) {
      case T_CLASS:
      case T_MODULE:
	break;
      default:
	Check_Type(include, T_CLASS);
	break;
    }
    rb_include_module(include, module);

    return module;
}

/*
 *  call-seq:
 *     include(module, ...)    =&gt; self
 *  
 *  Invokes &lt;code&gt;Module.append_features&lt;/code&gt; on each parameter in turn.
 */

static VALUE
rb_mod_include(argc, argv, module)
    int argc;
    VALUE *argv;
    VALUE module;
{
    int i;

    for (i=0; i&lt;argc; i++) Check_Type(argv[i], T_MODULE);
    while (argc--) {
	rb_funcall(argv[argc], rb_intern(&quot;append_features&quot;), 1, module);
	rb_funcall(argv[argc], rb_intern(&quot;included&quot;), 1, module);
    }
    return module;
}

void
rb_obj_call_init(obj, argc, argv)
    VALUE obj;
    int argc;
    VALUE *argv;
{
    PUSH_ITER(rb_block_given_p()?ITER_PRE:ITER_NOT);
    rb_funcall2(obj, init, argc, argv);
    POP_ITER();
}

void
rb_extend_object(obj, module)
    VALUE obj, module;
{
    rb_include_module(rb_singleton_class(obj), module);
}

/*
 *  call-seq:
 *     extend_object(obj)    =&gt; obj
 *  
 *  Extends the specified object by adding this module's constants and
 *  methods (which are added as singleton methods). This is the callback
 *  method used by &lt;code&gt;Object#extend&lt;/code&gt;.
 *     
 *     module Picky
 *       def Picky.extend_object(o)
 *         if String === o
 *           puts &quot;Can't add Picky to a String&quot;
 *         else
 *           puts &quot;Picky added to #{o.class}&quot;
 *           super
 *         end
 *       end
 *     end
 *     (s = Array.new).extend Picky  # Call Object.extend
 *     (s = &quot;quick brown fox&quot;).extend Picky
 *     
 *  &lt;em&gt;produces:&lt;/em&gt;
 *     
 *     Picky added to Array
 *     Can't add Picky to a String
 */

static VALUE
rb_mod_extend_object(mod, obj)
    VALUE mod, obj;
{
    rb_extend_object(obj, mod);
    return obj;
}

/*
 *  call-seq:
 *     obj.extend(module, ...)    =&gt; obj
 *  
 *  Adds to _obj_ the instance methods from each module given as a
 *  parameter.
 *     
 *     module Mod
 *       def hello
 *         &quot;Hello from Mod.\n&quot;
 *       end
 *     end
 *     
 *     class Klass
 *       def hello
 *         &quot;Hello from Klass.\n&quot;
 *       end
 *     end
 *     
 *     k = Klass.new
 *     k.hello         #=&gt; &quot;Hello from Klass.\n&quot;
 *     k.extend(Mod)   #=&gt; #&lt;Klass:0x401b3bc8&gt;
 *     k.hello         #=&gt; &quot;Hello from Mod.\n&quot;
 */

static VALUE
rb_obj_extend(argc, argv, obj)
    int argc;
    VALUE *argv;
    VALUE obj;
{
    int i;

    if (argc == 0) {
	rb_raise(rb_eArgError, &quot;wrong number of arguments (0 for 1)&quot;);
    }
    for (i=0; i&lt;argc; i++) Check_Type(argv[i], T_MODULE);
    while (argc--) {
	rb_funcall(argv[argc], rb_intern(&quot;extend_object&quot;), 1, obj);
	rb_funcall(argv[argc], rb_intern(&quot;extended&quot;), 1, obj);
    }
    return obj;
}

/*
 *  call-seq:
 *     include(module, ...)   =&gt; self
 *  
 *  Invokes &lt;code&gt;Module.append_features&lt;/code&gt;
 *  on each parameter in turn. Effectively adds the methods and constants
 *  in each module to the receiver.
 */

static VALUE
top_include(argc, argv, self)
    int argc;
    VALUE *argv;
    VALUE self;
{
    rb_secure(4);
    if (ruby_wrapper) {
	rb_warning(&quot;main#include in the wrapped load is effective only in wrapper module&quot;);
	return rb_mod_include(argc, argv, ruby_wrapper);
    }
    return rb_mod_include(argc, argv, rb_cObject);
}

VALUE rb_f_trace_var();
VALUE rb_f_untrace_var();

static void
errinfo_setter(val, id, var)
    VALUE val;
    ID id;
    VALUE *var;
{
    if (!NIL_P(val) &amp;&amp; !rb_obj_is_kind_of(val, rb_eException)) {
	rb_raise(rb_eTypeError, &quot;assigning non-exception to $!&quot;);
    }
    *var = val;
}

static VALUE
errat_getter(id)
    ID id;
{
    return get_backtrace(ruby_errinfo);
}

static void
errat_setter(val, id, var)
    VALUE val;
    ID id;
    VALUE *var;
{
    if (NIL_P(ruby_errinfo)) {
	rb_raise(rb_eArgError, &quot;$! not set&quot;);
    }
    set_backtrace(ruby_errinfo, val);
}

/*
 *  call-seq:
 *     local_variables    =&gt; array
 *  
 *  Returns the names of the current local variables.
 *     
 *     fred = 1
 *     for i in 1..10
 *        # ...
 *     end
 *     local_variables   #=&gt; [&quot;fred&quot;, &quot;i&quot;]
 */

static VALUE
rb_f_local_variables()
{
    ID *tbl;
    int n, i;
    VALUE ary = rb_ary_new();
    struct RVarmap *vars;

    tbl = ruby_scope-&gt;local_tbl;
    if (tbl) {
	n = *tbl++;
	for (i=2; i&lt;n; i++) {	/* skip first 2 ($_ and $~) */
	    if (!rb_is_local_id(tbl[i])) continue; /* skip flip states */
	    rb_ary_push(ary, rb_str_new2(rb_id2name(tbl[i])));
	}
    }

    vars = ruby_dyna_vars;
    while (vars) {
	if (vars-&gt;id &amp;&amp; rb_is_local_id(vars-&gt;id)) { /* skip $_, $~ and flip states */
	    rb_ary_push(ary, rb_str_new2(rb_id2name(vars-&gt;id)));
	}
	vars = vars-&gt;next;
    }

    return ary;
}

static VALUE rb_f_catch _((VALUE,VALUE));
NORETURN(static VALUE rb_f_throw _((int,VALUE*)));

struct end_proc_data {
    void (*func)();
    VALUE data;
    int safe;
    struct end_proc_data *next;
};

static struct end_proc_data *end_procs, *ephemeral_end_procs, *tmp_end_procs;

void
rb_set_end_proc(func, data)
    void (*func) _((VALUE));
    VALUE data;
{
    struct end_proc_data *link = ALLOC(struct end_proc_data);
    struct end_proc_data **list;

    if (ruby_wrapper) list = &amp;ephemeral_end_procs;
    else              list = &amp;end_procs;
    link-&gt;next = *list;
    link-&gt;func = func;
    link-&gt;data = data;
    link-&gt;safe = ruby_safe_level;
    *list = link;
}

void
rb_mark_end_proc()
{
    struct end_proc_data *link;

    link = end_procs;
    while (link) {
	rb_gc_mark(link-&gt;data);
	link = link-&gt;next;
    }
    link = ephemeral_end_procs;
    while (link) {
	rb_gc_mark(link-&gt;data);
	link = link-&gt;next;
    }
    link = tmp_end_procs;
    while (link) {
	rb_gc_mark(link-&gt;data);
	link = link-&gt;next;
    }
}

static void call_end_proc _((VALUE data));

static void
call_end_proc(data)
    VALUE data;
{
    PUSH_ITER(ITER_NOT);
    PUSH_FRAME();
    ruby_frame-&gt;self = ruby_frame-&gt;prev-&gt;self;
    ruby_frame-&gt;node = 0;
    ruby_frame-&gt;last_func = 0;
    ruby_frame-&gt;last_class = 0;
    proc_invoke(data, rb_ary_new2(0), Qundef, 0);
    POP_FRAME();
    POP_ITER();
}

static void
rb_f_END()
{
    PUSH_FRAME();
    ruby_frame-&gt;argc = 0;
    ruby_frame-&gt;iter = ITER_CUR;
    rb_set_end_proc(call_end_proc, rb_block_proc());
    POP_FRAME();
}

/*
 *  call-seq:
 *     at_exit { block } -&gt; proc
 *  
 *  Converts _block_ to a +Proc+ object (and therefore
 *  binds it at the point of call) and registers it for execution when
 *  the program exits. If multiple handlers are registered, they are
 *  executed in reverse order of registration.
 *     
 *     def do_at_exit(str1)
 *       at_exit { print str1 }
 *     end
 *     at_exit { puts &quot;cruel world&quot; }
 *     do_at_exit(&quot;goodbye &quot;)
 *     exit
 *     
 *  &lt;em&gt;produces:&lt;/em&gt;
 *     
 *     goodbye cruel world
 */

static VALUE
rb_f_at_exit()
{
    VALUE proc;

    if (!rb_block_given_p()) {
	rb_raise(rb_eArgError, &quot;called without a block&quot;);
    }
    proc = rb_block_proc();
    rb_set_end_proc(call_end_proc, proc);
    return proc;
}

void
rb_exec_end_proc()
{
    struct end_proc_data *link, *tmp;
    int status;
    volatile int safe = ruby_safe_level;

    while (ephemeral_end_procs) {
	tmp_end_procs = link = ephemeral_end_procs;
	ephemeral_end_procs = 0;
	while (link) {
	    PUSH_TAG(PROT_NONE);
	    if ((status = EXEC_TAG()) == 0) {
		ruby_safe_level = link-&gt;safe;
		(*link-&gt;func)(link-&gt;data);
	    }
	    POP_TAG();
	    if (status) {
		error_handle(status);
	    }
	    tmp = link;
	    tmp_end_procs = link = link-&gt;next;
	    free(tmp);
	}
    }
    while (end_procs) {
	tmp_end_procs = link = end_procs;
	end_procs = 0;
	while (link) {
	    PUSH_TAG(PROT_NONE);
	    if ((status = EXEC_TAG()) == 0) {
		ruby_safe_level = link-&gt;safe;
		(*link-&gt;func)(link-&gt;data);
	    }
	    POP_TAG();
	    if (status) {
		error_handle(status);
	    }
	    tmp = link;
	    tmp_end_procs = link = link-&gt;next;
	    free(tmp);
	}
    }
    ruby_safe_level = safe;
}

/*
 *  call-seq:
 *     __method__         =&gt; symbol
 *  
 *  Returns the name of the current method as a Symbol.
 *  If called from inside of an aliased method it will return the original
 *  nonaliased name.
 *  If called outside of a method, it returns &lt;code&gt;nil&lt;/code&gt;.
 *  
 *    def foo
 *      __method__
 *    end
 *    alias bar foo
 *    
 *    foo                # =&gt; :foo
 *    bar                # =&gt; :foo
 *
 */

static VALUE
rb_f_method_name()
{
    struct FRAME* prev = ruby_frame-&gt;prev;
    if (prev &amp;&amp; prev-&gt;orig_func) {
	return ID2SYM(prev-&gt;orig_func);
    }
    else {
	return Qnil;
    }
}

void
Init_eval()
{
    init = rb_intern(&quot;initialize&quot;);
    eqq = rb_intern(&quot;===&quot;);
    each = rb_intern(&quot;each&quot;);

    aref = rb_intern(&quot;[]&quot;);
    aset = rb_intern(&quot;[]=&quot;);
    match = rb_intern(&quot;=~&quot;);
    missing = rb_intern(&quot;method_missing&quot;);
    added = rb_intern(&quot;method_added&quot;);
    singleton_added = rb_intern(&quot;singleton_method_added&quot;);
    removed = rb_intern(&quot;method_removed&quot;);
    singleton_removed = rb_intern(&quot;singleton_method_removed&quot;);
    undefined = rb_intern(&quot;method_undefined&quot;);
    singleton_undefined = rb_intern(&quot;singleton_method_undefined&quot;);

    __id__ = rb_intern(&quot;__id__&quot;);
    __send__ = rb_intern(&quot;__send__&quot;);

    rb_global_variable((void *)&amp;top_scope);
    rb_global_variable((void *)&amp;ruby_eval_tree_begin);

    rb_global_variable((void *)&amp;ruby_eval_tree);
    rb_global_variable((void *)&amp;ruby_dyna_vars);

    rb_define_virtual_variable(&quot;$@&quot;, errat_getter, errat_setter);
    rb_define_hooked_variable(&quot;$!&quot;, &amp;ruby_errinfo, 0, errinfo_setter);

    rb_define_global_function(&quot;eval&quot;, rb_f_eval, -1);
    rb_define_global_function(&quot;iterator?&quot;, rb_f_block_given_p, 0);
    rb_define_global_function(&quot;block_given?&quot;, rb_f_block_given_p, 0);
    rb_define_global_function(&quot;method_missing&quot;, rb_method_missing, -1);
    rb_define_global_function(&quot;loop&quot;, rb_f_loop, 0);

    rb_define_method(rb_mKernel, &quot;respond_to?&quot;, obj_respond_to, -1);
    respond_to   = rb_intern(&quot;respond_to?&quot;);
    rb_global_variable((void *)&amp;basic_respond_to);
    basic_respond_to = rb_method_node(rb_cObject, respond_to);
    
    rb_define_global_function(&quot;raise&quot;, rb_f_raise, -1);
    rb_define_global_function(&quot;fail&quot;, rb_f_raise, -1);

    rb_define_global_function(&quot;caller&quot;, rb_f_caller, -1);

    rb_define_global_function(&quot;exit&quot;, rb_f_exit, -1);
    rb_define_global_function(&quot;abort&quot;, rb_f_abort, -1);

    rb_define_global_function(&quot;at_exit&quot;, rb_f_at_exit, 0);

    rb_define_global_function(&quot;catch&quot;, rb_f_catch, 1);
    rb_define_global_function(&quot;throw&quot;, rb_f_throw, -1);
    rb_define_global_function(&quot;global_variables&quot;, rb_f_global_variables, 0); /* in variable.c */
    rb_define_global_function(&quot;local_variables&quot;, rb_f_local_variables, 0);

    rb_define_global_function(&quot;__method__&quot;, rb_f_method_name, 0);

    rb_define_method(rb_mKernel, &quot;send&quot;, rb_f_send, -1);
    rb_define_method(rb_mKernel, &quot;__send__&quot;, rb_f_send, -1);
    rb_define_method(rb_mKernel, &quot;instance_eval&quot;, rb_obj_instance_eval, -1);
    rb_define_method(rb_mKernel, &quot;instance_exec&quot;, rb_obj_instance_exec, -1);

    rb_define_private_method(rb_cModule, &quot;append_features&quot;, rb_mod_append_features, 1);
    rb_define_private_method(rb_cModule, &quot;extend_object&quot;, rb_mod_extend_object, 1);
    rb_define_private_method(rb_cModule, &quot;include&quot;, rb_mod_include, -1);
    rb_define_private_method(rb_cModule, &quot;public&quot;, rb_mod_public, -1);
    rb_define_private_method(rb_cModule, &quot;protected&quot;, rb_mod_protected, -1);
    rb_define_private_method(rb_cModule, &quot;private&quot;, rb_mod_private, -1);
    rb_define_private_method(rb_cModule, &quot;module_function&quot;, rb_mod_modfunc, -1);
    rb_define_method(rb_cModule, &quot;method_defined?&quot;, rb_mod_method_defined, 1);
    rb_define_method(rb_cModule, &quot;public_method_defined?&quot;, rb_mod_public_method_defined, 1);
    rb_define_method(rb_cModule, &quot;private_method_defined?&quot;, rb_mod_private_method_defined, 1);
    rb_define_method(rb_cModule, &quot;protected_method_defined?&quot;, rb_mod_protected_method_defined, 1);
    rb_define_method(rb_cModule, &quot;public_class_method&quot;, rb_mod_public_method, -1);
    rb_define_method(rb_cModule, &quot;private_class_method&quot;, rb_mod_private_method, -1);
    rb_define_method(rb_cModule, &quot;module_eval&quot;, rb_mod_module_eval, -1);
    rb_define_method(rb_cModule, &quot;module_exec&quot;, rb_mod_module_exec, -1);
    rb_define_method(rb_cModule, &quot;class_eval&quot;, rb_mod_module_eval, -1);
    rb_define_method(rb_cModule, &quot;class_exec&quot;, rb_mod_module_exec, -1);

    rb_undef_method(rb_cClass, &quot;module_function&quot;);

    rb_define_private_method(rb_cModule, &quot;remove_method&quot;, rb_mod_remove_method, -1);
    rb_define_private_method(rb_cModule, &quot;undef_method&quot;, rb_mod_undef_method, -1);
    rb_define_private_method(rb_cModule, &quot;alias_method&quot;, rb_mod_alias_method, 2);
    rb_define_private_method(rb_cModule, &quot;define_method&quot;, rb_mod_define_method, -1);

    rb_define_singleton_method(rb_cModule, &quot;nesting&quot;, rb_mod_nesting, 0);
    rb_define_singleton_method(rb_cModule, &quot;constants&quot;, rb_mod_s_constants, 0);

    rb_define_singleton_method(ruby_top_self, &quot;include&quot;, top_include, -1);
    rb_define_singleton_method(ruby_top_self, &quot;public&quot;, top_public, -1);
    rb_define_singleton_method(ruby_top_self, &quot;private&quot;, top_private, -1);

    rb_define_method(rb_mKernel, &quot;extend&quot;, rb_obj_extend, -1);

    rb_define_global_function(&quot;trace_var&quot;, rb_f_trace_var, -1); /* in variable.c */
    rb_define_global_function(&quot;untrace_var&quot;, rb_f_untrace_var, -1); /* in variable.c */

    rb_define_global_function(&quot;set_trace_func&quot;, set_trace_func, 1);
    rb_global_variable(&amp;trace_func);

    rb_define_virtual_variable(&quot;$SAFE&quot;, safe_getter, safe_setter);
}

/*
 *  call-seq:
 *     mod.autoload(name, filename)   =&gt; nil
 *
 *  Registers _filename_ to be loaded (using &lt;code&gt;Kernel::require&lt;/code&gt;) 
 *  the first time that _name_ (which may be a &lt;code&gt;String&lt;/code&gt; or
 *  a symbol) is accessed in the namespace of _mod_.
 *
 *     module A
 *     end
 *     A.autoload(:B, &quot;b&quot;)
 *     A::B.doit            # autoloads &quot;b&quot;
 */

static VALUE
rb_mod_autoload(mod, sym, file)
    VALUE mod;
    VALUE sym;
    VALUE file;
{
    ID id = rb_to_id(sym);

    Check_SafeStr(file);
    rb_autoload(mod, id, RSTRING(file)-&gt;ptr);
    return Qnil;
}

/*
 *  call-seq:
 *     mod.autoload?(name)   =&gt; String or nil
 *
 *  Returns _filename_ to be loaded if _name_ is registered as
 *  +autoload+ in the namespace of _mod_.
 *
 *     module A
 *     end
 *     A.autoload(:B, &quot;b&quot;)
 *     A.autoload?(:B)            # =&gt; &quot;b&quot;
 */

static VALUE
rb_mod_autoload_p(mod, sym)
    VALUE mod, sym;
{
    return rb_autoload_p(mod, rb_to_id(sym));
}

/*
 *  call-seq:
 *     autoload(module, filename)   =&gt; nil
 *  
 *  Registers _filename_ to be loaded (using &lt;code&gt;Kernel::require&lt;/code&gt;) 
 *  the first time that _module_ (which may be a &lt;code&gt;String&lt;/code&gt; or
 *  a symbol) is accessed.
 *     
 *     autoload(:MyModule, &quot;/usr/local/lib/modules/my_module.rb&quot;)
 */

static VALUE
rb_f_autoload(obj, sym, file)
    VALUE obj;
    VALUE sym;
    VALUE file;
{
    if (NIL_P(ruby_cbase)) {
	rb_raise(rb_eTypeError, &quot;no class/module for autoload target&quot;);
    }
    return rb_mod_autoload(ruby_cbase, sym, file);
}

/*
 *  call-seq:
 *     autoload(module, filename)   =&gt; nil
 *
 *  Registers _filename_ to be loaded (using &lt;code&gt;Kernel::require&lt;/code&gt;)
 *  the first time that _module_ (which may be a &lt;code&gt;String&lt;/code&gt; or
 *  a symbol) is accessed.
 *
 *     autoload(:MyModule, &quot;/usr/local/lib/modules/my_module.rb&quot;)
 */

static VALUE
rb_f_autoload_p(obj, sym)
    VALUE obj;
    VALUE sym;
{
    /* use ruby_cbase as same as rb_f_autoload. */
    if (NIL_P(ruby_cbase)) {
	return Qfalse;
    }
    return rb_mod_autoload_p(ruby_cbase, sym);
}

void
Init_load()
{
    rb_define_readonly_variable(&quot;$:&quot;, &amp;rb_load_path);
    rb_define_readonly_variable(&quot;$-I&quot;, &amp;rb_load_path);
    rb_define_readonly_variable(&quot;$LOAD_PATH&quot;, &amp;rb_load_path);
    rb_load_path = rb_ary_new();

    rb_define_readonly_variable(&quot;$\&quot;&quot;, &amp;rb_features);
    rb_define_readonly_variable(&quot;$LOADED_FEATURES&quot;, &amp;rb_features);
    rb_features = rb_ary_new();

    rb_define_global_function(&quot;load&quot;, rb_f_load, -1);
    rb_define_global_function(&quot;require&quot;, rb_f_require, 1);
    rb_define_method(rb_cModule, &quot;autoload&quot;,  rb_mod_autoload,   2);
    rb_define_method(rb_cModule, &quot;autoload?&quot;, rb_mod_autoload_p, 1);
    rb_define_global_function(&quot;autoload&quot;,  rb_f_autoload,   2);
    rb_define_global_function(&quot;autoload?&quot;, rb_f_autoload_p, 1);
    rb_global_variable(&amp;ruby_wrapper);

    rb_global_variable(&amp;ruby_dln_librefs);
    ruby_dln_librefs = rb_ary_new();
}

static void
scope_dup(scope)
    struct SCOPE *scope;
{
    ID *tbl;
    VALUE *vars;

    scope-&gt;flags |= SCOPE_DONT_RECYCLE;
    if (scope-&gt;flags &amp; SCOPE_MALLOC) return;

    if (scope-&gt;local_tbl) {
	tbl = scope-&gt;local_tbl;
	vars = ALLOC_N(VALUE, tbl[0]+1);
	*vars++ = scope-&gt;local_vars[-1];
	MEMCPY(vars, scope-&gt;local_vars, VALUE, tbl[0]);
	scope-&gt;local_vars = vars;
	scope-&gt;flags |= SCOPE_MALLOC;
    }
}

static void
blk_mark(data)
    struct BLOCK *data;
{
    while (data) {
	rb_gc_mark_frame(&amp;data-&gt;frame);
	rb_gc_mark((VALUE)data-&gt;scope);
	rb_gc_mark((VALUE)data-&gt;var);
	rb_gc_mark((VALUE)data-&gt;body);
	rb_gc_mark((VALUE)data-&gt;self);
	rb_gc_mark((VALUE)data-&gt;dyna_vars);
	rb_gc_mark((VALUE)data-&gt;cref);
	rb_gc_mark(data-&gt;wrapper);
	rb_gc_mark(data-&gt;block_obj);
	data = data-&gt;prev;
    }
}

static void
frame_free(frame)
    struct FRAME *frame;
{
    struct FRAME *tmp;

    frame = frame-&gt;prev;
    while (frame) {
	tmp = frame;
	frame = frame-&gt;prev;
	free(tmp);
    }
}

static void
blk_free(data)
    struct BLOCK *data;
{
    void *tmp;

    while (data) {
	frame_free(&amp;data-&gt;frame);
	tmp = data;
	data = data-&gt;prev;
	free(tmp);
    }
}

static void
frame_dup(frame)
    struct FRAME *frame;
{
    struct FRAME *tmp;

    for (;;) {
	frame-&gt;tmp = 0;		/* should not preserve tmp */
	if (!frame-&gt;prev) break;
	tmp = ALLOC(struct FRAME);
	*tmp = *frame-&gt;prev;
	frame-&gt;prev = tmp;
	frame = tmp;
    }
}


static void
blk_copy_prev(block)
    struct BLOCK *block;
{
    struct BLOCK *tmp;
    struct RVarmap* vars;

    while (block-&gt;prev) {
	tmp = ALLOC_N(struct BLOCK, 1);
	MEMCPY(tmp, block-&gt;prev, struct BLOCK, 1);
	scope_dup(tmp-&gt;scope);
	frame_dup(&amp;tmp-&gt;frame);

	for (vars = tmp-&gt;dyna_vars; vars; vars = vars-&gt;next) {
	    if (FL_TEST(vars, DVAR_DONT_RECYCLE)) break;
	    FL_SET(vars, DVAR_DONT_RECYCLE);
	}

	block-&gt;prev = tmp;
	block = tmp;
    }
}


static void
blk_dup(dup, orig)
    struct BLOCK *dup, *orig;
{
    MEMCPY(dup, orig, struct BLOCK, 1);
    frame_dup(&amp;dup-&gt;frame);

    if (dup-&gt;iter) {
	blk_copy_prev(dup);
    }
    else {
	dup-&gt;prev = 0;
    }
}

/*
 * MISSING: documentation
 */

static VALUE
proc_clone(self)
    VALUE self;
{
    struct BLOCK *orig, *data;
    VALUE bind;

    Data_Get_Struct(self, struct BLOCK, orig);
    bind = Data_Make_Struct(rb_obj_class(self),struct BLOCK,blk_mark,blk_free,data);
    CLONESETUP(bind, self);
    blk_dup(data, orig);

    return bind;
}

/*
 * MISSING: documentation
 */

#define PROC_TSHIFT (FL_USHIFT+1)
#define PROC_TMASK  (FL_USER1|FL_USER2|FL_USER3)
#define PROC_TMAX   (PROC_TMASK &gt;&gt; PROC_TSHIFT)

static int proc_get_safe_level(VALUE);

static VALUE
proc_dup(self)
    VALUE self;
{
    struct BLOCK *orig, *data;
    VALUE bind;
    int safe = proc_get_safe_level(self);

    Data_Get_Struct(self, struct BLOCK, orig);
    bind = Data_Make_Struct(rb_obj_class(self),struct BLOCK,blk_mark,blk_free,data);
    blk_dup(data, orig);
    if (safe &gt; PROC_TMAX) safe = PROC_TMAX;
    FL_SET(bind, (safe &lt;&lt; PROC_TSHIFT) &amp; PROC_TMASK);

    return bind;
}

VALUE
rb_block_dup(self, klass, cref)
    VALUE self, klass, cref;
{
    struct BLOCK *block;
    VALUE obj = proc_dup(self);
    Data_Get_Struct(obj, struct BLOCK, block);
    block-&gt;klass = klass;
    block-&gt;cref = NEW_NODE(nd_type(block-&gt;cref), cref, block-&gt;cref-&gt;u2.node,
			   block-&gt;cref-&gt;u3.node);
    return obj;
}

/*
 *  call-seq:
 *     binding -&gt; a_binding
 *  
 *  Returns a +Binding+ object, describing the variable and
 *  method bindings at the point of call. This object can be used when
 *  calling +eval+ to execute the evaluated command in this
 *  environment. Also see the description of class +Binding+.
 *     
 *     def getBinding(param)
 *       return binding
 *     end
 *     b = getBinding(&quot;hello&quot;)
 *     eval(&quot;param&quot;, b)   #=&gt; &quot;hello&quot;
 */

static VALUE
rb_f_binding(self)
    VALUE self;
{
    struct BLOCK *data, *p;
    struct RVarmap *vars;
    VALUE bind;

    PUSH_BLOCK(0,0);
    bind = Data_Make_Struct(rb_cBinding,struct BLOCK,blk_mark,blk_free,data);
    *data = *ruby_block;

    data-&gt;orig_thread = rb_thread_current();
    data-&gt;wrapper = ruby_wrapper;
    data-&gt;iter = rb_f_block_given_p();
    frame_dup(&amp;data-&gt;frame);
    if (ruby_frame-&gt;prev) {
	data-&gt;frame.last_func = ruby_frame-&gt;prev-&gt;last_func;
	data-&gt;frame.last_class = ruby_frame-&gt;prev-&gt;last_class;
	data-&gt;frame.orig_func = ruby_frame-&gt;prev-&gt;orig_func;
    }

    if (data-&gt;iter) {
	blk_copy_prev(data);
    }
    else {
	data-&gt;prev = 0;
    }

    for (p = data; p; p = p-&gt;prev) {
	for (vars = p-&gt;dyna_vars; vars; vars = vars-&gt;next) {
	    if (FL_TEST(vars, DVAR_DONT_RECYCLE)) break;
	    FL_SET(vars, DVAR_DONT_RECYCLE);
	}
    }
    scope_dup(data-&gt;scope);
    POP_BLOCK();

    return bind;
}

/*
 *  call-seq:
 *     binding.eval(string [, filename [,lineno]])  =&gt; obj
 *
 *  Evaluates the Ruby expression(s) in &lt;em&gt;string&lt;/em&gt;, in the
 *  &lt;em&gt;binding&lt;/em&gt;'s context.  If the optional &lt;em&gt;filename&lt;/em&gt; and
 *  &lt;em&gt;lineno&lt;/em&gt; parameters are present, they will be used when
 *  reporting syntax errors.
 *
 *     def getBinding(param)
 *       return binding
 *     end
 *     b = getBinding(&quot;hello&quot;)
 *     b.eval(&quot;param&quot;)   #=&gt; &quot;hello&quot;
 */

static VALUE
bind_eval(argc, argv, bindval)
    int argc;
    VALUE *argv;
    VALUE bindval;
{
    VALUE args[4];

    rb_scan_args(argc, argv, &quot;12&quot;, &amp;args[0], &amp;args[2], &amp;args[3]);
    args[1] = bindval;
    return rb_f_eval(argc+1, args, Qnil /* self will be searched in eval */);
}

#define SAFE_LEVEL_MAX PROC_TMASK

static void
proc_save_safe_level(data)
    VALUE data;
{
    int safe = ruby_safe_level;
    if (safe &gt; PROC_TMAX) safe = PROC_TMAX;
    FL_SET(data, (safe &lt;&lt; PROC_TSHIFT) &amp; PROC_TMASK);
}

static int
proc_get_safe_level(data)
    VALUE data;
{
    return (RBASIC(data)-&gt;flags &amp; PROC_TMASK) &gt;&gt; PROC_TSHIFT;
}

static void
proc_set_safe_level(data)
    VALUE data;
{
    ruby_safe_level = proc_get_safe_level(data);
}

static VALUE
proc_alloc(klass, proc)
    VALUE klass;
    int proc;
{
    volatile VALUE block;
    struct BLOCK *data, *p;
    struct RVarmap *vars;

    if (!rb_block_given_p() &amp;&amp; !rb_f_block_given_p()) {
	rb_raise(rb_eArgError, &quot;tried to create Proc object without a block&quot;);
    }
    if (proc &amp;&amp; !rb_block_given_p()) {
	rb_warn(&quot;tried to create Proc object without a block&quot;);
    }

    if (!proc &amp;&amp; ruby_block-&gt;block_obj &amp;&amp; CLASS_OF(ruby_block-&gt;block_obj) == klass) {
	return ruby_block-&gt;block_obj;
    }
    block = Data_Make_Struct(klass, struct BLOCK, blk_mark, blk_free, data);
    *data = *ruby_block;

    data-&gt;orig_thread = rb_thread_current();
    data-&gt;wrapper = ruby_wrapper;
    data-&gt;iter = data-&gt;prev?Qtrue:Qfalse;
    data-&gt;block_obj = block;
    frame_dup(&amp;data-&gt;frame);
    if (data-&gt;iter) {
	blk_copy_prev(data);
    }
    else {
	data-&gt;prev = 0;
    }

    for (p = data; p; p = p-&gt;prev) {
	for (vars = p-&gt;dyna_vars; vars; vars = vars-&gt;next) {
	    if (FL_TEST(vars, DVAR_DONT_RECYCLE)) break;
	    FL_SET(vars, DVAR_DONT_RECYCLE);
	}
    }
    scope_dup(data-&gt;scope);
    proc_save_safe_level(block);
    if (proc) {
	data-&gt;flags |= BLOCK_LAMBDA;
    }
    else {
	ruby_block-&gt;block_obj = block;
    }

    return block;
}

/*
 *  call-seq:
 *     Proc.new {|...| block } =&gt; a_proc 
 *     Proc.new                =&gt; a_proc 
 *  
 *  Creates a new &lt;code&gt;Proc&lt;/code&gt; object, bound to the current
 *  context. &lt;code&gt;Proc::new&lt;/code&gt; may be called without a block only
 *  within a method with an attached block, in which case that block is
 *  converted to the &lt;code&gt;Proc&lt;/code&gt; object.
 *     
 *     def proc_from
 *       Proc.new
 *     end
 *     proc = proc_from { &quot;hello&quot; }
 *     proc.call   #=&gt; &quot;hello&quot;
 */

static VALUE
proc_s_new(argc, argv, klass)
    int argc;
    VALUE *argv;
    VALUE klass;
{
    VALUE block = proc_alloc(klass, Qfalse);

    rb_obj_call_init(block, argc, argv);
    return block;
}

VALUE
rb_block_proc()
{
    return proc_alloc(rb_cProc, Qfalse);
}

VALUE
rb_f_lambda()
{
    rb_warn(&quot;rb_f_lambda() is deprecated; use rb_block_proc() instead&quot;);
    return proc_alloc(rb_cProc, Qtrue);
}

/*
 * call-seq:
 *   proc   { |...| block }  =&gt; a_proc
 *   lambda { |...| block }  =&gt; a_proc
 *
 * Equivalent to &lt;code&gt;Proc.new&lt;/code&gt;, except the resulting Proc objects
 * check the number of parameters passed when called.
 */

static VALUE
proc_lambda()
{
    return proc_alloc(rb_cProc, Qtrue);
}

static int
block_orphan(data)
    struct BLOCK *data;
{
    if (data-&gt;scope-&gt;flags &amp; SCOPE_NOSTACK) {
	return 1;
    }
    if (data-&gt;orig_thread != rb_thread_current()) {
	return 1;
    }
    return 0;
}

static VALUE
proc_invoke(proc, args, self, klass)
    VALUE proc, args;		/* OK */
    VALUE self, klass;
{
    struct BLOCK * volatile old_block;
    struct BLOCK _block;
    struct BLOCK *data;
    volatile VALUE result = Qundef;
    int state;
    volatile int safe = ruby_safe_level;
    volatile VALUE old_wrapper = ruby_wrapper;
    volatile int pcall, avalue = Qtrue;
    volatile VALUE tmp = args;
    VALUE bvar = Qnil;

    if (rb_block_given_p() &amp;&amp; ruby_frame-&gt;last_func) {
	if (klass != ruby_frame-&gt;last_class)
	    klass = rb_obj_class(proc);
	bvar = rb_block_proc();
    }

    Data_Get_Struct(proc, struct BLOCK, data);
    pcall = (data-&gt;flags &amp; BLOCK_LAMBDA) ? YIELD_LAMBDA_CALL : 0;
    if (!pcall &amp;&amp; RARRAY(args)-&gt;len == 1) {
	avalue = Qfalse;
	args = RARRAY(args)-&gt;ptr[0];
    }

    PUSH_VARS();
    ruby_wrapper = data-&gt;wrapper;
    ruby_dyna_vars = data-&gt;dyna_vars;
    /* PUSH BLOCK from data */
    old_block = ruby_block;
    _block = *data;
    _block.block_obj = bvar;
    if (self != Qundef) _block.frame.self = self;
    if (klass) _block.frame.last_class = klass;
    _block.frame.argc = RARRAY(tmp)-&gt;len;
    _block.frame.flags = ruby_frame-&gt;flags;
    if (_block.frame.argc &amp;&amp; DMETHOD_P()) {
        NEWOBJ(scope, struct SCOPE);
        OBJSETUP(scope, tmp, T_SCOPE);
        scope-&gt;local_tbl = _block.scope-&gt;local_tbl;
        scope-&gt;local_vars = _block.scope-&gt;local_vars;
        scope-&gt;flags |= SCOPE_CLONE;
        _block.scope = scope;
    }
    /* modify current frame */
    ruby_block = &amp;_block;
    PUSH_ITER(ITER_CUR);
    ruby_frame-&gt;iter = ITER_CUR;
    PUSH_TAG(pcall ? PROT_LAMBDA : PROT_NONE);
    state = EXEC_TAG();
    if (state == 0) {
	proc_set_safe_level(proc);
	result = rb_yield_0(args, self, (self!=Qundef)?CLASS_OF(self):0,
			    pcall | YIELD_PROC_CALL, avalue);
    }
    else if (TAG_DST()) {
	result = prot_tag-&gt;retval;
    }
    POP_TAG();
    POP_ITER();
    ruby_block = old_block;
    ruby_wrapper = old_wrapper;
    POP_VARS();
    ruby_safe_level = safe;

    switch (state) {
      case 0:
	break;
      case TAG_RETRY:
	proc_jump_error(TAG_RETRY, Qnil); /* xxx */
	JUMP_TAG(state);
	break;
      case TAG_NEXT:
      case TAG_BREAK:
	if (!pcall &amp;&amp; result != Qundef) {
	    proc_jump_error(state, result);
	}
      case TAG_RETURN:
	if (result != Qundef) {
	    if (pcall) break;
	    return_jump(result);
	}
      default:
	JUMP_TAG(state);
    }
    return result;
}

/* CHECKME: are the argument checking semantics correct? */

/*
 *  call-seq:
 *     prc.call(params,...)   =&gt; obj
 *     prc[params,...]        =&gt; obj
 *  
 *  Invokes the block, setting the block's parameters to the values in
 *  &lt;i&gt;params&lt;/i&gt; using something close to method calling semantics.
 *  Generates a warning if multiple values are passed to a proc that
 *  expects just one (previously this silently converted the parameters
 *  to an array). 
 *
 *  For procs created using &lt;code&gt;Kernel.proc&lt;/code&gt;, generates an 
 *  error if the wrong number of parameters
 *  are passed to a proc with multiple parameters. For procs created using
 *  &lt;code&gt;Proc.new&lt;/code&gt;, extra parameters are silently discarded.
 *
 *  Returns the value of the last expression evaluated in the block. See
 *  also &lt;code&gt;Proc#yield&lt;/code&gt;.
 *     
 *     a_proc = Proc.new {|a, *b| b.collect {|i| i*a }}
 *     a_proc.call(9, 1, 2, 3)   #=&gt; [9, 18, 27]
 *     a_proc[9, 1, 2, 3]        #=&gt; [9, 18, 27]
 *     a_proc = Proc.new {|a,b| a}
 *     a_proc.call(1,2,3)
 *     
 *  &lt;em&gt;produces:&lt;/em&gt;
 *     
 *     prog.rb:5: wrong number of arguments (3 for 2) (ArgumentError)
 *     	from prog.rb:4:in `call'
 *     	from prog.rb:5
 */

VALUE
rb_proc_call(proc, args)
    VALUE proc, args;		/* OK */
{
    return proc_invoke(proc, args, Qundef, 0);
}

static VALUE bmcall _((VALUE, VALUE));
static VALUE method_arity _((VALUE));

/*
 *  call-seq:
 *     prc.arity -&gt; fixnum
 *  
 *  Returns the number of arguments that would not be ignored. If the block
 *  is declared to take no arguments, returns 0. If the block is known
 *  to take exactly n arguments, returns n. If the block has optional
 *  arguments, return -n-1, where n is the number of mandatory
 *  arguments. A &lt;code&gt;proc&lt;/code&gt; with no argument declarations
 *  is the same a block declaring &lt;code&gt;||&lt;/code&gt; as its arguments.
 *     
 *     Proc.new {}.arity          #=&gt;  0
 *     Proc.new {||}.arity        #=&gt;  0
 *     Proc.new {|a|}.arity       #=&gt;  1
 *     Proc.new {|a,b|}.arity     #=&gt;  2
 *     Proc.new {|a,b,c|}.arity   #=&gt;  3
 *     Proc.new {|*a|}.arity      #=&gt; -1
 *     Proc.new {|a,*b|}.arity    #=&gt; -2
 */

static VALUE
proc_arity(proc)
    VALUE proc;
{
    struct BLOCK *data;
    NODE *var, *list;
    int n;

    Data_Get_Struct(proc, struct BLOCK, data);
    var = data-&gt;var;
    if (var == 0) {
	if (data-&gt;body &amp;&amp; nd_type(data-&gt;body) == NODE_IFUNC &amp;&amp;
	    data-&gt;body-&gt;nd_cfnc == bmcall) {
	    return method_arity(data-&gt;body-&gt;nd_tval);
	}
	return INT2FIX(-1);
    }
    if (var == (NODE*)1) return INT2FIX(0);
    if (var == (NODE*)2) return INT2FIX(0);
    if (nd_type(var) == NODE_BLOCK_ARG) {
	var = var-&gt;nd_args;
	if (var == (NODE*)1) return INT2FIX(0);
	if (var == (NODE*)2) return INT2FIX(0);
    }
    switch (nd_type(var)) {
      default:
	return INT2FIX(1);
      case NODE_MASGN:
	list = var-&gt;nd_head;
	n = 0;
	while (list) {
	    n++;
	    list = list-&gt;nd_next;
	}
	if (var-&gt;nd_args) return INT2FIX(-n-1);
	return INT2FIX(n);
    }
}

/*
 * call-seq:
 *   prc == other_proc   =&gt;  true or false
 *
 * Return &lt;code&gt;true&lt;/code&gt; if &lt;i&gt;prc&lt;/i&gt; is the same object as
 * &lt;i&gt;other_proc&lt;/i&gt;, or if they are both procs with the same body.
 */

static VALUE
proc_eq(self, other)
    VALUE self, other;
{
    struct BLOCK *data, *data2;

    if (self == other) return Qtrue;
    if (TYPE(other) != T_DATA) return Qfalse;
    if (RDATA(other)-&gt;dmark != (RUBY_DATA_FUNC)blk_mark) return Qfalse;
    if (CLASS_OF(self) != CLASS_OF(other)) return Qfalse;
    Data_Get_Struct(self, struct BLOCK, data);
    Data_Get_Struct(other, struct BLOCK, data2);
    if (data-&gt;body != data2-&gt;body) return Qfalse;
    if (data-&gt;var != data2-&gt;var) return Qfalse;
    if (data-&gt;scope != data2-&gt;scope) return Qfalse;
    if (data-&gt;dyna_vars != data2-&gt;dyna_vars) return Qfalse;
    if (data-&gt;flags != data2-&gt;flags) return Qfalse;

    return Qtrue;
}

/*
 * call-seq:
 *   prc.to_s   =&gt; string
 *
 * Shows the unique identifier for this proc, along with
 * an indication of where the proc was defined.
 */

static VALUE
proc_to_s(self)
    VALUE self;
{
    struct BLOCK *data;
    NODE *node;
    const char *cname = rb_obj_classname(self);
    const int w = (sizeof(VALUE) * CHAR_BIT) / 4;
    long len = strlen(cname)+6+w; /* 6:tags 16:addr */
    VALUE str;

    Data_Get_Struct(self, struct BLOCK, data);
    if ((node = data-&gt;frame.node) || (node = data-&gt;body)) {
	len += strlen(node-&gt;nd_file) + 2 + (SIZEOF_LONG*CHAR_BIT-NODE_LSHIFT)/3;
	str = rb_str_new(0, len);
	snprintf(RSTRING(str)-&gt;ptr, len+1,
		 &quot;#&lt;%s:0x%.*lx@%s:%d&gt;&quot;, cname, w, (VALUE)data-&gt;body,
		 node-&gt;nd_file, nd_line(node));
    }
    else {
	str = rb_str_new(0, len);
	snprintf(RSTRING(str)-&gt;ptr, len+1,
		 &quot;#&lt;%s:0x%.*lx&gt;&quot;, cname, w, (VALUE)data-&gt;body);
    }
    RSTRING(str)-&gt;len = strlen(RSTRING(str)-&gt;ptr);
    if (OBJ_TAINTED(self)) OBJ_TAINT(str);

    return str;
}

/*
 *  call-seq:
 *     prc.to_proc -&gt; prc
 *  
 *  Part of the protocol for converting objects to &lt;code&gt;Proc&lt;/code&gt;
 *  objects. Instances of class &lt;code&gt;Proc&lt;/code&gt; simply return
 *  themselves.
 */

static VALUE
proc_to_self(self)
    VALUE self;
{
    return self;
}

/*
 *  call-seq:
 *     prc.binding    =&gt; binding
 *  
 *  Returns the binding associated with &lt;i&gt;prc&lt;/i&gt;. Note that
 *  &lt;code&gt;Kernel#eval&lt;/code&gt; accepts either a &lt;code&gt;Proc&lt;/code&gt; or a
 *  &lt;code&gt;Binding&lt;/code&gt; object as its second parameter.
 *     
 *     def fred(param)
 *       proc {}
 *     end
 *     
 *     b = fred(99)
 *     eval(&quot;param&quot;, b.binding)   #=&gt; 99
 *     eval(&quot;param&quot;, b)           #=&gt; 99
 */

static VALUE
proc_binding(proc)
    VALUE proc;
{
    struct BLOCK *orig, *data;
    VALUE bind;

    Data_Get_Struct(proc, struct BLOCK, orig);
    bind = Data_Make_Struct(rb_cBinding,struct BLOCK,blk_mark,blk_free,data);
    MEMCPY(data, orig, struct BLOCK, 1);
    frame_dup(&amp;data-&gt;frame);

    if (data-&gt;iter) {
	blk_copy_prev(data);
    }
    else {
	data-&gt;prev = 0;
    }

    return bind;
}

static VALUE
block_pass(self, node)
    VALUE self;
    NODE *node;
{
    VALUE proc = rb_eval(self, node-&gt;nd_body);	/* OK */
    VALUE b;
    struct BLOCK * volatile old_block;
    struct BLOCK _block;
    struct BLOCK *data;
    volatile VALUE result = Qnil;
    int state;
    volatile int orphan;
    volatile int safe = ruby_safe_level;

    if (NIL_P(proc)) {
	PUSH_ITER(ITER_NOT);
	result = rb_eval(self, node-&gt;nd_iter);
	POP_ITER();
	return result;
    }
    if (!rb_obj_is_proc(proc)) {
	b = rb_check_convert_type(proc, T_DATA, &quot;Proc&quot;, &quot;to_proc&quot;);
	if (!rb_obj_is_proc(b)) {
	    rb_raise(rb_eTypeError, &quot;wrong argument type %s (expected Proc)&quot;,
		     rb_obj_classname(proc));
	}
	proc = b;
    }

    if (ruby_safe_level &gt;= 1 &amp;&amp; OBJ_TAINTED(proc) &amp;&amp;
	ruby_safe_level &gt; proc_get_safe_level(proc)) {
	rb_raise(rb_eSecurityError, &quot;Insecure: tainted block value&quot;);
    }

    if (ruby_block &amp;&amp; ruby_block-&gt;block_obj == proc) {
	PUSH_ITER(ITER_PAS);
	result = rb_eval(self, node-&gt;nd_iter);
	POP_ITER();
	return result;
    }

    Data_Get_Struct(proc, struct BLOCK, data);
    orphan = block_orphan(data);

    /* PUSH BLOCK from data */
    old_block = ruby_block;
    _block = *data;
    _block.outer = ruby_block;
    if (orphan) _block.uniq = block_unique++;
    ruby_block = &amp;_block;
    PUSH_ITER(ITER_PRE);
    if (ruby_frame-&gt;iter == ITER_NOT)
	ruby_frame-&gt;iter = ITER_PRE;

    PUSH_TAG(PROT_LOOP);
    state = EXEC_TAG();
    if (state == 0) {
      retry:
	proc_set_safe_level(proc);
	if (safe &gt; ruby_safe_level)
	    ruby_safe_level = safe;
	result = rb_eval(self, node-&gt;nd_iter);
    }
    else if (state == TAG_BREAK &amp;&amp; TAG_DST()) {
	result = prot_tag-&gt;retval;
	state = 0;
    }
    else if (state == TAG_RETRY) {
	state = 0;
	goto retry;
    }
    POP_TAG();
    POP_ITER();
    ruby_block = old_block;
    ruby_safe_level = safe;

    switch (state) {/* escape from orphan block */
      case 0:
	break;
      case TAG_RETURN:
	if (orphan) {
	    proc_jump_error(state, prot_tag-&gt;retval);
	}
      default:
	JUMP_TAG(state);
    }

    return result;
}

struct METHOD {
    VALUE klass, rklass;
    VALUE recv;
    ID id, oid;
    int safe_level;
    NODE *body;
};

static void
bm_mark(data)
    struct METHOD *data;
{
    rb_gc_mark(data-&gt;rklass);
    rb_gc_mark(data-&gt;klass);
    rb_gc_mark(data-&gt;recv);
    rb_gc_mark((VALUE)data-&gt;body);
}

static VALUE
mnew(klass, obj, id, mklass)
    VALUE klass, obj, mklass;
    ID id;
{
    VALUE method;
    NODE *body;
    int noex;
    struct METHOD *data;
    VALUE rklass = klass;
    ID oid = id;

  again:
    if ((body = rb_get_method_body(&amp;klass, &amp;id, &amp;noex)) == 0) {
	print_undef(rklass, oid);
    }

    if (nd_type(body) == NODE_ZSUPER) {
	klass = RCLASS(klass)-&gt;super;
	goto again;
    }

    while (rklass != klass &amp;&amp;
	   (FL_TEST(rklass, FL_SINGLETON) || TYPE(rklass) == T_ICLASS)) {
	rklass = RCLASS(rklass)-&gt;super;
    }
    if (TYPE(klass) == T_ICLASS) klass = RBASIC(klass)-&gt;klass;
    method = Data_Make_Struct(mklass, struct METHOD, bm_mark, free, data);
    data-&gt;klass = klass;
    data-&gt;recv = obj;
    data-&gt;id = id;
    data-&gt;body = body;
    data-&gt;rklass = rklass;
    data-&gt;oid = oid;
    data-&gt;safe_level = NOEX_WITH_SAFE(noex);
    OBJ_INFECT(method, klass);

    return method;
}


/**********************************************************************
 *
 * Document-class : Method
 *
 *  Method objects are created by &lt;code&gt;Object#method&lt;/code&gt;, and are
 *  associated with a particular object (not just with a class). They
 *  may be used to invoke the method within the object, and as a block
 *  associated with an iterator. They may also be unbound from one
 *  object (creating an &lt;code&gt;UnboundMethod&lt;/code&gt;) and bound to
 *  another.
 *     
 *     class Thing
 *       def square(n)
 *         n*n
 *       end
 *     end
 *     thing = Thing.new
 *     meth  = thing.method(:square)
 *     
 *     meth.call(9)                 #=&gt; 81
 *     [ 1, 2, 3 ].collect(&amp;meth)   #=&gt; [1, 4, 9]
 *     
 */

/*
 * call-seq:
 *   meth == other_meth  =&gt; true or false
 *
 * Two method objects are equal if that are bound to the same
 * object and contain the same body.
 */


static VALUE
method_eq(method, other)
    VALUE method, other;
{
    struct METHOD *m1, *m2;

    if (TYPE(other) != T_DATA || RDATA(other)-&gt;dmark != (RUBY_DATA_FUNC)bm_mark)
	return Qfalse;
    if (CLASS_OF(method) != CLASS_OF(other))
	return Qfalse;

    Data_Get_Struct(method, struct METHOD, m1);
    Data_Get_Struct(other, struct METHOD, m2);

    if (m1-&gt;klass != m2-&gt;klass || m1-&gt;rklass != m2-&gt;rklass ||
	m1-&gt;recv != m2-&gt;recv || m1-&gt;body != m2-&gt;body)
	return Qfalse;

    return Qtrue;
}

/*
 *  call-seq:
 *     meth.unbind    =&gt; unbound_method
 *  
 *  Dissociates &lt;i&gt;meth&lt;/i&gt; from it's current receiver. The resulting
 *  &lt;code&gt;UnboundMethod&lt;/code&gt; can subsequently be bound to a new object
 *  of the same class (see &lt;code&gt;UnboundMethod&lt;/code&gt;).
 */

static VALUE
method_unbind(obj)
    VALUE obj;
{
    VALUE method;
    struct METHOD *orig, *data;

    Data_Get_Struct(obj, struct METHOD, orig);
    method = Data_Make_Struct(rb_cUnboundMethod, struct METHOD, bm_mark, free, data);
    data-&gt;klass = orig-&gt;klass;
    data-&gt;recv = Qundef;
    data-&gt;id = orig-&gt;id;
    data-&gt;body = orig-&gt;body;
    data-&gt;rklass = orig-&gt;rklass;
    data-&gt;oid = orig-&gt;oid;
    OBJ_INFECT(method, obj);

    return method;
}

/*
 *  call-seq:
 *     meth.receiver    =&gt; object
 *
 *  Returns the bound receiver of the method object.
 */

static VALUE
method_receiver(obj)
    VALUE obj;
{
    struct METHOD *data;

    Data_Get_Struct(obj, struct METHOD, data);
    return data-&gt;recv;
}

/*
 *  call-seq:
 *     meth.name    =&gt; string
 *
 *  Returns the name of the method.
 */

static VALUE
method_name(obj)
    VALUE obj;
{
    struct METHOD *data;

    Data_Get_Struct(obj, struct METHOD, data);
    return rb_str_new2(rb_id2name(data-&gt;oid));
}

/*
 *  call-seq:
 *     meth.owner    =&gt; class_or_module
 *
 *  Returns the class or module that defines the method.
 */

static VALUE
method_owner(obj)
    VALUE obj;
{
    struct METHOD *data;

    Data_Get_Struct(obj, struct METHOD, data);
    return data-&gt;klass;
}

/*
 *  call-seq:
 *     obj.method(sym)    =&gt; method
 *  
 *  Looks up the named method as a receiver in &lt;i&gt;obj&lt;/i&gt;, returning a
 *  &lt;code&gt;Method&lt;/code&gt; object (or raising &lt;code&gt;NameError&lt;/code&gt;). The
 *  &lt;code&gt;Method&lt;/code&gt; object acts as a closure in &lt;i&gt;obj&lt;/i&gt;'s object
 *  instance, so instance variables and the value of &lt;code&gt;self&lt;/code&gt;
 *  remain available.
 *     
 *     class Demo
 *       def initialize(n)
 *         @iv = n
 *       end
 *       def hello()
 *         &quot;Hello, @iv = #{@iv}&quot;
 *       end
 *     end
 *     
 *     k = Demo.new(99)
 *     m = k.method(:hello)
 *     m.call   #=&gt; &quot;Hello, @iv = 99&quot;
 *     
 *     l = Demo.new('Fred')
 *     m = l.method(&quot;hello&quot;)
 *     m.call   #=&gt; &quot;Hello, @iv = Fred&quot;
 */

VALUE
rb_obj_method(obj, vid)
    VALUE obj;
    VALUE vid;
{
    return mnew(CLASS_OF(obj), obj, rb_to_id(vid), rb_cMethod);
}

/*
 *  call-seq:
 *     mod.instance_method(symbol)   =&gt; unbound_method
 *  
 *  Returns an +UnboundMethod+ representing the given
 *  instance method in _mod_.
 *     
 *     class Interpreter
 *       def do_a() print &quot;there, &quot;; end
 *       def do_d() print &quot;Hello &quot;;  end
 *       def do_e() print &quot;!\n&quot;;     end
 *       def do_v() print &quot;Dave&quot;;    end
 *       Dispatcher = {
 *        ?a =&gt; instance_method(:do_a),
 *        ?d =&gt; instance_method(:do_d),
 *        ?e =&gt; instance_method(:do_e),
 *        ?v =&gt; instance_method(:do_v)
 *       }
 *       def interpret(string)
 *         string.each_byte {|b| Dispatcher[b].bind(self).call }
 *       end
 *     end
 *     
 *     
 *     interpreter = Interpreter.new
 *     interpreter.interpret('dave')
 *     
 *  &lt;em&gt;produces:&lt;/em&gt;
 *     
 *     Hello there, Dave!
 */

static VALUE
rb_mod_method(mod, vid)
    VALUE mod;
    VALUE vid;
{
    return mnew(mod, Qundef, rb_to_id(vid), rb_cUnboundMethod);
}

/*
 * MISSING: documentation
 */

static VALUE
method_clone(self)
    VALUE self;
{
    VALUE clone;
    struct METHOD *orig, *data;

    Data_Get_Struct(self, struct METHOD, orig);
    clone = Data_Make_Struct(CLASS_OF(self),struct METHOD, bm_mark, free, data);
    CLONESETUP(clone, self);
    *data = *orig;

    return clone;
}

VALUE
rb_method_dup(self, klass, cref)
    VALUE self;
    VALUE klass;
    VALUE cref;
{
    VALUE clone;
    struct METHOD *orig, *data;

    Data_Get_Struct(self, struct METHOD, orig);
    clone = Data_Make_Struct(CLASS_OF(self),struct METHOD, bm_mark, free, data);
    *data = *orig;
    data-&gt;rklass = klass;
    if (data-&gt;body-&gt;nd_rval) {
	NODE *tmp = NEW_NODE(nd_type(data-&gt;body-&gt;u2.node), cref,
			     data-&gt;body-&gt;u2.node-&gt;u2.node,
			     data-&gt;body-&gt;u2.node-&gt;u3.node);
	data-&gt;body = NEW_NODE(nd_type(data-&gt;body), data-&gt;body-&gt;u1.node, tmp,
			      data-&gt;body-&gt;u3.node);
    }
    return clone;
}

/*
 *  call-seq:
 *     meth.call(args, ...)    =&gt; obj
 *     meth[args, ...]         =&gt; obj
 *  
 *  Invokes the &lt;i&gt;meth&lt;/i&gt; with the specified arguments, returning the
 *  method's return value.
 *     
 *     m = 12.method(&quot;+&quot;)
 *     m.call(3)    #=&gt; 15
 *     m.call(20)   #=&gt; 32
 */

static VALUE
method_call(argc, argv, method)
    int argc;
    VALUE *argv;
    VALUE method;
{
    VALUE result = Qnil;	/* OK */
    struct METHOD *data;
    int safe;

    Data_Get_Struct(method, struct METHOD, data);
    if (data-&gt;recv == Qundef) {
	rb_raise(rb_eTypeError, &quot;can't call unbound method; bind first&quot;);
    }
    if (OBJ_TAINTED(method)) {
        safe = NOEX_WITH(data-&gt;safe_level, 4)|NOEX_TAINTED;
    }
    else {
	safe = data-&gt;safe_level;
    }
    PUSH_ITER(rb_block_given_p()?ITER_PRE:ITER_NOT);
    result = rb_call0(data-&gt;klass,data-&gt;recv,data-&gt;id,data-&gt;oid,argc,argv,data-&gt;body,safe);
    POP_ITER();
    return result;
}

/**********************************************************************
 *
 * Document-class: UnboundMethod
 *
 *  Ruby supports two forms of objectified methods. Class
 *  &lt;code&gt;Method&lt;/code&gt; is used to represent methods that are associated
 *  with a particular object: these method objects are bound to that
 *  object. Bound method objects for an object can be created using
 *  &lt;code&gt;Object#method&lt;/code&gt;.
 *     
 *  Ruby also supports unbound methods; methods objects that are not
 *  associated with a particular object. These can be created either by
 *  calling &lt;code&gt;Module#instance_method&lt;/code&gt; or by calling
 *  &lt;code&gt;unbind&lt;/code&gt; on a bound method object. The result of both of
 *  these is an &lt;code&gt;UnboundMethod&lt;/code&gt; object.
 *     
 *  Unbound methods can only be called after they are bound to an
 *  object. That object must be be a kind_of? the method's original
 *  class.
 *     
 *     class Square
 *       def area
 *         @side * @side
 *       end
 *       def initialize(side)
 *         @side = side
 *       end
 *     end
 *     
 *     area_un = Square.instance_method(:area)
 *     
 *     s = Square.new(12)
 *     area = area_un.bind(s)
 *     area.call   #=&gt; 144
 *     
 *  Unbound methods are a reference to the method at the time it was
 *  objectified: subsequent changes to the underlying class will not
 *  affect the unbound method.
 *     
 *     class Test
 *       def test
 *         :original
 *       end
 *     end
 *     um = Test.instance_method(:test)
 *     class Test
 *       def test
 *         :modified
 *       end
 *     end
 *     t = Test.new
 *     t.test            #=&gt; :modified
 *     um.bind(t).call   #=&gt; :original
 *     
 */

/*
 *  call-seq:
 *     umeth.bind(obj) -&gt; method
 *  
 *  Bind &lt;i&gt;umeth&lt;/i&gt; to &lt;i&gt;obj&lt;/i&gt;. If &lt;code&gt;Klass&lt;/code&gt; was the class
 *  from which &lt;i&gt;umeth&lt;/i&gt; was obtained,
 *  &lt;code&gt;obj.kind_of?(Klass)&lt;/code&gt; must be true.
 *     
 *     class A
 *       def test
 *         puts &quot;In test, class = #{self.class}&quot;
 *       end
 *     end
 *     class B &lt; A
 *     end
 *     class C &lt; B
 *     end
 *     
 *     
 *     um = B.instance_method(:test)
 *     bm = um.bind(C.new)
 *     bm.call
 *     bm = um.bind(B.new)
 *     bm.call
 *     bm = um.bind(A.new)
 *     bm.call
 *     
 *  &lt;em&gt;produces:&lt;/em&gt;
 *     
 *     In test, class = C
 *     In test, class = B
 *     prog.rb:16:in `bind': bind argument must be an instance of B (TypeError)
 *     	from prog.rb:16
 */

static VALUE
umethod_bind(method, recv)
    VALUE method, recv;
{
    struct METHOD *data, *bound;
    VALUE rklass = CLASS_OF(recv);

    Data_Get_Struct(method, struct METHOD, data);
    if (data-&gt;rklass != rklass) {
	if (FL_TEST(data-&gt;rklass, FL_SINGLETON)) {
	    rb_raise(rb_eTypeError, &quot;singleton method bound for a different object&quot;);
	}
	if (TYPE(data-&gt;rklass) == T_MODULE) {
	    st_table *m_tbl = RCLASS(data-&gt;rklass)-&gt;m_tbl;
	    while (RCLASS(rklass)-&gt;m_tbl != m_tbl) {
		rklass = RCLASS(rklass)-&gt;super;
		if (!rklass) goto not_instace;
	    }
	}
	else if (!rb_obj_is_kind_of(recv, data-&gt;rklass)) {
	  not_instace:
	    rb_raise(rb_eTypeError, &quot;bind argument must be an instance of %s&quot;,
		     rb_class2name(data-&gt;rklass));
	}
    }

    method = Data_Make_Struct(rb_cMethod,struct METHOD,bm_mark,free,bound);
    *bound = *data;
    bound-&gt;recv = recv;
    bound-&gt;rklass = rklass;

    return method;
}

/*
 *  call-seq:
 *     meth.arity    =&gt; fixnum
 *  
 *  Returns an indication of the number of arguments accepted by a
 *  method. Returns a nonnegative integer for methods that take a fixed
 *  number of arguments. For Ruby methods that take a variable number of
 *  arguments, returns -n-1, where n is the number of required
 *  arguments. For methods written in C, returns -1 if the call takes a
 *  variable number of arguments.
 *     
 *     class C
 *       def one;    end
 *       def two(a); end
 *       def three(*a);  end
 *       def four(a, b); end
 *       def five(a, b, *c);    end
 *       def six(a, b, *c, &amp;d); end
 *     end
 *     c = C.new
 *     c.method(:one).arity     #=&gt; 0
 *     c.method(:two).arity     #=&gt; 1
 *     c.method(:three).arity   #=&gt; -1
 *     c.method(:four).arity    #=&gt; 2
 *     c.method(:five).arity    #=&gt; -3
 *     c.method(:six).arity     #=&gt; -3
 *     
 *     &quot;cat&quot;.method(:size).arity      #=&gt; 0
 *     &quot;cat&quot;.method(:replace).arity   #=&gt; 1
 *     &quot;cat&quot;.method(:squeeze).arity   #=&gt; -1
 *     &quot;cat&quot;.method(:count).arity     #=&gt; -1
 */

static VALUE
method_arity(method)
    VALUE method;
{
    struct METHOD *data;
    NODE *body;
    int n;

    Data_Get_Struct(method, struct METHOD, data);

    body = data-&gt;body;
    switch (nd_type(body)) {
      case NODE_CFUNC:
	if (body-&gt;nd_argc &lt; 0) return INT2FIX(-1);
	return INT2FIX(body-&gt;nd_argc);
      case NODE_ZSUPER:
	return INT2FIX(-1);
      case NODE_ATTRSET:
	return INT2FIX(1);
      case NODE_IVAR:
	return INT2FIX(0);
      case NODE_BMETHOD:
	return proc_arity(body-&gt;nd_cval);
      case NODE_DMETHOD:
	return method_arity(body-&gt;nd_cval);
      case NODE_SCOPE:
	body = body-&gt;nd_next;	/* skip NODE_SCOPE */
	if (nd_type(body) == NODE_BLOCK)
	    body = body-&gt;nd_head;
	if (!body) return INT2FIX(0);
	n = body-&gt;nd_cnt;
	if (body-&gt;nd_opt || body-&gt;nd_rest)
	    n = -n-1;
	return INT2FIX(n);
      default:
	rb_raise(rb_eArgError, &quot;invalid node 0x%x&quot;, nd_type(body));
   }
}

/*
 *  call-seq:
 *   meth.to_s      =&gt;  string
 *   meth.inspect   =&gt;  string
 *
 *  Show the name of the underlying method.
 *
 *    &quot;cat&quot;.method(:count).inspect   #=&gt; &quot;#&lt;Method: String#count&gt;&quot;
 */

static VALUE
method_inspect(method)
    VALUE method;
{
    struct METHOD *data;
    VALUE str;
    const char *s;
    const char *sharp = &quot;#&quot;;

    Data_Get_Struct(method, struct METHOD, data);
    str = rb_str_buf_new2(&quot;#&lt;&quot;);
    s = rb_obj_classname(method);
    rb_str_buf_cat2(str, s);
    rb_str_buf_cat2(str, &quot;: &quot;);

    if (FL_TEST(data-&gt;klass, FL_SINGLETON)) {
	VALUE v = rb_iv_get(data-&gt;klass, &quot;__attached__&quot;);

	if (data-&gt;recv == Qundef) {
	    rb_str_buf_append(str, rb_inspect(data-&gt;klass));
	}
	else if (data-&gt;recv == v) {
	    rb_str_buf_append(str, rb_inspect(v));
	    sharp = &quot;.&quot;;
	}
	else {
	    rb_str_buf_append(str, rb_inspect(data-&gt;recv));
	    rb_str_buf_cat2(str, &quot;(&quot;);
	    rb_str_buf_append(str, rb_inspect(v));
	    rb_str_buf_cat2(str, &quot;)&quot;);
	    sharp = &quot;.&quot;;
	}
    }
    else {
	rb_str_buf_cat2(str, rb_class2name(data-&gt;rklass));
	if (data-&gt;rklass != data-&gt;klass) {
	    rb_str_buf_cat2(str, &quot;(&quot;);
	    rb_str_buf_cat2(str, rb_class2name(data-&gt;klass));
	    rb_str_buf_cat2(str, &quot;)&quot;);
	}
    }
    rb_str_buf_cat2(str, sharp);
    rb_str_buf_cat2(str, rb_id2name(data-&gt;oid));
    rb_str_buf_cat2(str, &quot;&gt;&quot;);

    return str;
}

static VALUE
mproc(method)
    VALUE method;
{
    VALUE proc;

    /* emulate ruby's method call */
    PUSH_ITER(ITER_CUR);
    PUSH_FRAME();
    proc = rb_block_proc();
    POP_FRAME();
    POP_ITER();

    return proc;
}

static VALUE
bmcall(args, method)
    VALUE args, method;
{
    volatile VALUE a;
    VALUE ret;

    a = svalue_to_avalue(args);
    ret = method_call(RARRAY(a)-&gt;len, RARRAY(a)-&gt;ptr, method);
    a = Qnil; /* prevent tail call */
    return ret;
}

VALUE
rb_proc_new(func, val)
    VALUE (*func)(ANYARGS);	/* VALUE yieldarg[, VALUE procarg] */
    VALUE val;
{
    struct BLOCK *data;
    VALUE proc = rb_iterate((VALUE(*)_((VALUE)))mproc, 0, func, val);

    Data_Get_Struct(proc, struct BLOCK, data);
    data-&gt;body-&gt;nd_state = YIELD_FUNC_LAMBDA;
    data-&gt;flags |= BLOCK_LAMBDA;
    return proc;
}

/*
 *  call-seq:
 *     meth.to_proc    =&gt; prc
 *  
 *  Returns a &lt;code&gt;Proc&lt;/code&gt; object corresponding to this method.
 */

static VALUE
method_proc(method)
    VALUE method;
{
    VALUE proc;
    struct METHOD *mdata;
    struct BLOCK *bdata;

    proc = rb_iterate((VALUE(*)_((VALUE)))mproc, 0, bmcall, method);
    Data_Get_Struct(method, struct METHOD, mdata);
    Data_Get_Struct(proc, struct BLOCK, bdata);
    bdata-&gt;body-&gt;nd_file = mdata-&gt;body-&gt;nd_file;
    nd_set_line(bdata-&gt;body, nd_line(mdata-&gt;body));
    bdata-&gt;body-&gt;nd_state = YIELD_FUNC_SVALUE;

    return proc;
}

static VALUE
rb_obj_is_method(m)
    VALUE m;
{
    if (TYPE(m) == T_DATA &amp;&amp; RDATA(m)-&gt;dmark == (RUBY_DATA_FUNC)bm_mark) {
	return Qtrue;
    }
    return Qfalse;
}

/*
 *  call-seq:
 *     define_method(symbol, method)     =&gt; new_method
 *     define_method(symbol) { block }   =&gt; proc
 *  
 *  Defines an instance method in the receiver. The _method_
 *  parameter can be a +Proc+ or +Method+ object.
 *  If a block is specified, it is used as the method body. This block
 *  is evaluated using &lt;code&gt;instance_eval&lt;/code&gt;, a point that is
 *  tricky to demonstrate because &lt;code&gt;define_method&lt;/code&gt; is private.
 *  (This is why we resort to the +send+ hack in this example.)
 *     
 *     class A
 *       def fred
 *         puts &quot;In Fred&quot;
 *       end
 *       def create_method(name, &amp;block)
 *         self.class.send(:define_method, name, &amp;block)
 *       end
 *       define_method(:wilma) { puts &quot;Charge it!&quot; }
 *     end
 *     class B &lt; A
 *       define_method(:barney, instance_method(:fred))
 *     end
 *     a = B.new
 *     a.barney
 *     a.wilma
 *     a.create_method(:betty) { p self }
 *     a.betty
 *     
 *  &lt;em&gt;produces:&lt;/em&gt;
 *     
 *     In Fred
 *     Charge it!
 *     #&lt;B:0x401b39e8&gt;
 */

static VALUE
rb_mod_define_method(argc, argv, mod)
    int argc;
    VALUE *argv;
    VALUE mod;
{
    ID id;
    VALUE body;
    NODE *node;
    int noex;

    if (argc == 1) {
	id = rb_to_id(argv[0]);
	body = proc_lambda();
    }
    else if (argc == 2) {
	id = rb_to_id(argv[0]);
	body = argv[1];
	if (!rb_obj_is_method(body) &amp;&amp; !rb_obj_is_proc(body)) {
	    rb_raise(rb_eTypeError, &quot;wrong argument type %s (expected Proc/Method)&quot;,
		     rb_obj_classname(body));
	}
    }
    else {
	rb_raise(rb_eArgError, &quot;wrong number of arguments (%d for 1)&quot;, argc);
    }
    if (RDATA(body)-&gt;dmark == (RUBY_DATA_FUNC)bm_mark) {
	node = NEW_DMETHOD(method_unbind(body));
    }
    else if (RDATA(body)-&gt;dmark == (RUBY_DATA_FUNC)blk_mark) {
	struct BLOCK *block;

	body = proc_clone(body);
	Data_Get_Struct(body, struct BLOCK, block);
	block-&gt;frame.last_func = id;
	block-&gt;frame.orig_func = id;
	block-&gt;frame.last_class = mod;
	node = NEW_BMETHOD(body);
    }
    else {
	/* type error */
	rb_raise(rb_eTypeError, &quot;wrong argument type (expected Proc/Method)&quot;);
    }

    noex = NOEX_PUBLIC;
    if (ruby_cbase == mod) {
	if (SCOPE_TEST(SCOPE_PRIVATE)) {
	    noex = NOEX_PRIVATE;
	}
	else if (SCOPE_TEST(SCOPE_PROTECTED)) {
	    noex = NOEX_PROTECTED;
	}
    }
    rb_add_method(mod, id, node, noex);
    return body;
}

/*
 *  &lt;code&gt;Proc&lt;/code&gt; objects are blocks of code that have been bound to
 *  a set of local variables. Once bound, the code may be called in
 *  different contexts and still access those variables.
 *     
 *     def gen_times(factor)
 *       return Proc.new {|n| n*factor }
 *     end
 *     
 *     times3 = gen_times(3)
 *     times5 = gen_times(5)
 *     
 *     times3.call(12)               #=&gt; 36
 *     times5.call(5)                #=&gt; 25
 *     times3.call(times5.call(4))   #=&gt; 60
 *     
 */

void
Init_Proc()
{
    rb_eLocalJumpError = rb_define_class(&quot;LocalJumpError&quot;, rb_eStandardError);
    rb_define_method(rb_eLocalJumpError, &quot;exit_value&quot;, localjump_xvalue, 0);
    rb_define_method(rb_eLocalJumpError, &quot;reason&quot;, localjump_reason, 0);

    rb_global_variable(&amp;exception_error);
    exception_error = rb_exc_new2(rb_eFatal, &quot;exception reentered&quot;);

    rb_eSysStackError = rb_define_class(&quot;SystemStackError&quot;, rb_eStandardError);
    rb_global_variable(&amp;sysstack_error);
    sysstack_error = rb_exc_new2(rb_eSysStackError, &quot;stack level too deep&quot;);
    OBJ_TAINT(sysstack_error);

    rb_cProc = rb_define_class(&quot;Proc&quot;, rb_cObject);
    rb_undef_alloc_func(rb_cProc);
    rb_define_singleton_method(rb_cProc, &quot;new&quot;, proc_s_new, -1);

    rb_define_method(rb_cProc, &quot;clone&quot;, proc_clone, 0);
    rb_define_method(rb_cProc, &quot;dup&quot;, proc_dup, 0);
    rb_define_method(rb_cProc, &quot;call&quot;, rb_proc_call, -2);
    rb_define_method(rb_cProc, &quot;arity&quot;, proc_arity, 0);
    rb_define_method(rb_cProc, &quot;[]&quot;, rb_proc_call, -2);
    rb_define_method(rb_cProc, &quot;==&quot;, proc_eq, 1);
    rb_define_method(rb_cProc, &quot;to_s&quot;, proc_to_s, 0);
    rb_define_method(rb_cProc, &quot;to_proc&quot;, proc_to_self, 0);
    rb_define_method(rb_cProc, &quot;binding&quot;, proc_binding, 0);

    rb_define_global_function(&quot;proc&quot;, proc_lambda, 0);
    rb_define_global_function(&quot;lambda&quot;, proc_lambda, 0);

    rb_cMethod = rb_define_class(&quot;Method&quot;, rb_cObject);
    rb_undef_alloc_func(rb_cMethod);
    rb_undef_method(CLASS_OF(rb_cMethod), &quot;new&quot;);
    rb_define_method(rb_cMethod, &quot;==&quot;, method_eq, 1);
    rb_define_method(rb_cMethod, &quot;clone&quot;, method_clone, 0);
    rb_define_method(rb_cMethod, &quot;call&quot;, method_call, -1);
    rb_define_method(rb_cMethod, &quot;[]&quot;, method_call, -1);
    rb_define_method(rb_cMethod, &quot;arity&quot;, method_arity, 0);
    rb_define_method(rb_cMethod, &quot;inspect&quot;, method_inspect, 0);
    rb_define_method(rb_cMethod, &quot;to_s&quot;, method_inspect, 0);
    rb_define_method(rb_cMethod, &quot;to_proc&quot;, method_proc, 0);
    rb_define_method(rb_cMethod, &quot;receiver&quot;, method_receiver, 0);
    rb_define_method(rb_cMethod, &quot;name&quot;, method_name, 0);
    rb_define_method(rb_cMethod, &quot;owner&quot;, method_owner, 0);
    rb_define_method(rb_cMethod, &quot;unbind&quot;, method_unbind, 0);
    rb_define_method(rb_mKernel, &quot;method&quot;, rb_obj_method, 1);

    rb_cUnboundMethod = rb_define_class(&quot;UnboundMethod&quot;, rb_cObject);
    rb_undef_alloc_func(rb_cUnboundMethod);
    rb_undef_method(CLASS_OF(rb_cUnboundMethod), &quot;new&quot;);
    rb_define_method(rb_cUnboundMethod, &quot;==&quot;, method_eq, 1);
    rb_define_method(rb_cUnboundMethod, &quot;clone&quot;, method_clone, 0);
    rb_define_method(rb_cUnboundMethod, &quot;arity&quot;, method_arity, 0);
    rb_define_method(rb_cUnboundMethod, &quot;inspect&quot;, method_inspect, 0);
    rb_define_method(rb_cUnboundMethod, &quot;to_s&quot;, method_inspect, 0);
    rb_define_method(rb_cUnboundMethod, &quot;name&quot;, method_name, 0);
    rb_define_method(rb_cUnboundMethod, &quot;owner&quot;, method_owner, 0);
    rb_define_method(rb_cUnboundMethod, &quot;bind&quot;, umethod_bind, 1);
    rb_define_method(rb_cModule, &quot;instance_method&quot;, rb_mod_method, 1);
}

/*
 *  Objects of class &lt;code&gt;Binding&lt;/code&gt; encapsulate the execution
 *  context at some particular place in the code and retain this context 
 *  for future use. The variables, methods, value of &lt;code&gt;self&lt;/code&gt;,
 *  and possibly an iterator block that can be accessed in this context
 *  are all retained. Binding objects can be created using
 *  &lt;code&gt;Kernel#binding&lt;/code&gt;, and are made available to the callback
 *  of &lt;code&gt;Kernel#set_trace_func&lt;/code&gt;.
 *     
 *  These binding objects can be passed as the second argument of the
 *  &lt;code&gt;Kernel#eval&lt;/code&gt; method, establishing an environment for the
 *  evaluation.
 *     
 *     class Demo
 *       def initialize(n)
 *         @secret = n
 *       end
 *       def getBinding
 *         return binding()
 *       end
 *     end
 *     
 *     k1 = Demo.new(99)
 *     b1 = k1.getBinding
 *     k2 = Demo.new(-3)
 *     b2 = k2.getBinding
 *     
 *     eval(&quot;@secret&quot;, b1)   #=&gt; 99
 *     eval(&quot;@secret&quot;, b2)   #=&gt; -3
 *     eval(&quot;@secret&quot;)       #=&gt; nil
 *     
 *  Binding objects have no class-specific methods.
 *     
 */

void 
Init_Binding() 
{
    rb_cBinding = rb_define_class(&quot;Binding&quot;, rb_cObject);
    rb_undef_alloc_func(rb_cBinding);
    rb_undef_method(CLASS_OF(rb_cBinding), &quot;new&quot;);
    rb_define_method(rb_cBinding, &quot;clone&quot;, proc_clone, 0);
    rb_define_method(rb_cBinding, &quot;dup&quot;, proc_dup, 0);
    rb_define_method(rb_cBinding, &quot;eval&quot;, bind_eval, -1);
    rb_define_global_function(&quot;binding&quot;, rb_f_binding, 0);
}

/* Windows SEH refers data on the stack. */
#undef SAVE_WIN32_EXCEPTION_LIST
#if defined _WIN32 || defined __CYGWIN__
#if defined __CYGWIN__
typedef unsigned long DWORD;
#endif

static inline DWORD
win32_get_exception_list()
{
    DWORD p;
# if defined _MSC_VER
#   ifdef _M_IX86
#   define SAVE_WIN32_EXCEPTION_LIST
#   if _MSC_VER &gt;= 1310
      /* warning: unsafe assignment to fs:0 ... this is ok */
#     pragma warning(disable: 4733)
#   endif
    __asm mov eax, fs:[0];
    __asm mov p, eax;
#   endif
# elif defined __GNUC__
#   ifdef __i386__
#   define SAVE_WIN32_EXCEPTION_LIST
    __asm__(&quot;movl %%fs:0,%0&quot; : &quot;=r&quot;(p));
#   endif
# elif defined __BORLANDC__
#   define SAVE_WIN32_EXCEPTION_LIST
    __emit__(0x64, 0xA1, 0, 0, 0, 0); /* mov eax, fs:[0] */
    p = _EAX;
# endif
    return p;
}

static inline void
win32_set_exception_list(p)
    DWORD p;
{
# if defined _MSC_VER
#   ifdef _M_IX86
    __asm mov eax, p;
    __asm mov fs:[0], eax;
#   endif
# elif defined __GNUC__
#   ifdef __i386__
    __asm__(&quot;movl %0,%%fs:0&quot; :: &quot;r&quot;(p));
#   endif
# elif defined __BORLANDC__
    _EAX = p;
    __emit__(0x64, 0xA3, 0, 0, 0, 0); /* mov fs:[0], eax */
# endif
}

#if !defined SAVE_WIN32_EXCEPTION_LIST &amp;&amp; !defined _WIN32_WCE
# error unsupported platform
#endif
#endif

int rb_thread_pending = 0;

VALUE rb_cThread;

extern VALUE rb_last_status;

#define WAIT_FD		(1&lt;&lt;0)
#define WAIT_SELECT	(1&lt;&lt;1)
#define WAIT_TIME	(1&lt;&lt;2)
#define WAIT_JOIN	(1&lt;&lt;3)
#define WAIT_PID	(1&lt;&lt;4)

/* +infty, for this purpose */
#define DELAY_INFTY 1E30

#if !defined HAVE_PAUSE
# if defined _WIN32 &amp;&amp; !defined __CYGWIN__
#  define pause() Sleep(INFINITE)
# else
#  define pause() sleep(0x7fffffff)
# endif
#endif

#define THREAD_RAISED 0x200	 /* temporary flag */
#define THREAD_TERMINATING 0x400 /* persistent flag */
#define THREAD_NO_ENSURE 0x800   /* persistent flag */
#define THREAD_FLAGS_MASK  0xc00 /* mask for persistent flags */

#define FOREACH_THREAD_FROM(f,x) x = f; do { x = x-&gt;next;
#define END_FOREACH_FROM(f,x) } while (x != f)

#define FOREACH_THREAD(x) FOREACH_THREAD_FROM(curr_thread,x)
#define END_FOREACH(x)    END_FOREACH_FROM(curr_thread,x)

struct thread_status_t {
    NODE *node;

    int tracing;
    VALUE errinfo;
    VALUE last_status;
    VALUE last_line;
    VALUE last_match;

    int safe;

    enum rb_thread_status status;
    int wait_for;
    int fd;
    fd_set readfds;
    fd_set writefds;
    fd_set exceptfds;
    int select_value;
    double delay;
    rb_thread_t join;
};

#define THREAD_COPY_STATUS(src, dst) (void)(	\
    (dst)-&gt;node = (src)-&gt;node,			\
						\
    (dst)-&gt;tracing = (src)-&gt;tracing,		\
    (dst)-&gt;errinfo = (src)-&gt;errinfo,		\
    (dst)-&gt;last_status = (src)-&gt;last_status,	\
    (dst)-&gt;last_line = (src)-&gt;last_line,	\
    (dst)-&gt;last_match = (src)-&gt;last_match,	\
						\
    (dst)-&gt;safe = (src)-&gt;safe,			\
						\
    (dst)-&gt;status = (src)-&gt;status,		\
    (dst)-&gt;wait_for = (src)-&gt;wait_for,		\
    (dst)-&gt;fd = (src)-&gt;fd,			\
    (dst)-&gt;readfds = (src)-&gt;readfds,		\
    (dst)-&gt;writefds = (src)-&gt;writefds,		\
    (dst)-&gt;exceptfds = (src)-&gt;exceptfds,	\
    (dst)-&gt;select_value = (src)-&gt;select_value,	\
    (dst)-&gt;delay = (src)-&gt;delay,		\
    (dst)-&gt;join = (src)-&gt;join,			\
    0)

static int
thread_set_raised()
{
    if (curr_thread-&gt;flags &amp; THREAD_RAISED) return 1;
    curr_thread-&gt;flags |= THREAD_RAISED;
    return 0;
}

static int
thread_reset_raised()
{
    if (!(curr_thread-&gt;flags &amp; THREAD_RAISED)) return 0;
    curr_thread-&gt;flags &amp;= ~THREAD_RAISED;
    return 1;
}

static int
thread_no_ensure()
{
    return ((curr_thread-&gt;flags &amp; THREAD_NO_ENSURE) == THREAD_NO_ENSURE);
}

static void rb_thread_ready _((rb_thread_t));

static VALUE run_trap_eval _((VALUE));
static VALUE
run_trap_eval(arg)
    VALUE arg;
{
    VALUE *p = (VALUE *)arg;
    return rb_eval_cmd(p[0], p[1], (int)p[2]);
}

static VALUE
rb_trap_eval(cmd, sig, safe)
    VALUE cmd;
    int sig, safe;
{
    int state;
    VALUE val = Qnil;		/* OK */
    volatile struct thread_status_t save;
    VALUE arg[3];

    arg[0] = cmd;
    arg[1] = rb_ary_new3(1, INT2FIX(sig));
    arg[2] = (VALUE)safe;
    THREAD_COPY_STATUS(curr_thread, &amp;save);
    rb_thread_ready(curr_thread);
    PUSH_ITER(ITER_NOT);
    val = rb_protect(run_trap_eval, (VALUE)&amp;arg, &amp;state);
    POP_ITER();
    THREAD_COPY_STATUS(&amp;save, curr_thread);

    if (state) {
	rb_trap_immediate = 0;
	rb_thread_ready(curr_thread);
	JUMP_TAG(state);
    }

    if (curr_thread-&gt;status == THREAD_STOPPED) {
	rb_thread_schedule();
    }
    errno = EINTR;

    return val;
}

static const char *
thread_status_name(status)
    enum rb_thread_status status;
{
    switch (status) {
      case THREAD_RUNNABLE:
	return &quot;run&quot;;
      case THREAD_STOPPED:
	return &quot;sleep&quot;;
      case THREAD_TO_KILL:
	return &quot;aborting&quot;;
      case THREAD_KILLED:
	return &quot;dead&quot;;
      default:
	return &quot;unknown&quot;;
    }
}

/* $SAFE accessor */
void
rb_set_safe_level(level)
    int level;
{
    if (level &gt; ruby_safe_level) {
	if (level &gt; SAFE_LEVEL_MAX) level = SAFE_LEVEL_MAX;
	ruby_safe_level = level;
	curr_thread-&gt;safe = level;
    }
}

static VALUE
safe_getter()
{
    return INT2NUM(ruby_safe_level);
}

static void
safe_setter(val)
    VALUE val;
{
    int level = NUM2INT(val);

    if (level &lt; ruby_safe_level) {
	rb_raise(rb_eSecurityError, &quot;tried to downgrade safe level from %d to %d&quot;,
		 ruby_safe_level, level);
    }
    if (level &gt; SAFE_LEVEL_MAX) level = SAFE_LEVEL_MAX;
    ruby_safe_level = level;
    curr_thread-&gt;safe = level;
}

/* Return the current time as a floating-point number */
static double
timeofday()
{
    struct timeval tv;
    gettimeofday(&amp;tv, NULL);
    return (double)tv.tv_sec + (double)tv.tv_usec * 1e-6;
}

#define STACK(addr) (th-&gt;stk_pos&lt;(VALUE*)(addr) &amp;&amp; (VALUE*)(addr)&lt;th-&gt;stk_pos+th-&gt;stk_len)
#define ADJ(addr) (void*)(STACK(addr)?(((VALUE*)(addr)-th-&gt;stk_pos)+th-&gt;stk_ptr):(VALUE*)(addr))
static void
thread_mark(th)
    rb_thread_t th;
{
    struct FRAME *frame;
    struct BLOCK *block;

    rb_gc_mark(th-&gt;result);
    rb_gc_mark(th-&gt;thread);
    if (th-&gt;join) rb_gc_mark(th-&gt;join-&gt;thread);

    rb_gc_mark(th-&gt;klass);
    rb_gc_mark(th-&gt;wrapper);
    rb_gc_mark((VALUE)th-&gt;cref);

    rb_gc_mark((VALUE)th-&gt;scope);
    rb_gc_mark((VALUE)th-&gt;dyna_vars);
    rb_gc_mark(th-&gt;errinfo);
    rb_gc_mark(th-&gt;last_status);
    rb_gc_mark(th-&gt;last_line);
    rb_gc_mark(th-&gt;last_match);
    rb_mark_tbl(th-&gt;locals);
    rb_gc_mark(th-&gt;thgroup);
    rb_gc_mark_maybe(th-&gt;sandbox);

    /* mark data in copied stack */
    if (th == curr_thread) return;
    if (th-&gt;status == THREAD_KILLED) return;
    if (th-&gt;stk_len == 0) return;  /* stack not active, no need to mark. */
    if (th-&gt;stk_ptr) {
	rb_gc_mark_locations(th-&gt;stk_ptr, th-&gt;stk_ptr+th-&gt;stk_len);
#if defined(THINK_C) || defined(__human68k__)
	rb_gc_mark_locations(th-&gt;stk_ptr+2, th-&gt;stk_ptr+th-&gt;stk_len+2);
#endif
#ifdef __ia64
	if (th-&gt;bstr_ptr) {
            rb_gc_mark_locations(th-&gt;bstr_ptr, th-&gt;bstr_ptr+th-&gt;bstr_len);
	}
#endif
    }
    frame = th-&gt;frame;
    while (frame &amp;&amp; frame != top_frame) {
	frame = ADJ(frame);
	rb_gc_mark_frame(frame);
	if (frame-&gt;tmp) {
	    struct FRAME *tmp = frame-&gt;tmp;

	    while (tmp &amp;&amp; tmp != top_frame) {
		tmp = ADJ(tmp);
		rb_gc_mark_frame(tmp);
		tmp = tmp-&gt;prev;
	    }
	}
	frame = frame-&gt;prev;
    }
    block = th-&gt;block;
    while (block) {
	block = ADJ(block);
	rb_gc_mark_frame(&amp;block-&gt;frame);
	block = block-&gt;prev;
    }
}

static int
mark_loading_thread(key, value, lev)
    ID key;
    VALUE value;
    int lev;
{
    rb_gc_mark(((rb_thread_t)value)-&gt;thread);
    return ST_CONTINUE;
}

void
rb_gc_mark_threads()
{
    rb_thread_t th;

    /* static global mark */
    rb_gc_mark((VALUE)ruby_cref);

    if (!curr_thread) return;
    rb_gc_mark(main_thread-&gt;thread);
    rb_gc_mark(curr_thread-&gt;thread);
    FOREACH_THREAD_FROM(main_thread, th) {
	switch (th-&gt;status) {
	  case THREAD_TO_KILL:
	  case THREAD_RUNNABLE:
	    break;
	  case THREAD_STOPPED:
	    if (th-&gt;wait_for) break;
	  default:
	    continue;
	}
	rb_gc_mark(th-&gt;thread);
    } END_FOREACH_FROM(main_thread, th);
    if (loading_tbl) st_foreach(loading_tbl, mark_loading_thread, 0);
}

void
rb_gc_abort_threads()
{
    rb_thread_t th;

    if (!main_thread)
        return;

    FOREACH_THREAD_FROM(main_thread, th) {
	if (FL_TEST(th-&gt;thread, FL_MARK)) continue;
	if (th-&gt;status == THREAD_STOPPED) {
	    th-&gt;status = THREAD_TO_KILL;
	    rb_gc_mark(th-&gt;thread);
	}
    } END_FOREACH_FROM(main_thread, th);
}

static void
thread_free(th)
    rb_thread_t th;
{
    if (th-&gt;stk_ptr) free(th-&gt;stk_ptr);
    th-&gt;stk_ptr = 0;
#ifdef __ia64
    if (th-&gt;bstr_ptr) free(th-&gt;bstr_ptr);
    th-&gt;bstr_ptr = 0;
#endif
    if (th-&gt;locals) st_free_table(th-&gt;locals);
    if (th-&gt;status != THREAD_KILLED) {
	if (th-&gt;prev) th-&gt;prev-&gt;next = th-&gt;next;
	if (th-&gt;next) th-&gt;next-&gt;prev = th-&gt;prev;
    }
    if (th != main_thread) free(th);
}

static rb_thread_t
rb_thread_check(data)
    VALUE data;
{
    if (TYPE(data) != T_DATA || RDATA(data)-&gt;dmark != (RUBY_DATA_FUNC)thread_mark) {
	rb_raise(rb_eTypeError, &quot;wrong argument type %s (expected Thread)&quot;,
		 rb_obj_classname(data));
    }
    return (rb_thread_t)RDATA(data)-&gt;data;
}

static VALUE rb_thread_raise _((int, VALUE*, rb_thread_t));

static VALUE th_raise_exception;
static NODE *th_raise_node;
static VALUE th_cmd;
static int   th_sig, th_safe;

#define RESTORE_NORMAL		1
#define RESTORE_FATAL		2
#define RESTORE_INTERRUPT	3
#define RESTORE_TRAP		4
#define RESTORE_RAISE		5
#define RESTORE_SIGNAL		6
#define RESTORE_EXIT		7

extern VALUE *rb_gc_stack_start;
#ifdef __ia64
extern VALUE *rb_gc_register_stack_start;
#endif

static void
rb_thread_save_context(th)
    rb_thread_t th;
{
    VALUE *pos;
    int len;
    static VALUE tval;

    len = ruby_stack_length(&amp;pos);
    th-&gt;stk_len = 0;
    th-&gt;stk_pos = pos;
    if (len &gt; th-&gt;stk_max) {
	VALUE *ptr = realloc(th-&gt;stk_ptr, sizeof(VALUE) * len);
	if (!ptr) rb_memerror();
	th-&gt;stk_ptr = ptr;
	th-&gt;stk_max = len;
    }
    th-&gt;stk_len = len;
    FLUSH_REGISTER_WINDOWS;
    MEMCPY(th-&gt;stk_ptr, th-&gt;stk_pos, VALUE, th-&gt;stk_len);
#ifdef __ia64
    th-&gt;bstr_pos = rb_gc_register_stack_start;
    len = (VALUE*)rb_ia64_bsp() - th-&gt;bstr_pos;
    th-&gt;bstr_len = 0;
    if (len &gt; th-&gt;bstr_max) {
        VALUE *ptr = realloc(th-&gt;bstr_ptr, sizeof(VALUE) * len);
        if (!ptr) rb_memerror();
        th-&gt;bstr_ptr = ptr;
        th-&gt;bstr_max = len;
    }
    th-&gt;bstr_len = len;
    rb_ia64_flushrs();
    MEMCPY(th-&gt;bstr_ptr, th-&gt;bstr_pos, VALUE, th-&gt;bstr_len);
#endif
#ifdef SAVE_WIN32_EXCEPTION_LIST
    th-&gt;win32_exception_list = win32_get_exception_list();
#endif

    th-&gt;frame = ruby_frame;
    th-&gt;scope = ruby_scope;
    ruby_scope-&gt;flags |= SCOPE_DONT_RECYCLE;
    th-&gt;klass = ruby_class;
    th-&gt;wrapper = ruby_wrapper;
    th-&gt;cref = ruby_cref;
    th-&gt;dyna_vars = ruby_dyna_vars;
    th-&gt;block = ruby_block;
    th-&gt;flags &amp;= THREAD_FLAGS_MASK;
    th-&gt;flags |= (rb_trap_immediate&lt;&lt;8) | scope_vmode;
    th-&gt;iter = ruby_iter;
    th-&gt;tag = prot_tag;
    th-&gt;tracing = tracing;
    th-&gt;errinfo = ruby_errinfo;
    th-&gt;last_status = rb_last_status;
    tval = rb_lastline_get();
    rb_lastline_set(th-&gt;last_line);
    th-&gt;last_line = tval;
    tval = rb_backref_get();
    rb_backref_set(th-&gt;last_match);
    th-&gt;last_match = tval;
    th-&gt;safe = ruby_safe_level;

    th-&gt;node = ruby_current_node;
    if (ruby_sandbox_save != NULL)
    {
      ruby_sandbox_save(th);
    }
}

static int
rb_thread_switch(n)
    int n;
{
    rb_trap_immediate = (curr_thread-&gt;flags&amp;0x100)?1:0;
    switch (n) {
      case 0:
	return 0;
      case RESTORE_FATAL:
	JUMP_TAG(TAG_FATAL);
	break;
      case RESTORE_INTERRUPT:
	rb_interrupt();
	break;
      case RESTORE_TRAP:
	rb_trap_eval(th_cmd, th_sig, th_safe);
	break;
      case RESTORE_RAISE:
	ruby_frame-&gt;last_func = 0;
	ruby_current_node = th_raise_node;
	rb_raise_jump(th_raise_exception);
	break;
      case RESTORE_SIGNAL:
	rb_thread_signal_raise(th_sig);
	break;
      case RESTORE_EXIT:
	ruby_errinfo = th_raise_exception;
	ruby_current_node = th_raise_node;
	if (!rb_obj_is_kind_of(ruby_errinfo, rb_eSystemExit)) {
	    terminate_process(EXIT_FAILURE, ruby_errinfo);
	}
	rb_exc_raise(th_raise_exception);
	break;
      case RESTORE_NORMAL:
      default:
	break;
    }
    return 1;
}

#define THREAD_SAVE_CONTEXT(th) \
    (rb_thread_switch(ruby_setjmp(rb_thread_save_context(th), (th)-&gt;context)))

NORETURN(static void rb_thread_restore_context _((rb_thread_t,int)));
NORETURN(NOINLINE(static void rb_thread_restore_context_0(rb_thread_t,int,void*)));
NORETURN(NOINLINE(static void stack_extend(rb_thread_t, int, VALUE *)));

static void
rb_thread_restore_context_0(rb_thread_t th, int exit, void *vp)
{
    static rb_thread_t tmp;
    static int ex;
    static VALUE tval;

    rb_trap_immediate = 0;	/* inhibit interrupts from here */
    if (ruby_sandbox_restore != NULL)
    {
      ruby_sandbox_restore(th);
    }
    ruby_frame = th-&gt;frame;
    ruby_scope = th-&gt;scope;
    ruby_class = th-&gt;klass;
    ruby_wrapper = th-&gt;wrapper;
    ruby_cref = th-&gt;cref;
    ruby_dyna_vars = th-&gt;dyna_vars;
    ruby_block = th-&gt;block;
    scope_vmode = th-&gt;flags&amp;SCOPE_MASK;
    ruby_iter = th-&gt;iter;
    prot_tag = th-&gt;tag;
    tracing = th-&gt;tracing;
    ruby_errinfo = th-&gt;errinfo;
    rb_last_status = th-&gt;last_status;
    ruby_safe_level = th-&gt;safe;

    ruby_current_node = th-&gt;node;

#ifdef SAVE_WIN32_EXCEPTION_LIST
    win32_set_exception_list(th-&gt;win32_exception_list);
#endif
    tmp = th;
    ex = exit;
    FLUSH_REGISTER_WINDOWS;
    MEMCPY(tmp-&gt;stk_pos, tmp-&gt;stk_ptr, VALUE, tmp-&gt;stk_len);
#ifdef __ia64
    MEMCPY(tmp-&gt;bstr_pos, tmp-&gt;bstr_ptr, VALUE, tmp-&gt;bstr_len);
#endif

    tval = rb_lastline_get();
    rb_lastline_set(tmp-&gt;last_line);
    tmp-&gt;last_line = tval;
    tval = rb_backref_get();
    rb_backref_set(tmp-&gt;last_match);
    tmp-&gt;last_match = tval;

    ruby_longjmp(tmp-&gt;context, ex);
}

#ifdef __ia64
#define C(a) rse_##a##0, rse_##a##1, rse_##a##2, rse_##a##3, rse_##a##4
#define E(a) rse_##a##0= rse_##a##1= rse_##a##2= rse_##a##3= rse_##a##4
static volatile int C(a), C(b), C(c), C(d), C(e);
static volatile int C(f), C(g), C(h), C(i), C(j);
static volatile int C(k), C(l), C(m), C(n), C(o);
static volatile int C(p), C(q), C(r), C(s), C(t);
int rb_dummy_false = 0;
NORETURN(NOINLINE(static void register_stack_extend(rb_thread_t, int, void *, VALUE *)));
static void
register_stack_extend(rb_thread_t th, int exit, void *vp, VALUE *curr_bsp)
{
    if (rb_dummy_false) {
        /* use registers as much as possible */
        E(a) = E(b) = E(c) = E(d) = E(e) =
        E(f) = E(g) = E(h) = E(i) = E(j) =
        E(k) = E(l) = E(m) = E(n) = E(o) =
        E(p) = E(q) = E(r) = E(s) = E(t) = 0;
        E(a) = E(b) = E(c) = E(d) = E(e) =
        E(f) = E(g) = E(h) = E(i) = E(j) =
        E(k) = E(l) = E(m) = E(n) = E(o) =
        E(p) = E(q) = E(r) = E(s) = E(t) = 0;
    }
    if (curr_bsp &lt; th-&gt;bstr_pos+th-&gt;bstr_len) {
        register_stack_extend(th, exit, &amp;exit, (VALUE*)rb_ia64_bsp());
    }
    rb_thread_restore_context_0(th, exit, &amp;exit);
}
#undef C
#undef E
#endif

# if defined(_MSC_VER) &amp;&amp; _MSC_VER &gt;= 1300
__declspec(noinline) static void stack_extend(rb_thread_t, int, VALUE*);
# endif
static void
stack_extend(rb_thread_t th, int exit, VALUE *addr_in_prev_frame)
{
#define STACK_PAD_SIZE 1024
    VALUE space[STACK_PAD_SIZE];

#if STACK_GROW_DIRECTION &lt; 0
    if (addr_in_prev_frame &gt; th-&gt;stk_pos) stack_extend(th, exit, &amp;space[0]);
#elif STACK_GROW_DIRECTION &gt; 0
    if (addr_in_prev_frame &lt; th-&gt;stk_pos + th-&gt;stk_len) stack_extend(th, exit, &amp;space[STACK_PAD_SIZE-1]);
#else
    if (addr_in_prev_frame &lt; rb_gc_stack_start) {
        /* Stack grows downward */
        if (addr_in_prev_frame &gt; th-&gt;stk_pos) stack_extend(th, exit, &amp;space[0]);
    }
    else {
        /* Stack grows upward */
        if (addr_in_prev_frame &lt; th-&gt;stk_pos + th-&gt;stk_len) stack_extend(th, exit, &amp;space[STACK_PAD_SIZE-1]);
    }
#endif
#ifdef __ia64
    register_stack_extend(th, exit, space, (VALUE*)rb_ia64_bsp());
#else
    rb_thread_restore_context_0(th, exit, space);
#endif
}

static void
rb_thread_restore_context(th, exit)
    rb_thread_t th;
    int exit;
{
    VALUE v;
    if (!th-&gt;stk_ptr) rb_bug(&quot;unsaved context&quot;);
    stack_extend(th, exit, &amp;v);
}

static void
rb_thread_ready(th)
    rb_thread_t th;
{
    th-&gt;wait_for = 0;
    if (th-&gt;status != THREAD_TO_KILL) {
	th-&gt;status = THREAD_RUNNABLE;
    }
}

static void
rb_thread_die(th)
    rb_thread_t th;
{
    th-&gt;thgroup = 0;
    th-&gt;status = THREAD_KILLED;
    if (th-&gt;stk_ptr) free(th-&gt;stk_ptr);
    th-&gt;stk_ptr = 0;
}

static void
rb_thread_remove(th)
    rb_thread_t th;
{
    if (th-&gt;status == THREAD_KILLED) return;

    rb_thread_ready(th);
    rb_thread_die(th);
    th-&gt;prev-&gt;next = th-&gt;next;
    th-&gt;next-&gt;prev = th-&gt;prev;
}

static int
rb_thread_dead(th)
    rb_thread_t th;
{
    return th-&gt;status == THREAD_KILLED;
}

void
rb_thread_fd_close(fd)
    int fd;
{
    rb_thread_t th;

    FOREACH_THREAD(th) {
	if (((th-&gt;wait_for &amp; WAIT_FD) &amp;&amp; fd == th-&gt;fd) ||
	    ((th-&gt;wait_for &amp; WAIT_SELECT) &amp;&amp; (fd &lt; th-&gt;fd) &amp;&amp;
	     (FD_ISSET(fd, &amp;th-&gt;readfds) ||
	      FD_ISSET(fd, &amp;th-&gt;writefds) ||
	      FD_ISSET(fd, &amp;th-&gt;exceptfds)))) {
	    VALUE exc = rb_exc_new2(rb_eIOError, &quot;stream closed&quot;);
	    rb_thread_raise(1, &amp;exc, th);
	}
    }
    END_FOREACH(th);
}

NORETURN(static void rb_thread_main_jump _((VALUE, int)));
static void
rb_thread_main_jump(err, tag)
    VALUE err;
    int tag;
{
    curr_thread = main_thread;
    th_raise_exception = err;
    th_raise_node = ruby_current_node;
    rb_thread_restore_context(main_thread, tag);
}

NORETURN(static void rb_thread_deadlock _((void)));
static void
rb_thread_deadlock()
{
    char msg[21+SIZEOF_LONG*2];
    VALUE e;

    sprintf(msg, &quot;Thread(0x%lx): deadlock&quot;, curr_thread-&gt;thread);
    e = rb_exc_new2(rb_eFatal, msg);
    if (curr_thread == main_thread) {
	rb_exc_raise(e);
    }
    rb_thread_main_jump(e, RESTORE_RAISE);
}

static void
copy_fds(dst, src, max)
    fd_set *dst, *src;
    int max;
{
    int n = 0;
    int i;

    for (i=0; i&lt;=max; i++) {
	if (FD_ISSET(i, src)) {
	    n = i;
	    FD_SET(i, dst);
	}
    }
}

static int
match_fds(dst, src, max)
    fd_set *dst, *src;
    int max;
{
    int i;

    for (i=0; i&lt;=max; i++) {
	if (FD_ISSET(i, src) &amp;&amp; FD_ISSET(i, dst)) {
	    return Qtrue;
	}
    }
    return Qfalse;
}

static int
intersect_fds(src, dst, max)
    fd_set *src, *dst;
    int max;
{
    int i, n = 0;

    for (i=0; i&lt;=max; i++) {
	if (FD_ISSET(i, dst)) {
	    if (FD_ISSET(i, src)) {
		/* Wake up only one thread per fd. */
		FD_CLR(i, src);
		n++;
	    }
	    else {
		FD_CLR(i, dst);
	    }
	}
    }
    return n;
}

static int
find_bad_fds(dst, src, max)
    fd_set *dst, *src;
    int max;
{
    int i, test = Qfalse;

    for (i=0; i&lt;=max; i++) {
	if (FD_ISSET(i, src) &amp;&amp; !FD_ISSET(i, dst)) {
	    FD_CLR(i, src);
	    test = Qtrue;
	}
    }
    return test;
}

void
rb_thread_schedule()
{
    rb_thread_t next;		/* OK */
    rb_thread_t th;
    rb_thread_t curr;
    int found = 0;

    fd_set readfds;
    fd_set writefds;
    fd_set exceptfds;
    struct timeval delay_tv, *delay_ptr;
    double delay, now;	/* OK */
    int n, max;
    int need_select = 0;
    int select_timeout = 0;

#ifdef HAVE_NATIVETHREAD
    if (!is_ruby_native_thread()) {
	rb_bug(&quot;cross-thread violation on rb_thread_schedule()&quot;);
    }
#endif
    rb_thread_pending = 0;
    if (curr_thread == curr_thread-&gt;next
	&amp;&amp; curr_thread-&gt;status == THREAD_RUNNABLE)
	return;

    next = 0;
    curr = curr_thread;		/* starting thread */

    while (curr-&gt;status == THREAD_KILLED) {
	curr = curr-&gt;prev;
    }

  again:
    max = -1;
    FD_ZERO(&amp;readfds);
    FD_ZERO(&amp;writefds);
    FD_ZERO(&amp;exceptfds);
    delay = DELAY_INFTY;
    now = -1.0;

    FOREACH_THREAD_FROM(curr, th) {
	if (!found &amp;&amp; th-&gt;status &lt;= THREAD_RUNNABLE) {
	    found = 1;
	}
	if (th-&gt;status != THREAD_STOPPED) continue;
	if (th-&gt;wait_for &amp; WAIT_JOIN) {
	    if (rb_thread_dead(th-&gt;join)) {
		th-&gt;status = THREAD_RUNNABLE;
		found = 1;
	    }
	}
	if (th-&gt;wait_for &amp; WAIT_FD) {
	    FD_SET(th-&gt;fd, &amp;readfds);
	    if (max &lt; th-&gt;fd) max = th-&gt;fd;
	    need_select = 1;
	}
	if (th-&gt;wait_for &amp; WAIT_SELECT) {
	    copy_fds(&amp;readfds, &amp;th-&gt;readfds, th-&gt;fd);
	    copy_fds(&amp;writefds, &amp;th-&gt;writefds, th-&gt;fd);
	    copy_fds(&amp;exceptfds, &amp;th-&gt;exceptfds, th-&gt;fd);
	    if (max &lt; th-&gt;fd) max = th-&gt;fd;
	    need_select = 1;
	    if (th-&gt;wait_for &amp; WAIT_TIME) {
		select_timeout = 1;
	    }
	    th-&gt;select_value = 0;
	}
	if (th-&gt;wait_for &amp; WAIT_TIME) {
	    double th_delay;

	    if (now &lt; 0.0) now = timeofday();
	    th_delay = th-&gt;delay - now;
	    if (th_delay &lt;= 0.0) {
		th-&gt;status = THREAD_RUNNABLE;
		found = 1;
	    }
	    else if (th_delay &lt; delay) {
		delay = th_delay;
		need_select = 1;
	    }
	    else if (th-&gt;delay == DELAY_INFTY) {
		need_select = 1;
	    }
	}
    }
    END_FOREACH_FROM(curr, th);

    /* Do the select if needed */
    if (need_select) {
	/* Convert delay to a timeval */
	/* If a thread is runnable, just poll */
	if (found) {
	    delay_tv.tv_sec = 0;
	    delay_tv.tv_usec = 0;
	    delay_ptr = &amp;delay_tv;
	}
	else if (delay == DELAY_INFTY) {
	    delay_ptr = 0;
	}
	else {
	    delay_tv.tv_sec = delay;
	    delay_tv.tv_usec = (delay - (double)delay_tv.tv_sec)*1e6;
	    delay_ptr = &amp;delay_tv;
	}

	n = select(max+1, &amp;readfds, &amp;writefds, &amp;exceptfds, delay_ptr);
	if (n &lt; 0) {
	    int e = errno;

	    if (rb_trap_pending) rb_trap_exec();
	    if (e == EINTR) goto again;
#ifdef ERESTART
	    if (e == ERESTART) goto again;
#endif
	    FOREACH_THREAD_FROM(curr, th) {
		if (th-&gt;wait_for &amp; WAIT_SELECT) {
		    int v = 0;

		    v |= find_bad_fds(&amp;readfds, &amp;th-&gt;readfds, th-&gt;fd);
		    v |= find_bad_fds(&amp;writefds, &amp;th-&gt;writefds, th-&gt;fd);
		    v |= find_bad_fds(&amp;exceptfds, &amp;th-&gt;exceptfds, th-&gt;fd);
		    if (v) {
			th-&gt;select_value = n;
			n = max;
		    }
		}
	    }
	    END_FOREACH_FROM(curr, th);
	}
 	if (select_timeout &amp;&amp; n == 0) {
 	    if (now &lt; 0.0) now = timeofday();
 	    FOREACH_THREAD_FROM(curr, th) {
 		if (((th-&gt;wait_for&amp;(WAIT_SELECT|WAIT_TIME)) == (WAIT_SELECT|WAIT_TIME)) &amp;&amp;
		    th-&gt;delay &lt;= now) {
 		    th-&gt;status = THREAD_RUNNABLE;
 		    th-&gt;wait_for = 0;
 		    th-&gt;select_value = 0;
 		    found = 1;
		    intersect_fds(&amp;readfds, &amp;th-&gt;readfds, max);
		    intersect_fds(&amp;writefds, &amp;th-&gt;writefds, max);
		    intersect_fds(&amp;exceptfds, &amp;th-&gt;exceptfds, max);
		}
	    }
	    END_FOREACH_FROM(curr, th);
	}
	if (n &gt; 0) {
	    now = -1.0;
	    /* Some descriptors are ready.
	       Make the corresponding threads runnable. */
	    FOREACH_THREAD_FROM(curr, th) {
		if ((th-&gt;wait_for&amp;WAIT_FD) &amp;&amp; FD_ISSET(th-&gt;fd, &amp;readfds)) {
		    /* Wake up only one thread per fd. */
		    FD_CLR(th-&gt;fd, &amp;readfds);
		    th-&gt;status = THREAD_RUNNABLE;
		    th-&gt;fd = 0;
		    th-&gt;wait_for = 0;
		    found = 1;
		}
		if ((th-&gt;wait_for&amp;WAIT_SELECT) &amp;&amp;
		    (match_fds(&amp;readfds, &amp;th-&gt;readfds, max) ||
		     match_fds(&amp;writefds, &amp;th-&gt;writefds, max) ||
		     match_fds(&amp;exceptfds, &amp;th-&gt;exceptfds, max))) {
		    /* Wake up only one thread per fd. */
		    th-&gt;status = THREAD_RUNNABLE;
		    th-&gt;wait_for = 0;
		    n = intersect_fds(&amp;readfds, &amp;th-&gt;readfds, max) +
			intersect_fds(&amp;writefds, &amp;th-&gt;writefds, max) +
			intersect_fds(&amp;exceptfds, &amp;th-&gt;exceptfds, max);
		    th-&gt;select_value = n;
		    found = 1;
		}
	    }
	    END_FOREACH_FROM(curr, th);
	}
	/* The delays for some of the threads should have expired.
	   Go through the loop once more, to check the delays. */
	if (!found &amp;&amp; delay != DELAY_INFTY)
	    goto again;
    }

    FOREACH_THREAD_FROM(curr, th) {
	if (th-&gt;status == THREAD_TO_KILL) {
	    next = th;
	    break;
	}
	if (th-&gt;status == THREAD_RUNNABLE &amp;&amp; th-&gt;stk_ptr) {
	    if (!next || next-&gt;priority &lt; th-&gt;priority)
	       next = th;
	}
    }
    END_FOREACH_FROM(curr, th);

    if (!next) {
	/* raise fatal error to main thread */
	curr_thread-&gt;node = ruby_current_node;
	if (curr-&gt;next == curr) {
	    TRAP_BEG;
	    pause();
	    TRAP_END;
	}
	FOREACH_THREAD_FROM(curr, th) {
	    warn_printf(&quot;deadlock 0x%lx: %s:&quot;,
			th-&gt;thread, thread_status_name(th-&gt;status));
	    if (th-&gt;wait_for &amp; WAIT_FD) warn_printf(&quot;F(%d)&quot;, th-&gt;fd);
	    if (th-&gt;wait_for &amp; WAIT_SELECT) warn_printf(&quot;S&quot;);
	    if (th-&gt;wait_for &amp; WAIT_TIME) warn_printf(&quot;T(%f)&quot;, th-&gt;delay);
	    if (th-&gt;wait_for &amp; WAIT_JOIN)
		warn_printf(&quot;J(0x%lx)&quot;, th-&gt;join ? th-&gt;join-&gt;thread : 0);
	    if (th-&gt;wait_for &amp; WAIT_PID) warn_printf(&quot;P&quot;);
	    if (!th-&gt;wait_for) warn_printf(&quot;-&quot;);
	    warn_printf(&quot; %s - %s:%d\n&quot;,
			th==main_thread ? &quot;(main)&quot; : &quot;&quot;,
			th-&gt;node-&gt;nd_file, nd_line(th-&gt;node));
	}
	END_FOREACH_FROM(curr, th);
	next = main_thread;
	rb_thread_ready(next);
	next-&gt;status = THREAD_TO_KILL;
	if (!rb_thread_dead(curr_thread)) {
	    rb_thread_save_context(curr_thread);
	}
	rb_thread_deadlock();
    }
    next-&gt;wait_for = 0;
    if (next-&gt;status == THREAD_RUNNABLE &amp;&amp; next == curr_thread) {
	return;
    }

    /* context switch */
    if (curr == curr_thread) {
	if (THREAD_SAVE_CONTEXT(curr)) {
	    return;
	}
    }

    curr_thread = next;
    if (next-&gt;status == THREAD_TO_KILL) {
	if (!(next-&gt;flags &amp; THREAD_TERMINATING)) {
	    next-&gt;flags |= THREAD_TERMINATING;
	    /* terminate; execute ensure-clause if any */
	    rb_thread_restore_context(next, RESTORE_FATAL);
	}
    }
    rb_thread_restore_context(next, RESTORE_NORMAL);
}

void
rb_thread_wait_fd(fd)
    int fd;
{
    if (rb_thread_critical) return;
    if (ruby_in_compile) return;
    if (curr_thread == curr_thread-&gt;next) return;
    if (curr_thread-&gt;status == THREAD_TO_KILL) return;

    curr_thread-&gt;status = THREAD_STOPPED;
    curr_thread-&gt;fd = fd;
    curr_thread-&gt;wait_for = WAIT_FD;
    rb_thread_schedule();
}

int
rb_thread_fd_writable(fd)
    int fd;
{
    if (rb_thread_critical) return Qtrue;
    if (curr_thread == curr_thread-&gt;next) return Qtrue;
    if (curr_thread-&gt;status == THREAD_TO_KILL) return Qtrue;
    if (curr_thread-&gt;status == THREAD_KILLED) return Qtrue;

    curr_thread-&gt;status = THREAD_STOPPED;
    FD_ZERO(&amp;curr_thread-&gt;readfds);
    FD_ZERO(&amp;curr_thread-&gt;writefds);
    FD_SET(fd, &amp;curr_thread-&gt;writefds);
    FD_ZERO(&amp;curr_thread-&gt;exceptfds);
    curr_thread-&gt;fd = fd+1;
    curr_thread-&gt;wait_for = WAIT_SELECT;
    rb_thread_schedule();
    return Qfalse;
}

void
rb_thread_wait_for(time)
    struct timeval time;
{
    double date;

    if (rb_thread_critical ||
	curr_thread == curr_thread-&gt;next ||
	curr_thread-&gt;status == THREAD_TO_KILL) {
	int n;
	int thr_critical = rb_thread_critical;
#ifndef linux
	double d, limit;
	limit = timeofday()+(double)time.tv_sec+(double)time.tv_usec*1e-6;
#endif
	for (;;) {
	    rb_thread_critical = Qtrue;
	    TRAP_BEG;
	    n = select(0, 0, 0, 0, &amp;time);
	    rb_thread_critical = thr_critical;
	    TRAP_END;
	    if (n == 0) return;
	    if (n &lt; 0) {
		switch (errno) {
		  case EINTR:
#ifdef ERESTART
		  case ERESTART:
#endif
		    break;
		  default:
		    rb_sys_fail(&quot;sleep&quot;);
		}
	    }
#ifndef linux
	    d = limit - timeofday();

	    time.tv_sec = (int)d;
	    time.tv_usec = (int)((d - (int)d)*1e6);
	    if (time.tv_usec &lt; 0) {
		time.tv_usec += (long)1e6;
		time.tv_sec -= 1;
	    }
	    if (time.tv_sec &lt; 0) return;
#endif
	}
    }

    date = timeofday() + (double)time.tv_sec + (double)time.tv_usec*1e-6;
    curr_thread-&gt;status = THREAD_STOPPED;
    curr_thread-&gt;delay = date;
    curr_thread-&gt;wait_for = WAIT_TIME;
    rb_thread_schedule();
}

void rb_thread_sleep_forever _((void));

int
rb_thread_alone()
{
    return curr_thread == curr_thread-&gt;next;
}

int
rb_thread_select(max, read, write, except, timeout)
    int max;
    fd_set *read, *write, *except;
    struct timeval *timeout;
{
#ifndef linux
    double limit;
#endif
    int n;

    if (!read &amp;&amp; !write &amp;&amp; !except) {
	if (!timeout) {
	    rb_thread_sleep_forever();
	    return 0;
	}
	rb_thread_wait_for(*timeout);
	return 0;
    }

#ifndef linux
    if (timeout) {
	limit = timeofday()+
	    (double)timeout-&gt;tv_sec+(double)timeout-&gt;tv_usec*1e-6;
    }
#endif

    if (rb_thread_critical ||
	curr_thread == curr_thread-&gt;next ||
	curr_thread-&gt;status == THREAD_TO_KILL) {
#ifndef linux
	struct timeval tv, *tvp = timeout;

	if (timeout) {
	    tv = *timeout;
	    tvp = &amp;tv;
	}
#else
	struct timeval *const tvp = timeout;
#endif
	for (;;) {
	    TRAP_BEG;
	    n = select(max, read, write, except, tvp);
	    TRAP_END;
	    if (n &lt; 0) {
		switch (errno) {
		  case EINTR:
#ifdef ERESTART
		  case ERESTART:
#endif
#ifndef linux
		    if (timeout) {
			double d = limit - timeofday();

			tv.tv_sec = (unsigned int)d;
			tv.tv_usec = (long)((d-(double)tv.tv_sec)*1e6);
			if (tv.tv_sec &lt; 0)  tv.tv_sec = 0;
			if (tv.tv_usec &lt; 0) tv.tv_usec = 0;
		    }
#endif
		    continue;
		  default:
		    break;
		}
	    }
	    return n;
	}
    }

    curr_thread-&gt;status = THREAD_STOPPED;
    if (read) curr_thread-&gt;readfds = *read;
    else FD_ZERO(&amp;curr_thread-&gt;readfds);
    if (write) curr_thread-&gt;writefds = *write;
    else FD_ZERO(&amp;curr_thread-&gt;writefds);
    if (except) curr_thread-&gt;exceptfds = *except;
    else FD_ZERO(&amp;curr_thread-&gt;exceptfds);
    curr_thread-&gt;fd = max;
    curr_thread-&gt;wait_for = WAIT_SELECT;
    if (timeout) {
	curr_thread-&gt;delay = timeofday() +
	    (double)timeout-&gt;tv_sec + (double)timeout-&gt;tv_usec*1e-6;
	curr_thread-&gt;wait_for |= WAIT_TIME;
    }
    rb_thread_schedule();
    if (read) *read = curr_thread-&gt;readfds;
    if (write) *write = curr_thread-&gt;writefds;
    if (except) *except = curr_thread-&gt;exceptfds;
    return curr_thread-&gt;select_value;
}

static int rb_thread_join _((rb_thread_t, double));

static int
rb_thread_join(th, limit)
    rb_thread_t th;
    double limit;
{
    enum rb_thread_status last_status = THREAD_RUNNABLE;

    if (rb_thread_critical) rb_thread_deadlock();
    if (!rb_thread_dead(th)) {
	if (th == curr_thread)
	    rb_raise(rb_eThreadError, &quot;thread 0x%lx tried to join itself&quot;,
		     th-&gt;thread);
	if ((th-&gt;wait_for &amp; WAIT_JOIN) &amp;&amp; th-&gt;join == curr_thread)
	    rb_raise(rb_eThreadError, &quot;Thread#join: deadlock 0x%lx - mutual join(0x%lx)&quot;,
		     curr_thread-&gt;thread, th-&gt;thread);
	if (curr_thread-&gt;status == THREAD_TO_KILL)
	    last_status = THREAD_TO_KILL;
	if (limit == 0) return Qfalse;
	curr_thread-&gt;status = THREAD_STOPPED;
	curr_thread-&gt;join = th;
	curr_thread-&gt;wait_for = WAIT_JOIN;
	curr_thread-&gt;delay = timeofday() + limit;
	if (limit &lt; DELAY_INFTY) curr_thread-&gt;wait_for |= WAIT_TIME;
	rb_thread_schedule();
	curr_thread-&gt;status = last_status;
	if (!rb_thread_dead(th)) return Qfalse;
    }

    if (!NIL_P(th-&gt;errinfo) &amp;&amp; (th-&gt;flags &amp; THREAD_RAISED)) {
	VALUE oldbt = get_backtrace(th-&gt;errinfo);
	VALUE errat = make_backtrace();
	VALUE errinfo = rb_obj_dup(th-&gt;errinfo);

	if (TYPE(oldbt) == T_ARRAY &amp;&amp; RARRAY(oldbt)-&gt;len &gt; 0) {
	    rb_ary_unshift(errat, rb_ary_entry(oldbt, 0));
	}
	set_backtrace(errinfo, errat);
	rb_exc_raise(errinfo);
    }

    return Qtrue;
}


/*
 *  call-seq:
 *     thr.join          =&gt; thr
 *     thr.join(limit)   =&gt; thr
 *  
 *  The calling thread will suspend execution and run &lt;i&gt;thr&lt;/i&gt;. Does not
 *  return until &lt;i&gt;thr&lt;/i&gt; exits or until &lt;i&gt;limit&lt;/i&gt; seconds have passed. If
 *  the time limit expires, &lt;code&gt;nil&lt;/code&gt; will be returned, otherwise
 *  &lt;i&gt;thr&lt;/i&gt; is returned.
 *     
 *  Any threads not joined will be killed when the main program exits.  If
 *  &lt;i&gt;thr&lt;/i&gt; had previously raised an exception and the
 *  &lt;code&gt;abort_on_exception&lt;/code&gt; and &lt;code&gt;$DEBUG&lt;/code&gt; flags are not set
 *  (so the exception has not yet been processed) it will be processed at this
 *  time.
 *     
 *     a = Thread.new { print &quot;a&quot;; sleep(10); print &quot;b&quot;; print &quot;c&quot; }
 *     x = Thread.new { print &quot;x&quot;; Thread.pass; print &quot;y&quot;; print &quot;z&quot; }
 *     x.join # Let x thread finish, a will be killed on exit.
 *     
 *  &lt;em&gt;produces:&lt;/em&gt;
 *     
 *     axyz
 *     
 *  The following example illustrates the &lt;i&gt;limit&lt;/i&gt; parameter.
 *     
 *     y = Thread.new { 4.times { sleep 0.1; puts 'tick... ' }}
 *     puts &quot;Waiting&quot; until y.join(0.15)
 *     
 *  &lt;em&gt;produces:&lt;/em&gt;
 *     
 *     tick...
 *     Waiting
 *     tick...
 *     Waitingtick...
 *     
 *     
 *     tick...
 */

static VALUE
rb_thread_join_m(argc, argv, thread)
    int argc;
    VALUE *argv;
    VALUE thread;
{
    VALUE limit;
    double delay = DELAY_INFTY;
    rb_thread_t th = rb_thread_check(thread);

    rb_scan_args(argc, argv, &quot;01&quot;, &amp;limit);
    if (!NIL_P(limit)) delay = rb_num2dbl(limit);
    if (!rb_thread_join(th, delay))
	return Qnil;
    return thread;
}


/*
 *  call-seq:
 *     Thread.current   =&gt; thread
 *  
 *  Returns the currently executing thread.
 *     
 *     Thread.current   #=&gt; #&lt;Thread:0x401bdf4c run&gt;
 */

VALUE
rb_thread_current()
{
    return curr_thread-&gt;thread;
}


/*
 *  call-seq:
 *     Thread.main   =&gt; thread
 *  
 *  Returns the main thread for the process.
 *     
 *     Thread.main   #=&gt; #&lt;Thread:0x401bdf4c run&gt;
 */

VALUE
rb_thread_main()
{
    return main_thread-&gt;thread;
}


/*
 *  call-seq:
 *     Thread.list   =&gt; array
 *  
 *  Returns an array of &lt;code&gt;Thread&lt;/code&gt; objects for all threads that are
 *  either runnable or stopped.
 *     
 *     Thread.new { sleep(200) }
 *     Thread.new { 1000000.times {|i| i*i } }
 *     Thread.new { Thread.stop }
 *     Thread.list.each {|t| p t}
 *     
 *  &lt;em&gt;produces:&lt;/em&gt;
 *     
 *     #&lt;Thread:0x401b3e84 sleep&gt;
 *     #&lt;Thread:0x401b3f38 run&gt;
 *     #&lt;Thread:0x401b3fb0 sleep&gt;
 *     #&lt;Thread:0x401bdf4c run&gt;
 */

VALUE
rb_thread_list()
{
    rb_thread_t th;
    VALUE ary = rb_ary_new();

    FOREACH_THREAD(th) {
	switch (th-&gt;status) {
	  case THREAD_RUNNABLE:
	  case THREAD_STOPPED:
	  case THREAD_TO_KILL:
	    rb_ary_push(ary, th-&gt;thread);
	  default:
	    break;
	}
    }
    END_FOREACH(th);

    return ary;
}


/*
 *  call-seq:
 *     thr.wakeup   =&gt; thr
 *  
 *  Marks &lt;i&gt;thr&lt;/i&gt; as eligible for scheduling (it may still remain blocked on
 *  I/O, however). Does not invoke the scheduler (see &lt;code&gt;Thread#run&lt;/code&gt;).
 *     
 *     c = Thread.new { Thread.stop; puts &quot;hey!&quot; }
 *     c.wakeup
 *     
 *  &lt;em&gt;produces:&lt;/em&gt;
 *     
 *     hey!
 */

VALUE
rb_thread_wakeup(thread)
    VALUE thread;
{
    if (!RTEST(rb_thread_wakeup_alive(thread)))
	rb_raise(rb_eThreadError, &quot;killed thread&quot;);
    return thread;
}

VALUE
rb_thread_wakeup_alive(thread)
    VALUE thread;
{
    rb_thread_t th = rb_thread_check(thread);

    if (th-&gt;status == THREAD_KILLED)
	return Qnil;
    rb_thread_ready(th);

    return thread;
}


/*
 *  call-seq:
 *     thr.run   =&gt; thr
 *  
 *  Wakes up &lt;i&gt;thr&lt;/i&gt;, making it eligible for scheduling. If not in a critical
 *  section, then invokes the scheduler.
 *     
 *     a = Thread.new { puts &quot;a&quot;; Thread.stop; puts &quot;c&quot; }
 *     Thread.pass
 *     puts &quot;Got here&quot;
 *     a.run
 *     a.join
 *     
 *  &lt;em&gt;produces:&lt;/em&gt;
 *     
 *     a
 *     Got here
 *     c
 */

VALUE
rb_thread_run(thread)
    VALUE thread;
{
    rb_thread_wakeup(thread);
    if (!rb_thread_critical) rb_thread_schedule();

    return thread;
}


static void
rb_kill_thread(th, flags)
    rb_thread_t th;
    int flags;
{
    if (th != curr_thread &amp;&amp; th-&gt;safe &lt; 4) {
	rb_secure(4);
    }
    if (th-&gt;status == THREAD_TO_KILL || th-&gt;status == THREAD_KILLED)
	return;
    if (th == th-&gt;next || th == main_thread) rb_exit(EXIT_SUCCESS);

    rb_thread_ready(th);
    th-&gt;flags |= flags;
    th-&gt;status = THREAD_TO_KILL;
    if (!rb_thread_critical) rb_thread_schedule();
}


/*
 *  call-seq:
 *     thr.exit        =&gt; thr
 *     thr.kill        =&gt; thr
 *     thr.terminate   =&gt; thr
 *  
 *  Terminates &lt;i&gt;thr&lt;/i&gt; and schedules another thread to be run, returning
 *  the terminated &lt;code&gt;Thread&lt;/code&gt;.  If this is the main thread, or the
 *  last thread, exits the process.
 */

VALUE
rb_thread_kill(thread)
    VALUE thread;
{
    rb_thread_t th = rb_thread_check(thread);

    rb_kill_thread(th, 0);
    return thread;
}


/*
 *  call-seq:
 *     thr.exit!        =&gt; thr
 *     thr.kill!        =&gt; thr
 *     thr.terminate!   =&gt; thr
 *  
 *  Terminates &lt;i&gt;thr&lt;/i&gt; without calling ensure clauses and schedules
 *  another thread to be run, returning the terminated &lt;code&gt;Thread&lt;/code&gt;.
 *  If this is the main thread, or the last thread, exits the process.
 *
 *  See &lt;code&gt;Thread#exit&lt;/code&gt; for the safer version.
 */

static VALUE
rb_thread_kill_bang(thread)
    VALUE thread;
{
    rb_thread_t th = rb_thread_check(thread);
    rb_kill_thread(th, THREAD_NO_ENSURE);
    return thread;
}

/*
 *  call-seq:
 *     Thread.kill(thread)   =&gt; thread
 *  
 *  Causes the given &lt;em&gt;thread&lt;/em&gt; to exit (see &lt;code&gt;Thread::exit&lt;/code&gt;).
 *     
 *     count = 0
 *     a = Thread.new { loop { count += 1 } }
 *     sleep(0.1)       #=&gt; 0
 *     Thread.kill(a)   #=&gt; #&lt;Thread:0x401b3d30 dead&gt;
 *     count            #=&gt; 93947
 *     a.alive?         #=&gt; false
 */

static VALUE
rb_thread_s_kill(obj, th)
    VALUE obj, th;
{
    return rb_thread_kill(th);
}


/*
 *  call-seq:
 *     Thread.exit   =&gt; thread
 *  
 *  Terminates the currently running thread and schedules another thread to be
 *  run. If this thread is already marked to be killed, &lt;code&gt;exit&lt;/code&gt;
 *  returns the &lt;code&gt;Thread&lt;/code&gt;. If this is the main thread, or the last
 *  thread, exit the process.
 */

static VALUE
rb_thread_exit()
{
    return rb_thread_kill(curr_thread-&gt;thread);
}


/*
 *  call-seq:
 *     Thread.pass   =&gt; nil
 *  
 *  Invokes the thread scheduler to pass execution to another thread.
 *     
 *     a = Thread.new { print &quot;a&quot;; Thread.pass;
 *                      print &quot;b&quot;; Thread.pass;
 *                      print &quot;c&quot; }
 *     b = Thread.new { print &quot;x&quot;; Thread.pass;
 *                      print &quot;y&quot;; Thread.pass;
 *                      print &quot;z&quot; }
 *     a.join
 *     b.join
 *     
 *  &lt;em&gt;produces:&lt;/em&gt;
 *     
 *     axbycz
 */

static VALUE
rb_thread_pass()
{
    rb_thread_schedule();
    return Qnil;
}


/*
 *  call-seq:
 *     Thread.stop   =&gt; nil
 *  
 *  Stops execution of the current thread, putting it into a ``sleep'' state,
 *  and schedules execution of another thread. Resets the ``critical'' condition
 *  to &lt;code&gt;false&lt;/code&gt;.
 *     
 *     a = Thread.new { print &quot;a&quot;; Thread.stop; print &quot;c&quot; }
 *     Thread.pass
 *     print &quot;b&quot;
 *     a.run
 *     a.join
 *     
 *  &lt;em&gt;produces:&lt;/em&gt;
 *     
 *     abc
 */

VALUE
rb_thread_stop()
{
    enum rb_thread_status last_status = THREAD_RUNNABLE;

    rb_thread_critical = 0;
    if (curr_thread == curr_thread-&gt;next) {
	rb_raise(rb_eThreadError, &quot;stopping only thread\n\tnote: use sleep to stop forever&quot;);
    }
    if (curr_thread-&gt;status == THREAD_TO_KILL)
	last_status = THREAD_TO_KILL;
    curr_thread-&gt;status = THREAD_STOPPED;
    rb_thread_schedule();
    curr_thread-&gt;status = last_status;

    return Qnil;
}

struct timeval rb_time_timeval();

void
rb_thread_polling()
{
    if (curr_thread != curr_thread-&gt;next) {
	curr_thread-&gt;status = THREAD_STOPPED;
	curr_thread-&gt;delay = timeofday() + (double)0.06;
	curr_thread-&gt;wait_for = WAIT_TIME;
	rb_thread_schedule();
    }
}

void
rb_thread_sleep(sec)
    int sec;
{
    if (curr_thread == curr_thread-&gt;next) {
	TRAP_BEG;
	sleep(sec);
	TRAP_END;
	return;
    }
    rb_thread_wait_for(rb_time_timeval(INT2FIX(sec)));
}

void
rb_thread_sleep_forever()
{
    int thr_critical = rb_thread_critical;
    if (curr_thread == curr_thread-&gt;next ||
	curr_thread-&gt;status == THREAD_TO_KILL) {
	rb_thread_critical = Qtrue;
	TRAP_BEG;
	pause();
	rb_thread_critical = thr_critical;
	TRAP_END;
	return;
    }

    curr_thread-&gt;delay = DELAY_INFTY;
    curr_thread-&gt;wait_for = WAIT_TIME;
    curr_thread-&gt;status = THREAD_STOPPED;
    rb_thread_schedule();
}


/*
 *  call-seq:
 *     thr.priority   =&gt; integer
 *
 *  Returns the priority of &lt;i&gt;thr&lt;/i&gt;. Default is inherited from the
 *  current thread which creating the new thread, or zero for the
 *  initial main thread; higher-priority threads will run before
 *  lower-priority threads.
 *
 *     Thread.current.priority   #=&gt; 0
 */

static VALUE
rb_thread_priority(thread)
    VALUE thread;
{
    return INT2NUM(rb_thread_check(thread)-&gt;priority);
}


/*
 *  call-seq:
 *     thr.priority= integer   =&gt; thr
 *
 *  Sets the priority of &lt;i&gt;thr&lt;/i&gt; to &lt;i&gt;integer&lt;/i&gt;. Higher-priority threads
 *  will run before lower-priority threads.
 *
 *     count1 = count2 = 0
 *     a = Thread.new do
 *           loop { count1 += 1 }
 *         end
 *     a.priority = -1
 *     
 *     b = Thread.new do
 *           loop { count2 += 1 }
 *         end
 *     b.priority = -2
 *     sleep 1   #=&gt; 1
 *     Thread.critical = 1
 *     count1    #=&gt; 622504
 *     count2    #=&gt; 5832
 */

static VALUE
rb_thread_priority_set(thread, prio)
    VALUE thread, prio;
{
    rb_thread_t th;

    rb_secure(4);
    th = rb_thread_check(thread);

    th-&gt;priority = NUM2INT(prio);
    rb_thread_schedule();
    return prio;
}


/*
 *  call-seq:
 *     thr.safe_level   =&gt; integer
 *  
 *  Returns the safe level in effect for &lt;i&gt;thr&lt;/i&gt;. Setting thread-local safe
 *  levels can help when implementing sandboxes which run insecure code.
 *     
 *     thr = Thread.new { $SAFE = 3; sleep }
 *     Thread.current.safe_level   #=&gt; 0
 *     thr.safe_level              #=&gt; 3
 */

static VALUE
rb_thread_safe_level(thread)
    VALUE thread;
{
    rb_thread_t th;

    th = rb_thread_check(thread);
    if (th == curr_thread) {
	return INT2NUM(ruby_safe_level);
    }
    return INT2NUM(th-&gt;safe);
}

static int ruby_thread_abort;
static VALUE thgroup_default;


/*
 *  call-seq:
 *     Thread.abort_on_exception   =&gt; true or false
 *  
 *  Returns the status of the global ``abort on exception'' condition.  The
 *  default is &lt;code&gt;false&lt;/code&gt;. When set to &lt;code&gt;true&lt;/code&gt;, or if the
 *  global &lt;code&gt;$DEBUG&lt;/code&gt; flag is &lt;code&gt;true&lt;/code&gt; (perhaps because the
 *  command line option &lt;code&gt;-d&lt;/code&gt; was specified) all threads will abort
 *  (the process will &lt;code&gt;exit(0)&lt;/code&gt;) if an exception is raised in any
 *  thread. See also &lt;code&gt;Thread::abort_on_exception=&lt;/code&gt;.
 */

static VALUE
rb_thread_s_abort_exc()
{
    return ruby_thread_abort?Qtrue:Qfalse;
}


/*
 *  call-seq:
 *     Thread.abort_on_exception= boolean   =&gt; true or false
 *  
 *  When set to &lt;code&gt;true&lt;/code&gt;, all threads will abort if an exception is
 *  raised. Returns the new state.
 *     
 *     Thread.abort_on_exception = true
 *     t1 = Thread.new do
 *       puts  &quot;In new thread&quot;
 *       raise &quot;Exception from thread&quot;
 *     end
 *     sleep(1)
 *     puts &quot;not reached&quot;
 *     
 *  &lt;em&gt;produces:&lt;/em&gt;
 *     
 *     In new thread
 *     prog.rb:4: Exception from thread (RuntimeError)
 *     	from prog.rb:2:in `initialize'
 *     	from prog.rb:2:in `new'
 *     	from prog.rb:2
 */

static VALUE
rb_thread_s_abort_exc_set(self, val)
    VALUE self, val;
{
    rb_secure(4);
    ruby_thread_abort = RTEST(val);
    return val;
}


/*
 *  call-seq:
 *     thr.abort_on_exception   =&gt; true or false
 *  
 *  Returns the status of the thread-local ``abort on exception'' condition for
 *  &lt;i&gt;thr&lt;/i&gt;. The default is &lt;code&gt;false&lt;/code&gt;. See also
 *  &lt;code&gt;Thread::abort_on_exception=&lt;/code&gt;.
 */

static VALUE
rb_thread_abort_exc(thread)
    VALUE thread;
{
    return rb_thread_check(thread)-&gt;abort?Qtrue:Qfalse;
}


/*
 *  call-seq:
 *     thr.abort_on_exception= boolean   =&gt; true or false
 *  
 *  When set to &lt;code&gt;true&lt;/code&gt;, causes all threads (including the main
 *  program) to abort if an exception is raised in &lt;i&gt;thr&lt;/i&gt;. The process will
 *  effectively &lt;code&gt;exit(0)&lt;/code&gt;.
 */

static VALUE
rb_thread_abort_exc_set(thread, val)
    VALUE thread, val;
{
    rb_secure(4);
    rb_thread_check(thread)-&gt;abort = RTEST(val);
    return val;
}


/*
 *  call-seq:
 *     thr.group   =&gt; thgrp or nil
 *  
 *  Returns the &lt;code&gt;ThreadGroup&lt;/code&gt; which contains &lt;i&gt;thr&lt;/i&gt;, or nil if
 *  the thread is not a member of any group.
 *     
 *     Thread.main.group   #=&gt; #&lt;ThreadGroup:0x4029d914&gt;
 */

VALUE
rb_thread_group(thread)
    VALUE thread;
{
    VALUE group = rb_thread_check(thread)-&gt;thgroup;
    if (!group) {
	group = Qnil;
    }
    return group;
}

#ifdef __ia64
# define IA64_INIT(x) x
#else
# define IA64_INIT(x)
#endif

#define THREAD_ALLOC(th) do {\
    th = ALLOC(struct rb_thread);\
\
    th-&gt;next = 0;\
    th-&gt;prev = 0;\
\
    th-&gt;status = THREAD_RUNNABLE;\
    th-&gt;result = 0;\
    th-&gt;flags = 0;\
\
    th-&gt;stk_ptr = 0;\
    th-&gt;stk_len = 0;\
    th-&gt;stk_max = 0;\
    th-&gt;wait_for = 0;\
    IA64_INIT(th-&gt;bstr_ptr = 0);\
    IA64_INIT(th-&gt;bstr_len = 0);\
    IA64_INIT(th-&gt;bstr_max = 0);\
    FD_ZERO(&amp;th-&gt;readfds);\
    FD_ZERO(&amp;th-&gt;writefds);\
    FD_ZERO(&amp;th-&gt;exceptfds);\
    th-&gt;delay = 0.0;\
    th-&gt;join = 0;\
\
    th-&gt;frame = 0;\
    th-&gt;scope = 0;\
    th-&gt;klass = 0;\
    th-&gt;wrapper = 0;\
    th-&gt;cref = ruby_cref;\
    th-&gt;dyna_vars = ruby_dyna_vars;\
    th-&gt;block = 0;\
    th-&gt;iter = 0;\
    th-&gt;tag = 0;\
    th-&gt;tracing = 0;\
    th-&gt;errinfo = Qnil;\
    th-&gt;last_status = 0;\
    th-&gt;last_line = 0;\
    th-&gt;last_match = Qnil;\
    th-&gt;abort = 0;\
    th-&gt;priority = 0;\
    th-&gt;thgroup = thgroup_default;\
    th-&gt;locals = 0;\
    th-&gt;thread = 0;\
    if (curr_thread == 0) {\
      th-&gt;sandbox = Qnil;\
    } else {\
      th-&gt;sandbox = curr_thread-&gt;sandbox;\
    }\
} while (0)

static rb_thread_t
rb_thread_alloc(klass)
    VALUE klass;
{
    rb_thread_t th;
    struct RVarmap *vars;

    THREAD_ALLOC(th);
    th-&gt;thread = Data_Wrap_Struct(klass, thread_mark, thread_free, th);

    for (vars = th-&gt;dyna_vars; vars; vars = vars-&gt;next) {
	if (FL_TEST(vars, DVAR_DONT_RECYCLE)) break;
	FL_SET(vars, DVAR_DONT_RECYCLE);
    }
    return th;
}

static int thread_init;

#if defined(_THREAD_SAFE)
static void
catch_timer(sig)
    int sig;
{
#if !defined(POSIX_SIGNAL) &amp;&amp; !defined(BSD_SIGNAL)
    signal(sig, catch_timer);
#endif
    /* cause EINTR */
}

static pthread_t time_thread;

static void*
thread_timer(dummy)
    void *dummy;
{
    sigset_t all_signals;

    sigfillset(&amp;all_signals);
    pthread_sigmask(SIG_BLOCK, &amp;all_signals, 0);

    for (;;) {
#ifdef HAVE_NANOSLEEP
	struct timespec req, rem;

	req.tv_sec = 0;
	req.tv_nsec = 10000000;
	nanosleep(&amp;req, &amp;rem);
#else
	struct timeval tv;
	tv.tv_sec = 0;
	tv.tv_usec = 10000;
	select(0, NULL, NULL, NULL, &amp;tv);
#endif
	if (!rb_thread_critical) {
	    rb_thread_pending = 1;
	    if (rb_trap_immediate) {
		pthread_kill(ruby_thid, SIGVTALRM);
	    }
	}
    }
}

void
rb_thread_start_timer()
{
}

void
rb_thread_stop_timer()
{
}
#elif defined(HAVE_SETITIMER)
static void
catch_timer(sig)
    int sig;
{
#if !defined(POSIX_SIGNAL) &amp;&amp; !defined(BSD_SIGNAL)
    signal(sig, catch_timer);
#endif
    if (!rb_thread_critical) {
	rb_thread_pending = 1;
    }
    /* cause EINTR */
}

void
rb_thread_start_timer()
{
    struct itimerval tval;

    if (!thread_init) return;
    tval.it_interval.tv_sec = 0;
    tval.it_interval.tv_usec = 10000;
    tval.it_value = tval.it_interval;
    setitimer(ITIMER_VIRTUAL, &amp;tval, NULL);
}

void
rb_thread_stop_timer()
{
    struct itimerval tval;

    if (!thread_init) return;
    tval.it_interval.tv_sec = 0;
    tval.it_interval.tv_usec = 0;
    tval.it_value = tval.it_interval;
    setitimer(ITIMER_VIRTUAL, &amp;tval, NULL);
}
#else  /* !(_THREAD_SAFE || HAVE_SETITIMER) */
int rb_thread_tick = THREAD_TICK;
#endif

static VALUE
rb_thread_start_0(fn, arg, th)
    VALUE (*fn)();
    void *arg;
    rb_thread_t th;
{
    volatile rb_thread_t th_save = th;
    volatile VALUE thread = th-&gt;thread;
    struct BLOCK *volatile saved_block = 0;
    enum rb_thread_status status;
    int state;

    if (OBJ_FROZEN(curr_thread-&gt;thgroup)) {
	rb_raise(rb_eThreadError,
		 &quot;can't start a new thread (frozen ThreadGroup)&quot;);
    }

    if (!thread_init) {
	thread_init = 1;
#if defined(HAVE_SETITIMER) || defined(_THREAD_SAFE)
#if defined(POSIX_SIGNAL)
	posix_signal(SIGVTALRM, catch_timer);
#else
	signal(SIGVTALRM, catch_timer);
#endif

#ifdef _THREAD_SAFE
	pthread_create(&amp;time_thread, 0, thread_timer, 0);
#else
	rb_thread_start_timer();
#endif
#endif
    }

    if (THREAD_SAVE_CONTEXT(curr_thread)) {
	return thread;
    }

    if (ruby_block) {		/* should nail down higher blocks */
	struct BLOCK dummy;

	dummy.prev = ruby_block;
	blk_copy_prev(&amp;dummy);
	saved_block = ruby_block = dummy.prev;
    }
    scope_dup(ruby_scope);

    if (!th-&gt;next) {
	/* merge in thread list */
	th-&gt;prev = curr_thread;
	curr_thread-&gt;next-&gt;prev = th;
	th-&gt;next = curr_thread-&gt;next;
	curr_thread-&gt;next = th;
	th-&gt;priority = curr_thread-&gt;priority;
	th-&gt;thgroup = curr_thread-&gt;thgroup;
    }

    PUSH_TAG(PROT_THREAD);
    if ((state = EXEC_TAG()) == 0) {
	if (THREAD_SAVE_CONTEXT(th) == 0) {
	    curr_thread = th;
	    th-&gt;result = (*fn)(arg, th);
	}
	th = th_save;
    }
    else if (TAG_DST()) {
	th = th_save;
	th-&gt;result = prot_tag-&gt;retval;
    }
    POP_TAG();
    status = th-&gt;status;

    if (th == main_thread) ruby_stop(state);
    rb_thread_remove(th);

    if (saved_block) {
	blk_free(saved_block);
    }

    if (state &amp;&amp; status != THREAD_TO_KILL &amp;&amp; !NIL_P(ruby_errinfo)) {
	th-&gt;flags |= THREAD_RAISED;
	if (state == TAG_FATAL) {
	    /* fatal error within this thread, need to stop whole script */
	    main_thread-&gt;errinfo = ruby_errinfo;
	    rb_thread_cleanup();
	}
	else if (rb_obj_is_kind_of(ruby_errinfo, rb_eSystemExit)) {
	    if (th-&gt;safe &gt;= 4) {
		char buf[32];

		sprintf(buf, &quot;Insecure exit at level %d&quot;, th-&gt;safe);
		th-&gt;errinfo = rb_exc_new2(rb_eSecurityError, buf);
	    }
	    else {
		/* delegate exception to main_thread */
		rb_thread_main_jump(ruby_errinfo, RESTORE_RAISE);
	    }
	}
	else if (th-&gt;safe &lt; 4 &amp;&amp; (ruby_thread_abort || th-&gt;abort || RTEST(ruby_debug))) {
	    /* exit on main_thread */
	    error_print();
	    rb_thread_main_jump(ruby_errinfo, RESTORE_EXIT);
	}
	else {
	    th-&gt;errinfo = ruby_errinfo;
	}
    }
    rb_thread_schedule();
    ruby_stop(0);		/* last thread termination */
    return 0;			/* not reached */
}

VALUE
rb_thread_create(fn, arg)
    VALUE (*fn)();
    void *arg;
{
    Init_stack((void *)&amp;arg);
    return rb_thread_start_0(fn, arg, rb_thread_alloc(rb_cThread));
}

static VALUE
rb_thread_yield(arg, th)
    VALUE arg;
    rb_thread_t th;
{
    const ID *tbl;

    scope_dup(ruby_block-&gt;scope);

    tbl = ruby_scope-&gt;local_tbl;
    if (tbl) {
	int n = *tbl++;
	for (tbl += 2, n -= 2; n &gt; 0; --n) { /* skip first 2 ($_ and $~) */
	    ID id = *tbl++;
	    if (id != 0 &amp;&amp; !rb_is_local_id(id))  /* push flip states */
		rb_dvar_push(id, Qfalse);
	}
    }
    rb_dvar_push('_', Qnil);
    rb_dvar_push('~', Qnil);
    ruby_block-&gt;dyna_vars = ruby_dyna_vars;

    return rb_yield_0(arg, 0, 0, YIELD_LAMBDA_CALL, Qtrue);
}

/*
 *  call-seq:
 *     Thread.new([arg]*) {|args| block }   =&gt; thread
 *  
 *  Creates and runs a new thread to execute the instructions given in
 *  &lt;i&gt;block&lt;/i&gt;. Any arguments passed to &lt;code&gt;Thread::new&lt;/code&gt; are passed
 *  into the block.
 *     
 *     x = Thread.new { sleep 0.1; print &quot;x&quot;; print &quot;y&quot;; print &quot;z&quot; }
 *     a = Thread.new { print &quot;a&quot;; print &quot;b&quot;; sleep 0.2; print &quot;c&quot; }
 *     x.join # Let the threads finish before
 *     a.join # main thread exits...
 *     
 *  &lt;em&gt;produces:&lt;/em&gt;
 *     
 *     abxyzc
 */

static VALUE
rb_thread_s_new(argc, argv, klass)
    int argc;
    VALUE *argv;
    VALUE klass;
{
    rb_thread_t th = rb_thread_alloc(klass);
    volatile VALUE *pos;

    pos = th-&gt;stk_pos;
    rb_obj_call_init(th-&gt;thread, argc, argv);
    if (th-&gt;stk_pos == 0) {
	rb_raise(rb_eThreadError, &quot;uninitialized thread - check `%s#initialize'&quot;,
		 rb_class2name(klass));
    }

    return th-&gt;thread;
}


/*
 *  call-seq:
 *     Thread.new([arg]*) {|args| block }   =&gt; thread
 *  
 *  Creates and runs a new thread to execute the instructions given in
 *  &lt;i&gt;block&lt;/i&gt;. Any arguments passed to &lt;code&gt;Thread::new&lt;/code&gt; are passed
 *  into the block.
 *     
 *     x = Thread.new { sleep 0.1; print &quot;x&quot;; print &quot;y&quot;; print &quot;z&quot; }
 *     a = Thread.new { print &quot;a&quot;; print &quot;b&quot;; sleep 0.2; print &quot;c&quot; }
 *     x.join # Let the threads finish before
 *     a.join # main thread exits...
 *     
 *  &lt;em&gt;produces:&lt;/em&gt;
 *     
 *     abxyzc
 */

static VALUE
rb_thread_initialize(thread, args)
    VALUE thread, args;
{
    rb_thread_t th;

    if (!rb_block_given_p()) {
	rb_raise(rb_eThreadError, &quot;must be called with a block&quot;);
    }
    th = rb_thread_check(thread);
    if (th-&gt;stk_max) {
	NODE *node = th-&gt;node;
	if (!node) {
	    rb_raise(rb_eThreadError, &quot;already initialized thread&quot;);
	}
	rb_raise(rb_eThreadError, &quot;already initialized thread - %s:%d&quot;,
		 node-&gt;nd_file, nd_line(node));
    }
    return rb_thread_start_0(rb_thread_yield, args, th);
}


/*
 *  call-seq:
 *     Thread.start([args]*) {|args| block }   =&gt; thread
 *     Thread.fork([args]*) {|args| block }    =&gt; thread
 *  
 *  Basically the same as &lt;code&gt;Thread::new&lt;/code&gt;. However, if class
 *  &lt;code&gt;Thread&lt;/code&gt; is subclassed, then calling &lt;code&gt;start&lt;/code&gt; in that
 *  subclass will not invoke the subclass's &lt;code&gt;initialize&lt;/code&gt; method.
 */

static VALUE
rb_thread_start(klass, args)
    VALUE klass, args;
{
    if (!rb_block_given_p()) {
	rb_raise(rb_eThreadError, &quot;must be called with a block&quot;);
    }
    return rb_thread_start_0(rb_thread_yield, args, rb_thread_alloc(klass));
}


/*
 *  call-seq:
 *     thr.value   =&gt; obj
 *  
 *  Waits for &lt;i&gt;thr&lt;/i&gt; to complete (via &lt;code&gt;Thread#join&lt;/code&gt;) and returns
 *  its value.
 *     
 *     a = Thread.new { 2 + 2 }
 *     a.value   #=&gt; 4
 */

static VALUE
rb_thread_value(thread)
    VALUE thread;
{
    rb_thread_t th = rb_thread_check(thread);

    while (!rb_thread_join(th, DELAY_INFTY));

    return th-&gt;result;
}


/*
 *  call-seq:
 *     thr.status   =&gt; string, false or nil
 *  
 *  Returns the status of &lt;i&gt;thr&lt;/i&gt;: ``&lt;code&gt;sleep&lt;/code&gt;'' if &lt;i&gt;thr&lt;/i&gt; is
 *  sleeping or waiting on I/O, ``&lt;code&gt;run&lt;/code&gt;'' if &lt;i&gt;thr&lt;/i&gt; is executing,
 *  ``&lt;code&gt;aborting&lt;/code&gt;'' if &lt;i&gt;thr&lt;/i&gt; is aborting, &lt;code&gt;false&lt;/code&gt; if
 *  &lt;i&gt;thr&lt;/i&gt; terminated normally, and &lt;code&gt;nil&lt;/code&gt; if &lt;i&gt;thr&lt;/i&gt;
 *  terminated with an exception.
 *     
 *     a = Thread.new { raise(&quot;die now&quot;) }
 *     b = Thread.new { Thread.stop }
 *     c = Thread.new { Thread.exit }
 *     d = Thread.new { sleep }
 *     Thread.critical = true
 *     d.kill                  #=&gt; #&lt;Thread:0x401b3678 aborting&gt;
 *     a.status                #=&gt; nil
 *     b.status                #=&gt; &quot;sleep&quot;
 *     c.status                #=&gt; false
 *     d.status                #=&gt; &quot;aborting&quot;
 *     Thread.current.status   #=&gt; &quot;run&quot;
 */

static VALUE
rb_thread_status(thread)
    VALUE thread;
{
    rb_thread_t th = rb_thread_check(thread);

    if (rb_thread_dead(th)) {
	if (!NIL_P(th-&gt;errinfo) &amp;&amp; (th-&gt;flags &amp; THREAD_RAISED))
	    return Qnil;
	return Qfalse;
    }

    return rb_str_new2(thread_status_name(th-&gt;status));
}


/*
 *  call-seq:
 *     thr.alive?   =&gt; true or false
 *  
 *  Returns &lt;code&gt;true&lt;/code&gt; if &lt;i&gt;thr&lt;/i&gt; is running or sleeping.
 *     
 *     thr = Thread.new { }
 *     thr.join                #=&gt; #&lt;Thread:0x401b3fb0 dead&gt;
 *     Thread.current.alive?   #=&gt; true
 *     thr.alive?              #=&gt; false
 */

VALUE
rb_thread_alive_p(thread)
    VALUE thread;
{
    rb_thread_t th = rb_thread_check(thread);

    if (rb_thread_dead(th)) return Qfalse;
    return Qtrue;
}


/*
 *  call-seq:
 *     thr.stop?   =&gt; true or false
 *  
 *  Returns &lt;code&gt;true&lt;/code&gt; if &lt;i&gt;thr&lt;/i&gt; is dead or sleeping.
 *     
 *     a = Thread.new { Thread.stop }
 *     b = Thread.current
 *     a.stop?   #=&gt; true
 *     b.stop?   #=&gt; false
 */

static VALUE
rb_thread_stop_p(thread)
    VALUE thread;
{
    rb_thread_t th = rb_thread_check(thread);

    if (rb_thread_dead(th)) return Qtrue;
    if (th-&gt;status == THREAD_STOPPED) return Qtrue;
    return Qfalse;
}

static void
rb_thread_wait_other_threads()
{
    rb_thread_t th;
    int found;

    /* wait other threads to terminate */
    while (curr_thread != curr_thread-&gt;next) {
	found = 0;
	FOREACH_THREAD(th) {
	    if (th != curr_thread &amp;&amp; th-&gt;status != THREAD_STOPPED) {
		found = 1;
		break;
	    }
	}
	END_FOREACH(th);
	if (!found) return;
	rb_thread_schedule();
    }
}

static void
rb_thread_cleanup()
{
    rb_thread_t curr, th;

    curr = curr_thread;
    while (curr-&gt;status == THREAD_KILLED) {
	curr = curr-&gt;prev;
    }

    FOREACH_THREAD_FROM(curr, th) {
	if (th-&gt;status != THREAD_KILLED) {
	    rb_thread_ready(th);
	    if (th != main_thread) {
		th-&gt;thgroup = 0;
		th-&gt;priority = 0;
		th-&gt;status = THREAD_TO_KILL;
		RDATA(th-&gt;thread)-&gt;dfree = NULL;
	    }
	}
    }
    END_FOREACH_FROM(curr, th);
}

int rb_thread_critical;


/*
 *  call-seq:
 *     Thread.critical   =&gt; true or false
 *  
 *  Returns the status of the global ``thread critical'' condition.
 */

static VALUE
rb_thread_critical_get()
{
    return rb_thread_critical?Qtrue:Qfalse;
}


/*
 *  call-seq:
 *     Thread.critical= boolean   =&gt; true or false
 *  
 *  Sets the status of the global ``thread critical'' condition and returns
 *  it. When set to &lt;code&gt;true&lt;/code&gt;, prohibits scheduling of any existing
 *  thread. Does not block new threads from being created and run. Certain
 *  thread operations (such as stopping or killing a thread, sleeping in the
 *  current thread, and raising an exception) may cause a thread to be scheduled
 *  even when in a critical section.  &lt;code&gt;Thread::critical&lt;/code&gt; is not
 *  intended for daily use: it is primarily there to support folks writing
 *  threading libraries.
 */

static VALUE
rb_thread_critical_set(obj, val)
    VALUE obj, val;
{
    rb_thread_critical = RTEST(val);
    return val;
}

void
rb_thread_interrupt()
{
    rb_thread_critical = 0;
    rb_thread_ready(main_thread);
    if (curr_thread == main_thread) {
	rb_interrupt();
    }
    if (!rb_thread_dead(curr_thread)) {
	if (THREAD_SAVE_CONTEXT(curr_thread)) {
	    return;
	}
    }
    curr_thread = main_thread;
    rb_thread_restore_context(curr_thread, RESTORE_INTERRUPT);
}

void
rb_thread_signal_raise(sig)
    int sig;
{
    rb_thread_critical = 0;
    if (curr_thread == main_thread) {
	VALUE argv[1];

	rb_thread_ready(curr_thread);
	argv[0] = INT2FIX(sig);
	rb_exc_raise(rb_class_new_instance(1, argv, rb_eSignal));
    }
    rb_thread_ready(main_thread);
    if (!rb_thread_dead(curr_thread)) {
	if (THREAD_SAVE_CONTEXT(curr_thread)) {
	    return;
	}
    }
    th_sig = sig;
    curr_thread = main_thread;
    rb_thread_restore_context(curr_thread, RESTORE_SIGNAL);
}

void
rb_thread_trap_eval(cmd, sig, safe)
    VALUE cmd;
    int sig, safe;
{
    rb_thread_critical = 0;
    if (curr_thread == main_thread) {
	rb_trap_eval(cmd, sig, safe);
	return;
    }
    if (!rb_thread_dead(curr_thread)) {
	if (THREAD_SAVE_CONTEXT(curr_thread)) {
	    return;
	}
    }
    th_cmd = cmd;
    th_sig = sig;
    th_safe = safe;
    curr_thread = main_thread;
    rb_thread_restore_context(curr_thread, RESTORE_TRAP);
}

void
rb_thread_signal_exit()
{
    VALUE args[2];

    rb_thread_critical = 0;
    if (curr_thread == main_thread) {
	rb_thread_ready(curr_thread);
	rb_exit(EXIT_SUCCESS);
    }
    args[0] = INT2NUM(EXIT_SUCCESS);
    args[1] = rb_str_new2(&quot;exit&quot;);
    rb_thread_ready(main_thread);
    if (!rb_thread_dead(curr_thread)) {
	if (THREAD_SAVE_CONTEXT(curr_thread)) {
	    return;
	}
    }
    rb_thread_main_jump(rb_class_new_instance(2, args, rb_eSystemExit), 
			RESTORE_EXIT);
}

static VALUE
rb_thread_raise(argc, argv, th)
    int argc;
    VALUE *argv;
    rb_thread_t th;
{
    volatile rb_thread_t th_save = th;
    VALUE exc;

    if (!th-&gt;next) {
	rb_raise(rb_eArgError, &quot;unstarted thread&quot;);
    }
    if (rb_thread_dead(th)) return Qnil;
    exc = rb_make_exception(argc, argv);
    if (curr_thread == th) {
	rb_raise_jump(exc);
    }

    if (!rb_thread_dead(curr_thread)) {
	if (THREAD_SAVE_CONTEXT(curr_thread)) {
	    return th_save-&gt;thread;
	}
    }

    rb_thread_ready(th);
    curr_thread = th;

    th_raise_exception = exc;
    th_raise_node = ruby_current_node;
    rb_thread_restore_context(curr_thread, RESTORE_RAISE);
    return Qnil;		/* not reached */
}


/*
 *  call-seq:
 *     thr.raise(exception)
 *  
 *  Raises an exception (see &lt;code&gt;Kernel::raise&lt;/code&gt;) from &lt;i&gt;thr&lt;/i&gt;. The
 *  caller does not have to be &lt;i&gt;thr&lt;/i&gt;.
 *     
 *     Thread.abort_on_exception = true
 *     a = Thread.new { sleep(200) }
 *     a.raise(&quot;Gotcha&quot;)
 *     
 *  &lt;em&gt;produces:&lt;/em&gt;
 *     
 *     prog.rb:3: Gotcha (RuntimeError)
 *     	from prog.rb:2:in `initialize'
 *     	from prog.rb:2:in `new'
 *     	from prog.rb:2
 */

static VALUE
rb_thread_raise_m(argc, argv, thread)
    int argc;
    VALUE *argv;
    VALUE thread;
{
    rb_thread_t th = rb_thread_check(thread);

    if (ruby_safe_level &gt; th-&gt;safe) {
	rb_secure(4);
    }
    rb_thread_raise(argc, argv, th);
    return Qnil;		/* not reached */
}

VALUE
rb_thread_local_aref(thread, id)
    VALUE thread;
    ID id;
{
    rb_thread_t th;
    VALUE val;

    th = rb_thread_check(thread);
    if (ruby_safe_level &gt;= 4 &amp;&amp; th != curr_thread) {
	rb_raise(rb_eSecurityError, &quot;Insecure: thread locals&quot;);
    }
    if (!th-&gt;locals) return Qnil;
    if (st_lookup(th-&gt;locals, id, &amp;val)) {
	return val;
    }
    return Qnil;
}


/*
 *  call-seq:
 *      thr[sym]   =&gt; obj or nil
 *  
 *  Attribute Reference---Returns the value of a thread-local variable, using
 *  either a symbol or a string name. If the specified variable does not exist,
 *  returns &lt;code&gt;nil&lt;/code&gt;.
 *     
 *     a = Thread.new { Thread.current[&quot;name&quot;] = &quot;A&quot;; Thread.stop }
 *     b = Thread.new { Thread.current[:name]  = &quot;B&quot;; Thread.stop }
 *     c = Thread.new { Thread.current[&quot;name&quot;] = &quot;C&quot;; Thread.stop }
 *     Thread.list.each {|x| puts &quot;#{x.inspect}: #{x[:name]}&quot; }
 *     
 *  &lt;em&gt;produces:&lt;/em&gt;
 *     
 *     #&lt;Thread:0x401b3b3c sleep&gt;: C
 *     #&lt;Thread:0x401b3bc8 sleep&gt;: B
 *     #&lt;Thread:0x401b3c68 sleep&gt;: A
 *     #&lt;Thread:0x401bdf4c run&gt;:
 */

static VALUE
rb_thread_aref(thread, id)
    VALUE thread, id;
{
    return rb_thread_local_aref(thread, rb_to_id(id));
}

VALUE
rb_thread_local_aset(thread, id, val)
    VALUE thread;
    ID id;
    VALUE val;
{
    rb_thread_t th = rb_thread_check(thread);

    if (ruby_safe_level &gt;= 4 &amp;&amp; th != curr_thread) {
	rb_raise(rb_eSecurityError, &quot;Insecure: can't modify thread locals&quot;);
    }
    if (OBJ_FROZEN(thread)) rb_error_frozen(&quot;thread locals&quot;);

    if (!th-&gt;locals) {
	th-&gt;locals = st_init_numtable();
    }
    if (NIL_P(val)) {
	st_delete(th-&gt;locals, (st_data_t*)&amp;id, 0);
	return Qnil;
    }
    st_insert(th-&gt;locals, id, val);

    return val;
}


/*
 *  call-seq:
 *      thr[sym] = obj   =&gt; obj
 *  
 *  Attribute Assignment---Sets or creates the value of a thread-local variable,
 *  using either a symbol or a string. See also &lt;code&gt;Thread#[]&lt;/code&gt;.
 */

static VALUE
rb_thread_aset(thread, id, val)
    VALUE thread, id, val;
{
    return rb_thread_local_aset(thread, rb_to_id(id), val);
}


/*
 *  call-seq:
 *     thr.key?(sym)   =&gt; true or false
 *  
 *  Returns &lt;code&gt;true&lt;/code&gt; if the given string (or symbol) exists as a
 *  thread-local variable.
 *     
 *     me = Thread.current
 *     me[:oliver] = &quot;a&quot;
 *     me.key?(:oliver)    #=&gt; true
 *     me.key?(:stanley)   #=&gt; false
 */

static VALUE
rb_thread_key_p(thread, id)
    VALUE thread, id;
{
    rb_thread_t th = rb_thread_check(thread);

    if (!th-&gt;locals) return Qfalse;
    if (st_lookup(th-&gt;locals, rb_to_id(id), 0))
	return Qtrue;
    return Qfalse;
}

static int
thread_keys_i(key, value, ary)
    ID key;
    VALUE value, ary;
{
    rb_ary_push(ary, ID2SYM(key));
    return ST_CONTINUE;
}


/*
 *  call-seq:
 *     thr.keys   =&gt; array
 *  
 *  Returns an an array of the names of the thread-local variables (as Symbols).
 *     
 *     thr = Thread.new do
 *       Thread.current[:cat] = 'meow'
 *       Thread.current[&quot;dog&quot;] = 'woof'
 *     end
 *     thr.join   #=&gt; #&lt;Thread:0x401b3f10 dead&gt;
 *     thr.keys   #=&gt; [:dog, :cat]
 */

static VALUE
rb_thread_keys(thread)
    VALUE thread;
{
    rb_thread_t th = rb_thread_check(thread);
    VALUE ary = rb_ary_new();

    if (th-&gt;locals) {
	st_foreach(th-&gt;locals, thread_keys_i, ary);
    }
    return ary;
}

/*
 * call-seq:
 *   thr.inspect   =&gt; string
 *
 * Dump the name, id, and status of _thr_ to a string.
 */

static VALUE
rb_thread_inspect(thread)
    VALUE thread;
{
    const char *cname = rb_obj_classname(thread);
    rb_thread_t th = rb_thread_check(thread);
    const char *status = thread_status_name(th-&gt;status);
    VALUE str;
    size_t len = strlen(cname)+7+16+9+1;

    str = rb_str_new(0, len); /* 7:tags 16:addr 9:status 1:nul */
    snprintf(RSTRING(str)-&gt;ptr, len, &quot;#&lt;%s:0x%lx %s&gt;&quot;, cname, thread, status);
    RSTRING(str)-&gt;len = strlen(RSTRING(str)-&gt;ptr);
    OBJ_INFECT(str, thread);

    return str;
}

void
rb_thread_atfork()
{
    rb_thread_t th;

    if (rb_thread_alone()) return;
    FOREACH_THREAD(th) {
	if (th != curr_thread) {
	    rb_thread_die(th);
	}
    }
    END_FOREACH(th);
    main_thread = curr_thread;
    curr_thread-&gt;next = curr_thread;
    curr_thread-&gt;prev = curr_thread;
}


/*
 *  Document-class: Continuation
 *
 *  Continuation objects are generated by
 *  &lt;code&gt;Kernel#callcc&lt;/code&gt;. They hold a return address and execution
 *  context, allowing a nonlocal return to the end of the
 *  &lt;code&gt;callcc&lt;/code&gt; block from anywhere within a program.
 *  Continuations are somewhat analogous to a structured version of C's
 *  &lt;code&gt;setjmp/longjmp&lt;/code&gt; (although they contain more state, so
 *  you might consider them closer to threads).
 *     
 *  For instance:
 *     
 *     arr = [ &quot;Freddie&quot;, &quot;Herbie&quot;, &quot;Ron&quot;, &quot;Max&quot;, &quot;Ringo&quot; ]
 *     callcc{|$cc|}
 *     puts(message = arr.shift)
 *     $cc.call unless message =~ /Max/
 *     
 *  &lt;em&gt;produces:&lt;/em&gt;
 *     
 *     Freddie
 *     Herbie
 *     Ron
 *     Max
 *     
 *  This (somewhat contrived) example allows the inner loop to abandon
 *  processing early:
 *     
 *     callcc {|cont|
 *       for i in 0..4
 *         print &quot;\n#{i}: &quot;
 *         for j in i*5...(i+1)*5
 *           cont.call() if j == 17
 *           printf &quot;%3d&quot;, j
 *         end
 *       end
 *     }
 *     print &quot;\n&quot;
 *     
 *  &lt;em&gt;produces:&lt;/em&gt;
 *     
 *     0:   0  1  2  3  4
 *     1:   5  6  7  8  9
 *     2:  10 11 12 13 14
 *     3:  15 16
 */

VALUE rb_cCont;

/*
 *  call-seq:
 *     callcc {|cont| block }   =&gt;  obj
 *  
 *  Generates a &lt;code&gt;Continuation&lt;/code&gt; object, which it passes to the
 *  associated block. Performing a &lt;em&gt;cont&lt;/em&gt;&lt;code&gt;.call&lt;/code&gt; will
 *  cause the &lt;code&gt;callcc&lt;/code&gt; to return (as will falling through the
 *  end of the block). The value returned by the &lt;code&gt;callcc&lt;/code&gt; is
 *  the value of the block, or the value passed to
 *  &lt;em&gt;cont&lt;/em&gt;&lt;code&gt;.call&lt;/code&gt;. See class &lt;code&gt;Continuation&lt;/code&gt; 
 *  for more details. Also see &lt;code&gt;Kernel::throw&lt;/code&gt; for
 *  an alternative mechanism for unwinding a call stack.
 */

static VALUE
rb_callcc(self)
    VALUE self;
{
    volatile VALUE cont;
    rb_thread_t th;
    volatile rb_thread_t th_save;
    struct tag *tag;
    struct RVarmap *vars;

    THREAD_ALLOC(th);
    cont = Data_Wrap_Struct(rb_cCont, thread_mark, thread_free, th);

    scope_dup(ruby_scope);
    for (tag=prot_tag; tag; tag=tag-&gt;prev) {
	scope_dup(tag-&gt;scope);
    }
    th-&gt;thread = curr_thread-&gt;thread;
    th-&gt;thgroup = cont_protect;

    for (vars = ruby_dyna_vars; vars; vars = vars-&gt;next) {
	if (FL_TEST(vars, DVAR_DONT_RECYCLE)) break;
	FL_SET(vars, DVAR_DONT_RECYCLE);
    }
    th_save = th;
    if (THREAD_SAVE_CONTEXT(th)) {
	return th_save-&gt;result;
    }
    else {
	return rb_yield(cont);
    }
}

/*
 *  call-seq:
 *     cont.call(args, ...) 
 *     cont[args, ...]
 *  
 *  Invokes the continuation. The program continues from the end of the
 *  &lt;code&gt;callcc&lt;/code&gt; block. If no arguments are given, the original
 *  &lt;code&gt;callcc&lt;/code&gt; returns &lt;code&gt;nil&lt;/code&gt;. If one argument is
 *  given, &lt;code&gt;callcc&lt;/code&gt; returns it. Otherwise, an array
 *  containing &lt;i&gt;args&lt;/i&gt; is returned.
 *     
 *     callcc {|cont|  cont.call }           #=&gt; nil
 *     callcc {|cont|  cont.call 1 }         #=&gt; 1
 *     callcc {|cont|  cont.call 1, 2, 3 }   #=&gt; [1, 2, 3]
 */

static VALUE
rb_cont_call(argc, argv, cont)
    int argc;
    VALUE *argv;
    VALUE cont;
{
    rb_thread_t th = rb_thread_check(cont);

    if (th-&gt;thread != curr_thread-&gt;thread) {
	rb_raise(rb_eRuntimeError, &quot;continuation called across threads&quot;);
    }
    if (th-&gt;thgroup != cont_protect) {
	rb_raise(rb_eRuntimeError, &quot;continuation called across trap&quot;);
    }
    switch (argc) {
      case 0:
	th-&gt;result = Qnil;
	break;
      case 1:
	th-&gt;result = argv[0];
	break;
      default:
	th-&gt;result = rb_ary_new4(argc, argv);
	break;
    }

    rb_thread_restore_context(th, RESTORE_NORMAL);
    return Qnil;
}

struct thgroup {
    int enclosed;
    VALUE group;
};


/*
 * Document-class: ThreadGroup
 *
 *  &lt;code&gt;ThreadGroup&lt;/code&gt; provides a means of keeping track of a number of
 *  threads as a group. A &lt;code&gt;Thread&lt;/code&gt; can belong to only one
 *  &lt;code&gt;ThreadGroup&lt;/code&gt; at a time; adding a thread to a new group will
 *  remove it from any previous group.
 *     
 *  Newly created threads belong to the same group as the thread from which they
 *  were created.
 */

static VALUE thgroup_s_alloc _((VALUE));
static VALUE
thgroup_s_alloc(klass)
    VALUE klass;
{
    VALUE group;
    struct thgroup *data;

    group = Data_Make_Struct(klass, struct thgroup, 0, free, data);
    data-&gt;enclosed = 0;
    data-&gt;group = group;

    return group;
}


/*
 *  call-seq:
 *     thgrp.list   =&gt; array
 *  
 *  Returns an array of all existing &lt;code&gt;Thread&lt;/code&gt; objects that belong to
 *  this group.
 *     
 *     ThreadGroup::Default.list   #=&gt; [#&lt;Thread:0x401bdf4c run&gt;]
 */

static VALUE
thgroup_list(group)
    VALUE group;
{
    struct thgroup *data;
    rb_thread_t th;
    VALUE ary;

    Data_Get_Struct(group, struct thgroup, data);
    ary = rb_ary_new();

    FOREACH_THREAD(th) {
	if (th-&gt;thgroup == data-&gt;group) {
	    rb_ary_push(ary, th-&gt;thread);
	}
    }
    END_FOREACH(th);

    return ary;
}


/*
 *  call-seq:
 *     thgrp.enclose   =&gt; thgrp
 *  
 *  Prevents threads from being added to or removed from the receiving
 *  &lt;code&gt;ThreadGroup&lt;/code&gt;. New threads can still be started in an enclosed
 *  &lt;code&gt;ThreadGroup&lt;/code&gt;.
 *     
 *     ThreadGroup::Default.enclose        #=&gt; #&lt;ThreadGroup:0x4029d914&gt;
 *     thr = Thread::new { Thread.stop }   #=&gt; #&lt;Thread:0x402a7210 sleep&gt;
 *     tg = ThreadGroup::new               #=&gt; #&lt;ThreadGroup:0x402752d4&gt;
 *     tg.add thr
 *
 *  &lt;em&gt;produces:&lt;/em&gt;
 *
 *     ThreadError: can't move from the enclosed thread group
 */

static VALUE
thgroup_enclose(group)
    VALUE group;
{
    struct thgroup *data;

    Data_Get_Struct(group, struct thgroup, data);
    data-&gt;enclosed = 1;

    return group;
}


/*
 *  call-seq:
 *     thgrp.enclosed?   =&gt; true or false
 *  
 *  Returns &lt;code&gt;true&lt;/code&gt; if &lt;em&gt;thgrp&lt;/em&gt; is enclosed. See also
 *  ThreadGroup#enclose.
 */

static VALUE
thgroup_enclosed_p(group)
    VALUE group;
{
    struct thgroup *data;

    Data_Get_Struct(group, struct thgroup, data);
    if (data-&gt;enclosed) return Qtrue;
    return Qfalse;
}


/*
 *  call-seq:
 *     thgrp.add(thread)   =&gt; thgrp
 *  
 *  Adds the given &lt;em&gt;thread&lt;/em&gt; to this group, removing it from any other
 *  group to which it may have previously belonged.
 *     
 *     puts &quot;Initial group is #{ThreadGroup::Default.list}&quot;
 *     tg = ThreadGroup.new
 *     t1 = Thread.new { sleep }
 *     t2 = Thread.new { sleep }
 *     puts &quot;t1 is #{t1}&quot;
 *     puts &quot;t2 is #{t2}&quot;
 *     tg.add(t1)
 *     puts &quot;Initial group now #{ThreadGroup::Default.list}&quot;
 *     puts &quot;tg group now #{tg.list}&quot;
 *     
 *  &lt;em&gt;produces:&lt;/em&gt;
 *     
 *     Initial group is #&lt;Thread:0x401bdf4c&gt;
 *     t1 is #&lt;Thread:0x401b3c90&gt;
 *     t2 is #&lt;Thread:0x401b3c18&gt;
 *     Initial group now #&lt;Thread:0x401b3c18&gt;#&lt;Thread:0x401bdf4c&gt;
 *     tg group now #&lt;Thread:0x401b3c90&gt;
 */

static VALUE
thgroup_add(group, thread)
    VALUE group, thread;
{
    rb_thread_t th;
    struct thgroup *data;

    rb_secure(4);
    th = rb_thread_check(thread);
    if (!th-&gt;next || !th-&gt;prev) {
	rb_raise(rb_eTypeError, &quot;wrong argument type %s (expected Thread)&quot;,
		 rb_obj_classname(thread));
    }

    if (OBJ_FROZEN(group)) {
      rb_raise(rb_eThreadError, &quot;can't move to the frozen thread group&quot;);
    }
    Data_Get_Struct(group, struct thgroup, data);
    if (data-&gt;enclosed) {
	rb_raise(rb_eThreadError, &quot;can't move to the enclosed thread group&quot;);
    }

    if (!th-&gt;thgroup) {
	return Qnil;
    }
    if (OBJ_FROZEN(th-&gt;thgroup)) {
	rb_raise(rb_eThreadError, &quot;can't move from the frozen thread group&quot;);
    }
    Data_Get_Struct(th-&gt;thgroup, struct thgroup, data);
    if (data-&gt;enclosed) {
	rb_raise(rb_eThreadError, &quot;can't move from the enclosed thread group&quot;);
    }

    th-&gt;thgroup = group;
    return group;
}


/* variables for recursive traversals */
static ID recursive_key;

static VALUE
recursive_check(hash, obj)
    VALUE hash;
    VALUE obj;
{
    if (NIL_P(hash) || TYPE(hash) != T_HASH) {
	return Qfalse;
    }
    else {
	VALUE list = rb_hash_aref(hash, ID2SYM(rb_frame_last_func()));

	if (NIL_P(list) || TYPE(list) != T_HASH)
	    return Qfalse;
	if (NIL_P(rb_hash_lookup(list, obj)))
	    return Qfalse;
	return Qtrue;
    }
}

static VALUE
recursive_push(hash, obj)
    VALUE hash;
    VALUE obj;
{
    VALUE list, sym;

    sym = ID2SYM(rb_frame_last_func());
    if (NIL_P(hash) || TYPE(hash) != T_HASH) {
	hash = rb_hash_new();
	rb_thread_local_aset(rb_thread_current(), recursive_key, hash);
	list = Qnil;
    }
    else {
	list = rb_hash_aref(hash, sym);
    }
    if (NIL_P(list) || TYPE(list) != T_HASH) {
	list = rb_hash_new();
	rb_hash_aset(hash, sym, list);
    }
    rb_hash_aset(list, obj, Qtrue);
    return hash;
}

static void
recursive_pop(hash, obj)
    VALUE hash;
    VALUE obj;
{
    VALUE list, sym;

    sym = ID2SYM(rb_frame_last_func());
    if (NIL_P(hash) || TYPE(hash) != T_HASH) {
	VALUE symname;
	VALUE thrname;
	symname = rb_inspect(sym);
	thrname = rb_inspect(rb_thread_current());

	rb_raise(rb_eTypeError, &quot;invalid inspect_tbl hash for %s in %s&quot;,
		 StringValuePtr(symname), StringValuePtr(thrname));
    }
    list = rb_hash_aref(hash, sym);
    if (NIL_P(list) || TYPE(list) != T_HASH) {
	VALUE symname = rb_inspect(sym);
	VALUE thrname = rb_inspect(rb_thread_current());
	rb_raise(rb_eTypeError, &quot;invalid inspect_tbl list for %s in %s&quot;,
		 StringValuePtr(symname), StringValuePtr(thrname));
    }
    rb_hash_delete(list, obj);
}

VALUE
rb_exec_recursive(func, obj, arg)
    VALUE (*func) _((VALUE, VALUE, int));
    VALUE obj;
    VALUE arg;
{
    VALUE hash = rb_thread_local_aref(rb_thread_current(), recursive_key);
    VALUE objid = rb_obj_id(obj);

    if (recursive_check(hash, objid)) {
	return (*func) (obj, arg, Qtrue);
    }
    else {
	VALUE result = Qundef;
	int state;

	hash = recursive_push(hash, objid);
	PUSH_TAG(PROT_NONE);
	if ((state = EXEC_TAG()) == 0) {
	    result = (*func) (obj, arg, Qfalse);
	}
	POP_TAG();
	recursive_pop(hash, objid);
	if (state)
	    JUMP_TAG(state);
	return result;
    }
}


/*
 *  +Thread+ encapsulates the behavior of a thread of
 *  execution, including the main thread of the Ruby script.
 *     
 *  In the descriptions of the methods in this class, the parameter _sym_
 *  refers to a symbol, which is either a quoted string or a 
 *  +Symbol+ (such as &lt;code&gt;:name&lt;/code&gt;).
 */

void
Init_Thread()
{
    VALUE cThGroup;

    recursive_key = rb_intern(&quot;__recursive_key__&quot;);
    rb_eThreadError = rb_define_class(&quot;ThreadError&quot;, rb_eStandardError);
    rb_cThread = rb_define_class(&quot;Thread&quot;, rb_cObject);
    rb_undef_alloc_func(rb_cThread);

    rb_define_singleton_method(rb_cThread, &quot;new&quot;, rb_thread_s_new, -1);
    rb_define_method(rb_cThread, &quot;initialize&quot;, rb_thread_initialize, -2);
    rb_define_singleton_method(rb_cThread, &quot;start&quot;, rb_thread_start, -2);
    rb_define_singleton_method(rb_cThread, &quot;fork&quot;, rb_thread_start, -2);

    rb_define_singleton_method(rb_cThread, &quot;stop&quot;, rb_thread_stop, 0);
    rb_define_singleton_method(rb_cThread, &quot;kill&quot;, rb_thread_s_kill, 1);
    rb_define_singleton_method(rb_cThread, &quot;exit&quot;, rb_thread_exit, 0);
    rb_define_singleton_method(rb_cThread, &quot;pass&quot;, rb_thread_pass, 0);
    rb_define_singleton_method(rb_cThread, &quot;current&quot;, rb_thread_current, 0);
    rb_define_singleton_method(rb_cThread, &quot;main&quot;, rb_thread_main, 0);
    rb_define_singleton_method(rb_cThread, &quot;list&quot;, rb_thread_list, 0);

    rb_define_singleton_method(rb_cThread, &quot;critical&quot;, rb_thread_critical_get, 0);
    rb_define_singleton_method(rb_cThread, &quot;critical=&quot;, rb_thread_critical_set, 1);

    rb_define_singleton_method(rb_cThread, &quot;abort_on_exception&quot;, rb_thread_s_abort_exc, 0);
    rb_define_singleton_method(rb_cThread, &quot;abort_on_exception=&quot;, rb_thread_s_abort_exc_set, 1);

    rb_define_method(rb_cThread, &quot;run&quot;, rb_thread_run, 0);
    rb_define_method(rb_cThread, &quot;wakeup&quot;, rb_thread_wakeup, 0);
    rb_define_method(rb_cThread, &quot;kill&quot;, rb_thread_kill, 0);
    rb_define_method(rb_cThread, &quot;terminate&quot;, rb_thread_kill, 0);
    rb_define_method(rb_cThread, &quot;exit&quot;, rb_thread_kill, 0);
    rb_define_method(rb_cThread, &quot;kill!&quot;, rb_thread_kill_bang, 0);
    rb_define_method(rb_cThread, &quot;terminate!&quot;, rb_thread_kill_bang, 0);
    rb_define_method(rb_cThread, &quot;exit!&quot;, rb_thread_kill_bang, 0);
    rb_define_method(rb_cThread, &quot;value&quot;, rb_thread_value, 0);
    rb_define_method(rb_cThread, &quot;status&quot;, rb_thread_status, 0);
    rb_define_method(rb_cThread, &quot;join&quot;, rb_thread_join_m, -1);
    rb_define_method(rb_cThread, &quot;alive?&quot;, rb_thread_alive_p, 0);
    rb_define_method(rb_cThread, &quot;stop?&quot;, rb_thread_stop_p, 0);
    rb_define_method(rb_cThread, &quot;raise&quot;, rb_thread_raise_m, -1);

    rb_define_method(rb_cThread, &quot;abort_on_exception&quot;, rb_thread_abort_exc, 0);
    rb_define_method(rb_cThread, &quot;abort_on_exception=&quot;, rb_thread_abort_exc_set, 1);

    rb_define_method(rb_cThread, &quot;priority&quot;, rb_thread_priority, 0);
    rb_define_method(rb_cThread, &quot;priority=&quot;, rb_thread_priority_set, 1);
    rb_define_method(rb_cThread, &quot;safe_level&quot;, rb_thread_safe_level, 0);
    rb_define_method(rb_cThread, &quot;group&quot;, rb_thread_group, 0);

    rb_define_method(rb_cThread, &quot;[]&quot;, rb_thread_aref, 1);
    rb_define_method(rb_cThread, &quot;[]=&quot;, rb_thread_aset, 2);
    rb_define_method(rb_cThread, &quot;key?&quot;, rb_thread_key_p, 1);
    rb_define_method(rb_cThread, &quot;keys&quot;, rb_thread_keys, 0);

    rb_define_method(rb_cThread, &quot;inspect&quot;, rb_thread_inspect, 0);

    rb_cCont = rb_define_class(&quot;Continuation&quot;, rb_cObject);
    rb_undef_alloc_func(rb_cCont);
    rb_undef_method(CLASS_OF(rb_cCont), &quot;new&quot;);
    rb_define_method(rb_cCont, &quot;call&quot;, rb_cont_call, -1);
    rb_define_method(rb_cCont, &quot;[]&quot;, rb_cont_call, -1);
    rb_define_global_function(&quot;callcc&quot;, rb_callcc, 0);
    rb_global_variable(&amp;cont_protect);

    cThGroup = rb_define_class(&quot;ThreadGroup&quot;, rb_cObject);
    rb_define_alloc_func(cThGroup, thgroup_s_alloc);
    rb_define_method(cThGroup, &quot;list&quot;, thgroup_list, 0);
    rb_define_method(cThGroup, &quot;enclose&quot;, thgroup_enclose, 0);
    rb_define_method(cThGroup, &quot;enclosed?&quot;, thgroup_enclosed_p, 0);
    rb_define_method(cThGroup, &quot;add&quot;, thgroup_add, 1);
    rb_global_variable(&amp;thgroup_default);
    thgroup_default = rb_obj_alloc(cThGroup);
    rb_define_const(cThGroup, &quot;Default&quot;, thgroup_default);

    /* allocate main thread */
    main_thread = rb_thread_alloc(rb_cThread);
    curr_thread = main_thread-&gt;prev = main_thread-&gt;next = main_thread;
}

/*
 *  call-seq:
 *     catch(symbol) {| | block }  &gt; obj
 *  
 *  +catch+ executes its block. If a +throw+ is
 *  executed, Ruby searches up its stack for a +catch+ block
 *  with a tag corresponding to the +throw+'s
 *  _symbol_. If found, that block is terminated, and
 *  +catch+ returns the value given to +throw+. If
 *  +throw+ is not called, the block terminates normally, and
 *  the value of +catch+ is the value of the last expression
 *  evaluated. +catch+ expressions may be nested, and the
 *  +throw+ call need not be in lexical scope.
 *     
 *     def routine(n)
 *       puts n
 *       throw :done if n &lt;= 0
 *       routine(n-1)
 *     end
 *     
 *     
 *     catch(:done) { routine(3) }
 *     
 *  &lt;em&gt;produces:&lt;/em&gt;
 *     
 *     3
 *     2
 *     1
 *     0
 */

static VALUE
rb_f_catch(dmy, tag)
    VALUE dmy, tag;
{
    int state;
    VALUE val = Qnil;		/* OK */

    tag = ID2SYM(rb_to_id(tag));
    PUSH_TAG(tag);
    if ((state = EXEC_TAG()) == 0) {
	val = rb_yield_0(tag, 0, 0, 0, Qfalse);
    }
    else if (state == TAG_THROW &amp;&amp; tag == prot_tag-&gt;dst) {
	val = prot_tag-&gt;retval;
	state = 0;
    }
    POP_TAG();
    if (state) JUMP_TAG(state);

    return val;
}

static VALUE
catch_i(tag)
    VALUE tag;
{
    return rb_funcall(Qnil, rb_intern(&quot;catch&quot;), 1, tag);
}

VALUE
rb_catch(tag, func, data)
    const char *tag;
    VALUE (*func)();
    VALUE data;
{
    return rb_iterate((VALUE(*)_((VALUE)))catch_i, ID2SYM(rb_intern(tag)), func, data);
}

/*
 *  call-seq:
 *     throw(symbol [, obj])
 *  
 *  Transfers control to the end of the active +catch+ block
 *  waiting for _symbol_. Raises +NameError+ if there
 *  is no +catch+ block for the symbol. The optional second
 *  parameter supplies a return value for the +catch+ block,
 *  which otherwise defaults to +nil+. For examples, see
 *  &lt;code&gt;Kernel::catch&lt;/code&gt;.
 */

static VALUE
rb_f_throw(argc, argv)
    int argc;
    VALUE *argv;
{
    VALUE tag, value;
    struct tag *tt = prot_tag;

    rb_scan_args(argc, argv, &quot;11&quot;, &amp;tag, &amp;value);
    tag = ID2SYM(rb_to_id(tag));

    while (tt) {
	if (tt-&gt;tag == tag) {
	    tt-&gt;dst = tag;
	    tt-&gt;retval = value;
	    break;
	}
	if (tt-&gt;tag == PROT_THREAD) {
	    rb_raise(rb_eThreadError, &quot;uncaught throw `%s' in thread 0x%lx&quot;,
		     rb_id2name(SYM2ID(tag)),
		     curr_thread);
	}
	tt = tt-&gt;prev;
    }
    if (!tt) {
	rb_name_error(SYM2ID(tag), &quot;uncaught throw `%s'&quot;, rb_id2name(SYM2ID(tag)));
    }
    rb_trap_restore_mask();
    JUMP_TAG(TAG_THROW);
#ifndef __GNUC__
    return Qnil; 		/* not reached */
#endif
}

void
rb_throw(tag, val)
    const char *tag;
    VALUE val;
{
    VALUE argv[2];

    argv[0] = ID2SYM(rb_intern(tag));
    argv[1] = val;
    rb_f_throw(2, argv);
}
</pre>
    </div>