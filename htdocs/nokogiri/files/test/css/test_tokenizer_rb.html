  <div id="fileHeader">
    <h1>test_tokenizer.rb</h1>
    <table class="header-table">
    <tr class="top-aligned-row">
      <td><strong>Path:</strong></td>
      <td>test/css/test_tokenizer.rb</td>
    </tr>
    <tr class="top-aligned-row">
      <td><strong>Last Update:</strong></td>
      <td>Mon Oct 12 19:40:25 +0200 2009</td>
    </tr>
    </table>
  </div>
 <!-- banner header -->

  <div id="bodyContent" >
    <h2>Source Code</h2>
    <pre># -*- coding: utf-8 -*-

require &quot;helper&quot;

module Nokogiri
  module CSS
    class TestTokenizer &lt; Nokogiri::TestCase
      def setup
        super
        @scanner = Nokogiri::CSS::Tokenizer.new
      end

      def test_unicode
        @scanner.scan(&quot;a日本語&quot;)
        assert_tokens([[:IDENT, 'a日本語']], @scanner)
      end

      def test_tokenize_bad_single_quote
        @scanner.scan(&quot;'&quot;)
        assert_tokens([[&quot;'&quot;, &quot;'&quot;]], @scanner)
      end

      def test_not_equal
        @scanner.scan(&quot;h1[a!='Tender Lovemaking']&quot;)
        assert_tokens([ [:IDENT, 'h1'],
                        [:LSQUARE, '['],
                        [:IDENT, 'a'],
                        [:NOT_EQUAL, '!='],
                        [:STRING, &quot;'Tender Lovemaking'&quot;],
                        [:RSQUARE, ']'],
        ], @scanner)
      end

      def test_negation
        @scanner.scan(&quot;p:not(.a)&quot;)
        assert_tokens([ [:IDENT, 'p'],
                        [:NOT, ':not('],
                        ['.', '.'],
                        [:IDENT, 'a'],
                        [:RPAREN, ')'],
        ], @scanner)
      end

      def test_function
        @scanner.scan(&quot;script comment()&quot;)
        assert_tokens([ [:IDENT, 'script'],
                        [:S, ' '],
                        [:FUNCTION, 'comment('],
                        [:RPAREN, ')'],
        ], @scanner)
      end

      def test_preceding_selector
        @scanner.scan(&quot;E ~ F&quot;)
        assert_tokens([ [:IDENT, 'E'],
                        [:TILDE, ' ~ '],
                        [:IDENT, 'F'],
        ], @scanner)
      end

      def test_scan_attribute_string
        @scanner.scan(&quot;h1[a='Tender Lovemaking']&quot;)
        assert_tokens([ [:IDENT, 'h1'],
                        [:LSQUARE, '['],
                        [:IDENT, 'a'],
                        [:EQUAL, '='],
                        [:STRING, &quot;'Tender Lovemaking'&quot;],
                        [:RSQUARE, ']'],
        ], @scanner)
        @scanner.scan('h1[a=&quot;Tender Lovemaking&quot;]')
        assert_tokens([ [:IDENT, 'h1'],
                        [:LSQUARE, '['],
                        [:IDENT, 'a'],
                        [:EQUAL, '='],
                        [:STRING, '&quot;Tender Lovemaking&quot;'],
                        [:RSQUARE, ']'],
        ], @scanner)
      end

      def test_scan_id
        @scanner.scan('#foo')
        assert_tokens([ [:HASH, '#foo'] ], @scanner)
      end

      def test_scan_pseudo
        @scanner.scan('a:visited')
        assert_tokens([ [:IDENT, 'a'],
                        [':', ':'],
                        [:IDENT, 'visited']
        ], @scanner)
      end

      def test_scan_star
        @scanner.scan('*')
        assert_tokens([ ['*', '*'], ], @scanner)
      end

      def test_scan_class
        @scanner.scan('x.awesome')
        assert_tokens([ [:IDENT, 'x'],
                        ['.', '.'],
                        [:IDENT, 'awesome'],
        ], @scanner)
      end

      def test_scan_greater
        @scanner.scan('x &gt; y')
        assert_tokens([ [:IDENT, 'x'],
                        [:GREATER, ' &gt; '],
                        [:IDENT, 'y']
        ], @scanner)
      end

      def test_scan_slash
        @scanner.scan('x/y')
        assert_tokens([ [:IDENT, 'x'],
                        [:SLASH, '/'],
                        [:IDENT, 'y']
        ], @scanner)
      end

      def test_scan_doubleslash
        @scanner.scan('x//y')
        assert_tokens([ [:IDENT, 'x'],
                        [:DOUBLESLASH, '//'],
                        [:IDENT, 'y']
        ], @scanner)
      end

      def test_scan_function_selector
        @scanner.scan('x:eq(0)')
        assert_tokens([ [:IDENT, 'x'],
                        [':', ':'],
                        [:FUNCTION, 'eq('],
                        [:NUMBER, &quot;0&quot;],
                        [:RPAREN, ')'],
        ], @scanner)
      end

      def test_scan_an_plus_b
        @scanner.scan('x:nth-child(5n+3)')
        assert_tokens([ [:IDENT, 'x'],
                        [':', ':'],
                        [:FUNCTION, 'nth-child('],
                        [:NUMBER, '5'],
                        [:IDENT, 'n'],
                        [:PLUS, '+'],
                        [:NUMBER, '3'],
                        [:RPAREN, ')'],
        ], @scanner)

        @scanner.scan('x:nth-child(-1n+3)')
        assert_tokens([ [:IDENT, 'x'],
                        [':', ':'],
                        [:FUNCTION, 'nth-child('],
                        [:NUMBER, '-1'],
                        [:IDENT, 'n'],
                        [:PLUS, '+'],
                        [:NUMBER, '3'],
                        [:RPAREN, ')'],
        ], @scanner)

        @scanner.scan('x:nth-child(-n+3)')
        assert_tokens([ [:IDENT, 'x'],
                        [':', ':'],
                        [:FUNCTION, 'nth-child('],
                        [:IDENT, '-n'],
                        [:PLUS, '+'],
                        [:NUMBER, '3'],
                        [:RPAREN, ')'],
        ], @scanner)
      end

      def assert_tokens(tokens, scanner)
        toks = []
        while tok = @scanner.next_token
          toks &lt;&lt; tok
        end
        assert_equal(tokens, toks)
      end
    end
  end
end
</pre>
    </div>